{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Testing_year_15.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMH1yxOu0zGA+Rtyuvb1tvA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zanifar/Recommending-colleges-for-each-category-of-students/blob/main/Testing_year_15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SeIewWf3-Kb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2c1c6c5-5d0d-40da-ef12-ea830f147f9c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udptDjb_9xxn"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plts\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ct8BItJq-Di1",
        "outputId": "4fb98547-c145-468d-cff8-334d74d63291"
      },
      "source": [
        "for i in range(1,14):\n",
        "  print(\"t\"+str(i),\",\",end=\" \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t1 , t2 , t3 , t4 , t5 , t6 , t7 , t8 , t9 , t10 , t11 , t12 , t13 , "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIaU9fg107xR"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjgS45zB-EsC"
      },
      "source": [
        "**All the Dataset load**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iliHEaPH-AJh",
        "outputId": "a95c5f6a-a7cd-4696-dcc6-8e628bb177ca"
      },
      "source": [
        "t1 =pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Thesis/mapSSCHSC03.csv')\n",
        "t2 =pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Thesis/mapSSCHSC04.csv')\n",
        "t3 =pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Thesis/mapSSCHSC05.csv')\n",
        "t4 =pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Thesis/mapSSCHSC06.csv')\n",
        "t5 =pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Thesis/mapSSCHSC07.csv')\n",
        "t6 =pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Thesis/mapSSCHSC08.csv')\n",
        "t7 =pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Thesis/mapSSCHSC09.csv')\n",
        "t8 =pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Thesis/mapSSCHSC10.csv')\n",
        "t9 =pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Thesis/mapSSCHSC11.csv')\n",
        "t10 =pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Thesis/mapSSCHSC12.csv')\n",
        "t11 =pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Thesis/mapSSCHSC13.csv')\n",
        "t12 =pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Thesis/mapSSCHSC14.csv')\n",
        "t13 =pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Thesis/mapSSCHSC15.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glg4wpqN1pcX",
        "outputId": "ff1b1a0f-beeb-49bd-d92e-00ce8a486c98"
      },
      "source": [
        "t1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6174, 23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfNAymul1qyM",
        "outputId": "aaaa3bc1-410c-42cc-83b7-e2e31d94e760"
      },
      "source": [
        "t13.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50300, 23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCUbc9RR8PUN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsGdEmAY91Tr",
        "outputId": "df14a5e3-1c0b-4e2b-fa9b-e689a57e86ab"
      },
      "source": [
        "dataset = [t1 , t2 , t3 , t4 , t5 , t6 , t7 , t8 , t9 , t10 , t11 , t12 , t13]\n",
        "t_df=pd.concat(dataset)\n",
        "t_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(268374, 29)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "HKKmv6HPt1J2",
        "outputId": "3c4fdd06-f3d2-4e3c-8738-0d7c751492b7"
      },
      "source": [
        "g = sns.catplot(x=\"PASS_YE.1\", hue=\"SEX\",\n",
        "                data=t_df, kind=\"count\",\n",
        "                height=6, aspect=1.5);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 690.375x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "e3RtIjGD3h3O",
        "outputId": "901539fe-eff0-4455-e74d-6235fb82baff"
      },
      "source": [
        "g1 = sns.catplot(x=\"PASS_YE.1\", hue=\"STUD_GROUP.1\",\n",
        "                data=t_df, kind=\"count\",\n",
        "                height=7, aspect=1.8);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1038.7x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "-7pw_efL3gu-",
        "outputId": "195ee879-a1e0-44f5-b111-9a2c5fdd0801"
      },
      "source": [
        "g1 = sns.catplot(x=\"PASS_YE.1\", hue=\"SEX\",col=\"STUD_GROUP.1\",\n",
        "                data=t_df, kind=\"count\",\n",
        "                height=10, aspect=.9);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1986.38x720 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMWH883rlKBj",
        "outputId": "5de99b74-d9e2-4b1b-f380-01633f9b2c98"
      },
      "source": [
        "train1 =pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Thesis/mapSSCHSC13.csv')\n",
        "train1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37123, 23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "cJMfsObKlKJ2",
        "outputId": "14b8cfe1-8262-4433-c5d2-884b2517a66c"
      },
      "source": [
        "train2 =pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Thesis/mapSSCHSC14.csv')\n",
        "train2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NAME</th>\n",
              "      <th>FATHER</th>\n",
              "      <th>MOTHER</th>\n",
              "      <th>SESSION</th>\n",
              "      <th>PASS_YE</th>\n",
              "      <th>GPA</th>\n",
              "      <th>RESULT</th>\n",
              "      <th>INST_</th>\n",
              "      <th>EXAM_</th>\n",
              "      <th>STUD_GROUP</th>\n",
              "      <th>STUD_TYPE</th>\n",
              "      <th>GRD_MARK</th>\n",
              "      <th>SEX</th>\n",
              "      <th>SESSION.1</th>\n",
              "      <th>PASS_YE.1</th>\n",
              "      <th>GPA.1</th>\n",
              "      <th>INST_.1</th>\n",
              "      <th>EXAM_.1</th>\n",
              "      <th>RESULT.1</th>\n",
              "      <th>STUD_GROUP.1</th>\n",
              "      <th>STUD_TYPE.1</th>\n",
              "      <th>LTRGRD</th>\n",
              "      <th>STUD_S</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SABBIR AHMED</td>\n",
              "      <td>MD. ABDUL MOTALEB</td>\n",
              "      <td>SHAHIDA BEGUM</td>\n",
              "      <td>2010-11</td>\n",
              "      <td>2012</td>\n",
              "      <td>5.0000</td>\n",
              "      <td>P</td>\n",
              "      <td>1000</td>\n",
              "      <td>SSC</td>\n",
              "      <td>HUMANITIES</td>\n",
              "      <td>REGULAR</td>\n",
              "      <td>101:A+,107:A+,109:A+,127:A ,111:A+,110:A+,139:...</td>\n",
              "      <td>0</td>\n",
              "      <td>2012-13</td>\n",
              "      <td>2014</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1150</td>\n",
              "      <td>HSC</td>\n",
              "      <td>P</td>\n",
              "      <td>HUMANITIES</td>\n",
              "      <td>REGULAR</td>\n",
              "      <td>101:A+,107:A+,109:A ,111:A+,125:A+,129:A+</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SHAJIB MAHMUD ZAKIR</td>\n",
              "      <td>HAJI ABDUL KADIR MORAL</td>\n",
              "      <td>ZAKIA AKTER</td>\n",
              "      <td>2010-11</td>\n",
              "      <td>2012</td>\n",
              "      <td>5.0000</td>\n",
              "      <td>P</td>\n",
              "      <td>1000</td>\n",
              "      <td>SSC</td>\n",
              "      <td>HUMANITIES</td>\n",
              "      <td>REGULAR</td>\n",
              "      <td>101:A+,107:A+,109:A+,127:A+,111:A+,110:A+,139:...</td>\n",
              "      <td>0</td>\n",
              "      <td>2012-13</td>\n",
              "      <td>2014</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1150</td>\n",
              "      <td>HSC</td>\n",
              "      <td>P</td>\n",
              "      <td>HUMANITIES</td>\n",
              "      <td>REGULAR</td>\n",
              "      <td>101:A+,107:A+,109:A+,111:A+,125:A+,129:A+</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MAHMUDUL HASAN SADI</td>\n",
              "      <td>MD. ABDUL MANNAN</td>\n",
              "      <td>LIPI AKTAR</td>\n",
              "      <td>2010-11</td>\n",
              "      <td>2012</td>\n",
              "      <td>5.0000</td>\n",
              "      <td>P</td>\n",
              "      <td>1000</td>\n",
              "      <td>SSC</td>\n",
              "      <td>HUMANITIES</td>\n",
              "      <td>REGULAR</td>\n",
              "      <td>101:A+,107:A ,109:B ,127:A+,111:A+,110:A+,139:...</td>\n",
              "      <td>0</td>\n",
              "      <td>2012-13</td>\n",
              "      <td>2014</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1150</td>\n",
              "      <td>HSC</td>\n",
              "      <td>P</td>\n",
              "      <td>HUMANITIES</td>\n",
              "      <td>REGULAR</td>\n",
              "      <td>101:A ,107:A+,109:A ,111:A ,125:A+,129:A+</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MD. ZOBAIR BIN ZAHIR</td>\n",
              "      <td>MD. ZAHIRUL HAQUE</td>\n",
              "      <td>KAMRUNNAHAR</td>\n",
              "      <td>2010-11</td>\n",
              "      <td>2012</td>\n",
              "      <td>5.0000</td>\n",
              "      <td>P</td>\n",
              "      <td>1000</td>\n",
              "      <td>SSC</td>\n",
              "      <td>HUMANITIES</td>\n",
              "      <td>REGULAR</td>\n",
              "      <td>101:A+,107:A ,109:A+,127:A+,111:A+,110:A+,139:...</td>\n",
              "      <td>0</td>\n",
              "      <td>2012-13</td>\n",
              "      <td>2014</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1150</td>\n",
              "      <td>HSC</td>\n",
              "      <td>P</td>\n",
              "      <td>HUMANITIES</td>\n",
              "      <td>REGULAR</td>\n",
              "      <td>101:A+,107:A+,109:A+,111:A+,125:A+,129:A+</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ABRAR SHAHRIAR KHAN</td>\n",
              "      <td>SHAWKAT HAMID</td>\n",
              "      <td>SAEEDA AKHTER</td>\n",
              "      <td>2010-11</td>\n",
              "      <td>2012</td>\n",
              "      <td>5.0000</td>\n",
              "      <td>P</td>\n",
              "      <td>1000</td>\n",
              "      <td>SSC</td>\n",
              "      <td>HUMANITIES</td>\n",
              "      <td>REGULAR</td>\n",
              "      <td>101:A ,107:A+,109:A+,127:A+,111:A+,110:A+,139:...</td>\n",
              "      <td>0</td>\n",
              "      <td>2012-13</td>\n",
              "      <td>2014</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1150</td>\n",
              "      <td>HSC</td>\n",
              "      <td>P</td>\n",
              "      <td>HUMANITIES</td>\n",
              "      <td>REGULAR</td>\n",
              "      <td>101:A+,107:A+,109:A ,111:A+,125:A+,129:A+</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49532</th>\n",
              "      <td>MD. HABIBUR RAHMAN</td>\n",
              "      <td>MD. ABDUL HANNAN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1998-99</td>\n",
              "      <td>2001</td>\n",
              "      <td>2.5000</td>\n",
              "      <td>GPA=2.50</td>\n",
              "      <td>1850</td>\n",
              "      <td>SSC</td>\n",
              "      <td>HUMANITIES</td>\n",
              "      <td>IRREGULAR</td>\n",
              "      <td>101:C  ,107:C  ,109:A  ,127:C  ,111:B  ,110:C ...</td>\n",
              "      <td>0</td>\n",
              "      <td>2014</td>\n",
              "      <td>2014</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1000</td>\n",
              "      <td>HSC</td>\n",
              "      <td>P</td>\n",
              "      <td>HUMANITIES</td>\n",
              "      <td>PRIVATE</td>\n",
              "      <td>101:B ,107:B ,111:A-,119:A-,209:B</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49533</th>\n",
              "      <td>MD. AMINUL ISLAM</td>\n",
              "      <td>MD. ABDUS SHAHID</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1999-00</td>\n",
              "      <td>2001</td>\n",
              "      <td>3.1300</td>\n",
              "      <td>GPA=3.13</td>\n",
              "      <td>2325</td>\n",
              "      <td>SSC</td>\n",
              "      <td>SCIENCE</td>\n",
              "      <td>REGULAR</td>\n",
              "      <td>101:B  ,107:C  ,109:D  ,145:B  ,111:A  ,136:A ...</td>\n",
              "      <td>0</td>\n",
              "      <td>2012-13</td>\n",
              "      <td>2014</td>\n",
              "      <td>3.3</td>\n",
              "      <td>2325</td>\n",
              "      <td>HSC</td>\n",
              "      <td>P</td>\n",
              "      <td>HUMANITIES</td>\n",
              "      <td>REGULAR</td>\n",
              "      <td>101:B ,107:A-,109:C ,111:B ,242:B ,237:A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49534</th>\n",
              "      <td>ASMA BEGUM</td>\n",
              "      <td>MD. RAJAB ALI</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1996-97</td>\n",
              "      <td>2001</td>\n",
              "      <td>3.0625</td>\n",
              "      <td>MARKS= 558(2nd Div.)</td>\n",
              "      <td>2507</td>\n",
              "      <td>SSC</td>\n",
              "      <td>HUMANITIES</td>\n",
              "      <td>IRREGULAR</td>\n",
              "      <td>101:B, 107:C, 109:C, 127:A-, 111:B, 110:B, 13...</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-12</td>\n",
              "      <td>2014</td>\n",
              "      <td>1.9</td>\n",
              "      <td>1060</td>\n",
              "      <td>HSC</td>\n",
              "      <td>F1</td>\n",
              "      <td>HUMANITIES</td>\n",
              "      <td>IRREGULAR</td>\n",
              "      <td>101:C ,107:F ,111:C ,117:C ,249:C ,131:A-</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49535</th>\n",
              "      <td>GULA JANNAT</td>\n",
              "      <td>ABDUL KODDUS</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1999-00</td>\n",
              "      <td>2001</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>GPA=3.00</td>\n",
              "      <td>2516</td>\n",
              "      <td>SSC</td>\n",
              "      <td>HUMANITIES</td>\n",
              "      <td>REGULAR</td>\n",
              "      <td>101:B  ,107:D  ,109:A  ,127:C  ,111:A  ,110:B ...</td>\n",
              "      <td>1</td>\n",
              "      <td>2013</td>\n",
              "      <td>2014</td>\n",
              "      <td>2.9</td>\n",
              "      <td>1000</td>\n",
              "      <td>HSC</td>\n",
              "      <td>P</td>\n",
              "      <td>HUMANITIES</td>\n",
              "      <td>PRIVATE</td>\n",
              "      <td>101:B ,107:D ,111:B ,209:A-,249:A</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49536</th>\n",
              "      <td>SADEKA AKTER</td>\n",
              "      <td>MD IMAN ALI</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1997-98</td>\n",
              "      <td>2001</td>\n",
              "      <td>3.0625</td>\n",
              "      <td>MARKS= 560(2nd Div.)</td>\n",
              "      <td>2526</td>\n",
              "      <td>SSC</td>\n",
              "      <td>SCIENCE</td>\n",
              "      <td>IRREGULAR</td>\n",
              "      <td>101:C, 107:C, 109:B, 145:B, 111:A-, 136:B, 13...</td>\n",
              "      <td>1</td>\n",
              "      <td>2013</td>\n",
              "      <td>2014</td>\n",
              "      <td>1.8</td>\n",
              "      <td>1000</td>\n",
              "      <td>HSC</td>\n",
              "      <td>P</td>\n",
              "      <td>HUMANITIES</td>\n",
              "      <td>PRIVATE</td>\n",
              "      <td>101:B ,107:C ,109:D ,111:C ,209:D</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>49537 rows  23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       NAME  ... STUD_S\n",
              "0              SABBIR AHMED  ...      0\n",
              "1       SHAJIB MAHMUD ZAKIR  ...      0\n",
              "2       MAHMUDUL HASAN SADI  ...      0\n",
              "3      MD. ZOBAIR BIN ZAHIR  ...      0\n",
              "4       ABRAR SHAHRIAR KHAN  ...      0\n",
              "...                     ...  ...    ...\n",
              "49532    MD. HABIBUR RAHMAN  ...      0\n",
              "49533      MD. AMINUL ISLAM  ...      0\n",
              "49534            ASMA BEGUM  ...      1\n",
              "49535           GULA JANNAT  ...      1\n",
              "49536          SADEKA AKTER  ...      1\n",
              "\n",
              "[49537 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "gTcjzGKslKQO",
        "outputId": "87c3bdec-337a-4356-953e-89377abbb729"
      },
      "source": [
        "test=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Thesis/mapSSCHSC15.csv')\n",
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NAME</th>\n",
              "      <th>FATHER</th>\n",
              "      <th>MOTHER</th>\n",
              "      <th>SESSION</th>\n",
              "      <th>PASS_YE</th>\n",
              "      <th>GPA</th>\n",
              "      <th>RESULT</th>\n",
              "      <th>INST_</th>\n",
              "      <th>EXAM_</th>\n",
              "      <th>STUD_GROUP</th>\n",
              "      <th>STUD_TYPE</th>\n",
              "      <th>GRD_MARK</th>\n",
              "      <th>SEX</th>\n",
              "      <th>SESSION.1</th>\n",
              "      <th>PASS_YE.1</th>\n",
              "      <th>GPA.1</th>\n",
              "      <th>INST_.1</th>\n",
              "      <th>EXAM_.1</th>\n",
              "      <th>RESULT.1</th>\n",
              "      <th>STUD_GROUP.1</th>\n",
              "      <th>STUD_TYPE.1</th>\n",
              "      <th>LTRGRD</th>\n",
              "      <th>STUD_S</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NADIA AKTER</td>\n",
              "      <td>SIDDIQUR RAHMAN</td>\n",
              "      <td>LAILA BEGUM</td>\n",
              "      <td>2011-12</td>\n",
              "      <td>2013</td>\n",
              "      <td>4.13</td>\n",
              "      <td>P</td>\n",
              "      <td>1001</td>\n",
              "      <td>SSC</td>\n",
              "      <td>HUMANITIES</td>\n",
              "      <td>REGULAR</td>\n",
              "      <td>101:A ,107:A ,109:A-,127:A-,111:A+,110:A ,139:...</td>\n",
              "      <td>1</td>\n",
              "      <td>2013-14</td>\n",
              "      <td>2015</td>\n",
              "      <td>3.58</td>\n",
              "      <td>1050</td>\n",
              "      <td>HSC</td>\n",
              "      <td>P</td>\n",
              "      <td>HUMANITIES</td>\n",
              "      <td>REGULAR</td>\n",
              "      <td>101:B ,107:C ,275:A ,109:B ,269:A ,271:A-,273:A</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>IMRAN AHMAD</td>\n",
              "      <td>MD. ANAM MIA</td>\n",
              "      <td>SELUFA BEGUM</td>\n",
              "      <td>2011-12</td>\n",
              "      <td>2013</td>\n",
              "      <td>3.88</td>\n",
              "      <td>P</td>\n",
              "      <td>1001</td>\n",
              "      <td>SSC</td>\n",
              "      <td>HUMANITIES</td>\n",
              "      <td>REGULAR</td>\n",
              "      <td>101:A-,107:B ,109:A-,127:A-,111:A ,110:A ,139:...</td>\n",
              "      <td>0</td>\n",
              "      <td>2013-14</td>\n",
              "      <td>2015</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1075</td>\n",
              "      <td>HSC</td>\n",
              "      <td>F1</td>\n",
              "      <td>HUMANITIES</td>\n",
              "      <td>REGULAR</td>\n",
              "      <td>101:C ,107:D ,275:B ,109:D ,267:F ,271:C ,121:F</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MOUMITA AKTER</td>\n",
              "      <td>MD. MOMIN  MIA</td>\n",
              "      <td>MAHMUDA AKTER</td>\n",
              "      <td>2011-12</td>\n",
              "      <td>2013</td>\n",
              "      <td>3.88</td>\n",
              "      <td>P</td>\n",
              "      <td>1001</td>\n",
              "      <td>SSC</td>\n",
              "      <td>HUMANITIES</td>\n",
              "      <td>REGULAR</td>\n",
              "      <td>101:A-,107:A ,109:B ,127:A ,111:A ,110:A-,139:...</td>\n",
              "      <td>1</td>\n",
              "      <td>2013-14</td>\n",
              "      <td>2015</td>\n",
              "      <td>2.33</td>\n",
              "      <td>2651</td>\n",
              "      <td>HSC</td>\n",
              "      <td>P</td>\n",
              "      <td>HUMANITIES</td>\n",
              "      <td>REGULAR</td>\n",
              "      <td>101:B ,107:D ,275:C ,117:B ,269:B ,304:C ,121:F</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RUMANA AKTER</td>\n",
              "      <td>LATE ABDUL KHALEK</td>\n",
              "      <td>ASIA KHATUN</td>\n",
              "      <td>2011-12</td>\n",
              "      <td>2013</td>\n",
              "      <td>4.00</td>\n",
              "      <td>P</td>\n",
              "      <td>1001</td>\n",
              "      <td>SSC</td>\n",
              "      <td>HUMANITIES</td>\n",
              "      <td>REGULAR</td>\n",
              "      <td>101:A-,107:A ,109:A ,127:A-,111:A ,110:A-,139:...</td>\n",
              "      <td>1</td>\n",
              "      <td>2013-14</td>\n",
              "      <td>2015</td>\n",
              "      <td>2.70</td>\n",
              "      <td>1051</td>\n",
              "      <td>HSC</td>\n",
              "      <td>F1</td>\n",
              "      <td>BUSINESS STUDIES</td>\n",
              "      <td>REGULAR</td>\n",
              "      <td>101:B ,107:D ,275:A-,253:F ,277:A-,286:A-,292:D</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MEHERUN NESA ESHA</td>\n",
              "      <td>MD. MIZANUR RAHMAN</td>\n",
              "      <td>SHAHANA BEGUM</td>\n",
              "      <td>2011-12</td>\n",
              "      <td>2013</td>\n",
              "      <td>4.19</td>\n",
              "      <td>P</td>\n",
              "      <td>1001</td>\n",
              "      <td>SSC</td>\n",
              "      <td>HUMANITIES</td>\n",
              "      <td>REGULAR</td>\n",
              "      <td>101:A-,107:A ,109:A-,127:A ,111:A ,110:A ,139:...</td>\n",
              "      <td>1</td>\n",
              "      <td>2013-14</td>\n",
              "      <td>2015</td>\n",
              "      <td>4.00</td>\n",
              "      <td>1050</td>\n",
              "      <td>HSC</td>\n",
              "      <td>P</td>\n",
              "      <td>HUMANITIES</td>\n",
              "      <td>REGULAR</td>\n",
              "      <td>101:A-,107:B ,275:A+,109:A-,269:A ,271:A-,267:A-</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                NAME  ... STUD_S\n",
              "0        NADIA AKTER  ...      1\n",
              "1        IMRAN AHMAD  ...      0\n",
              "2      MOUMITA AKTER  ...      1\n",
              "3       RUMANA AKTER  ...      1\n",
              "4  MEHERUN NESA ESHA  ...      1\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIcfHy3v-oeh",
        "outputId": "329a0810-164d-4a83-e7e8-ead0f476eea1"
      },
      "source": [
        "frame = [train1,train2]\n",
        "train=pd.concat(frame)\n",
        "train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(86660, 23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JPk1Gph--Ld"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvMX_bipyxYi",
        "outputId": "d4966d8c-c43d-45ea-a765-de64b2356e39"
      },
      "source": [
        "tnd= train.loc[(train[\"GPA.1\"]<1.0)]\n",
        "tnd.shape\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2837, 23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVKJeoFWy0a9"
      },
      "source": [
        "tnd= train.loc[(train[\"GPA.1\"]<1.0)].index\n",
        "\n",
        "train.drop(tnd, inplace = True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ah2nBO2YupXw"
      },
      "source": [
        "features_drop = ['NAME','FATHER','MOTHER','SESSION','PASS_YE','RESULT','EXAM_','STUD_TYPE','EXAM_.1','STUD_TYPE.1','PASS_YE.1','GRD_MARK','SESSION.1','RESULT.1','LTRGRD','STUD_S']\n",
        "train = train.drop(features_drop, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otXXYSFQupb7"
      },
      "source": [
        "train_data1 = [train] \n",
        "group_mapping = {\"SCIENCE\": 0, \"HUMANITIES\": 1, \"BUSINESS STUDIES\": 2}\n",
        "for dataset in train_data1:\n",
        "    dataset['STUD_GROUP'] = dataset['STUD_GROUP'].map(group_mapping)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvJn4bHoupgc"
      },
      "source": [
        "train_data2 = [train] \n",
        "group_mapping = {\"SCIENCE\": 0, \"HUMANITIES\": 1, \"BUSINESS STUDIES\": 2}\n",
        "for dataset in train_data2:\n",
        "    dataset['STUD_GROUP.1'] = dataset['STUD_GROUP.1'].map(group_mapping)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWK6-WZ6y_Un",
        "outputId": "199cdfcc-516c-4f56-8ab9-a4a2c28b73ab"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(81550, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4BY27hBzB5D",
        "outputId": "abe8dbfb-25d4-4061-d989-58f562bd020b"
      },
      "source": [
        "train.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPA               0\n",
              "INST_             0\n",
              "STUD_GROUP        0\n",
              "SEX               0\n",
              "GPA.1           554\n",
              "INST_.1           0\n",
              "STUD_GROUP.1      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdy80DkIbWID"
      },
      "source": [
        "train = train.dropna(axis = 0, how ='any') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxNEx3ekbae1",
        "outputId": "584e1596-5bb6-4552-ad67-33cd8b5c86a2"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80996, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UwpHpCfswYB",
        "outputId": "b9369451-3a3a-485b-c8b7-9c7774da6a11"
      },
      "source": [
        "test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50300, 23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvVcz5gV131b"
      },
      "source": [
        "tsd= test.loc[(test[\"GPA.1\"]<1.0)].index\n",
        "\n",
        "test.drop(tsd, inplace = True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lWVswfqvHib"
      },
      "source": [
        "features_drop = ['NAME','FATHER','MOTHER','SESSION','PASS_YE','LTRGRD' ,'RESULT','EXAM_','STUD_TYPE','GRD_MARK','PASS_YE.1','SESSION.1','EXAM_.1','RESULT.1','STUD_TYPE.1','STUD_S']\n",
        "test= test.drop(features_drop, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwa76URMtFFB",
        "outputId": "e4715126-6499-41fa-ea6f-1a368b7e2cef"
      },
      "source": [
        "test.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPA               0\n",
              "INST_             0\n",
              "STUD_GROUP        0\n",
              "SEX               0\n",
              "GPA.1           328\n",
              "INST_.1           0\n",
              "STUD_GROUP.1      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMHJgtPYvKlo"
      },
      "source": [
        "test_data1 = [test] \n",
        "group_mapping = {\"SCIENCE\": 0, \"HUMANITIES\": 1, \"BUSINESS STUDIES\": 2}\n",
        "for dataset in test_data1:\n",
        "    dataset['STUD_GROUP'] = dataset['STUD_GROUP'].map(group_mapping)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpDMhPqPuprP"
      },
      "source": [
        "test_data2 = [test] \n",
        "group_mapping = {\"SCIENCE\": 0, \"HUMANITIES\": 1, \"BUSINESS STUDIES\": 2}\n",
        "for dataset in test_data2:\n",
        "    dataset['STUD_GROUP.1'] = dataset['STUD_GROUP.1'].map(group_mapping)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkqNsuxNbR4L"
      },
      "source": [
        "test = test.dropna(axis = 0, how ='any') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvfpEI99nx3k",
        "outputId": "a4ff0439-fcfb-4ea5-fe7e-4e25e8d4b816"
      },
      "source": [
        "test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48939, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9btgNFT_BVd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "CU4P-e3JukaW",
        "outputId": "08777713-5cfe-41da-b84c-2aaca64aa512"
      },
      "source": [
        "criteria = [train['GPA'].between(5.0,5.0), train['GPA'].between(4.5,5.0), train['GPA'].between(4.0,4.50), train['GPA'].between(3.5,4.0),train['GPA'].between(3.0,3.50),train['GPA'].between(2.5,3.0),train['GPA'].between(2.0,2.50),train['GPA'].between(1.5,2.0),train['GPA'].between(1.0,1.5)]\n",
        "values = ['5.0','4.5-5.0', '4.0-4.5', '3.5-4.0', '3.0-3.5','2.5-3.0', '2.0-2.5','1.5-2.0','1.0-1.5']\n",
        "\n",
        "train['SSC_GPA_CATEGORY'] = np.select(criteria, values)\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GPA</th>\n",
              "      <th>INST_</th>\n",
              "      <th>STUD_GROUP</th>\n",
              "      <th>SEX</th>\n",
              "      <th>GPA.1</th>\n",
              "      <th>INST_.1</th>\n",
              "      <th>STUD_GROUP.1</th>\n",
              "      <th>SSC_GPA_CATEGORY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>1000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1150</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>1000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1150</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>1000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1150</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>1000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1150</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>1000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1150</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   GPA  INST_  STUD_GROUP  SEX  GPA.1  INST_.1  STUD_GROUP.1 SSC_GPA_CATEGORY\n",
              "0  5.0   1000           0    0    5.0     1150             0              5.0\n",
              "1  5.0   1000           0    0    5.0     1150             0              5.0\n",
              "2  5.0   1000           0    0    5.0     1150             0              5.0\n",
              "3  5.0   1000           0    0    5.0     1150             0              5.0\n",
              "4  5.0   1000           0    0    5.0     1150             0              5.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "TB2CJJ0gAH3x",
        "outputId": "cf1cb321-788e-4339-818c-3c9896f95da8"
      },
      "source": [
        "criteria = [test['GPA'].between(5.0,5.0), test['GPA'].between(4.5,5.0), test['GPA'].between(4.0,4.50), test['GPA'].between(3.5,4.0),test['GPA'].between(3.0,3.50),test['GPA'].between(2.5,3.0),test['GPA'].between(2.0,2.50),test['GPA'].between(1.5,2.0),test['GPA'].between(1.0,1.5)]\n",
        "values = ['5.0','4.5-5.0', '4.0-4.5', '3.5-4.0', '3.0-3.5','2.5-3.0', '2.0-2.5','1.5-2.0','1.0-1.5']\n",
        "\n",
        "test['SSC_GPA_CATEGORY'] = np.select(criteria, values)\n",
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GPA</th>\n",
              "      <th>INST_</th>\n",
              "      <th>STUD_GROUP</th>\n",
              "      <th>SEX</th>\n",
              "      <th>GPA.1</th>\n",
              "      <th>INST_.1</th>\n",
              "      <th>STUD_GROUP.1</th>\n",
              "      <th>SSC_GPA_CATEGORY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.13</td>\n",
              "      <td>1001</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.58</td>\n",
              "      <td>1050</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0-4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.88</td>\n",
              "      <td>1001</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1075</td>\n",
              "      <td>1</td>\n",
              "      <td>3.5-4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.88</td>\n",
              "      <td>1001</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.33</td>\n",
              "      <td>2651</td>\n",
              "      <td>1</td>\n",
              "      <td>3.5-4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.00</td>\n",
              "      <td>1001</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.70</td>\n",
              "      <td>1051</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0-4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.19</td>\n",
              "      <td>1001</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.00</td>\n",
              "      <td>1050</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0-4.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    GPA  INST_  STUD_GROUP  SEX  GPA.1  INST_.1  STUD_GROUP.1 SSC_GPA_CATEGORY\n",
              "0  4.13   1001           1    1   3.58     1050             1          4.0-4.5\n",
              "1  3.88   1001           1    0   1.40     1075             1          3.5-4.0\n",
              "2  3.88   1001           1    1   2.33     2651             1          3.5-4.0\n",
              "3  4.00   1001           1    1   2.70     1051             2          4.0-4.5\n",
              "4  4.19   1001           1    1   4.00     1050             1          4.0-4.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkNH2c9j7SWi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abb816e1-1608-4d26-a2bf-4d0eb29cdc37"
      },
      "source": [
        "test[\"SSC_GPA_CATEGORY\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0-3.5    12236\n",
              "3.5-4.0    11572\n",
              "2.5-3.0     7739\n",
              "4.0-4.5     7713\n",
              "4.5-5.0     3994\n",
              "2.0-2.5     2689\n",
              "5.0         2552\n",
              "1.5-2.0      424\n",
              "1.0-1.5       20\n",
              "Name: SSC_GPA_CATEGORY, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNOyfMJ0_DMy",
        "outputId": "6ab810ad-5619-434c-f6ef-7c197ac6d33f"
      },
      "source": [
        "for i in range(1,25,9):\n",
        "    print(\"train_category\"+str(i+0),\" = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='5.0')]\",\"\\n\"+\n",
        " \"train_category\"+str(i+1),\" = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='4.5-5.0')]\",\"\\n\"+\n",
        "\"train_category\"+str(i+2),\" = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='4.0-4.5')]\",\"\\n\"+\n",
        "\"train_category\"+str(i+3),\" = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='3.5-4.0')]\",\"\\n\"+\n",
        "\"train_category\"+str(i+4),\" = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='3.0-3.5')]\",\"\\n\"+\n",
        "\"train_category\"+str(i+5),\" = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='2.5-3.0')]\",\"\\n\"+\n",
        "\"train_category\"+str(i+6),\" = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='2.0-2.5')]\",\"\\n\"+ \n",
        "\"train_category\"+str(i+7),\" = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='1.5-2.0')]\",\"\\n\"+\n",
        "\"train_category\"+str(i+8),\" = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='1.0-1.5')]\",\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_category1  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='5.0')] \n",
            "train_category2  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='4.5-5.0')] \n",
            "train_category3  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='4.0-4.5')] \n",
            "train_category4  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='3.5-4.0')] \n",
            "train_category5  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='3.0-3.5')] \n",
            "train_category6  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='2.5-3.0')] \n",
            "train_category7  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='2.0-2.5')] \n",
            "train_category8  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='1.5-2.0')] \n",
            "train_category9  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='1.0-1.5')] \n",
            "\n",
            "train_category10  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='5.0')] \n",
            "train_category11  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='4.5-5.0')] \n",
            "train_category12  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='4.0-4.5')] \n",
            "train_category13  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='3.5-4.0')] \n",
            "train_category14  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='3.0-3.5')] \n",
            "train_category15  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='2.5-3.0')] \n",
            "train_category16  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='2.0-2.5')] \n",
            "train_category17  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='1.5-2.0')] \n",
            "train_category18  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='1.0-1.5')] \n",
            "\n",
            "train_category19  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='5.0')] \n",
            "train_category20  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='4.5-5.0')] \n",
            "train_category21  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='4.0-4.5')] \n",
            "train_category22  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='3.5-4.0')] \n",
            "train_category23  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='3.0-3.5')] \n",
            "train_category24  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='2.5-3.0')] \n",
            "train_category25  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='2.0-2.5')] \n",
            "train_category26  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='1.5-2.0')] \n",
            "train_category27  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='1.0-1.5')] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcE1jzUOvaXb",
        "outputId": "798adbd7-8387-4c8b-ceda-f1965a7499f9"
      },
      "source": [
        "for i in range(28,55,9):\n",
        "    print(\"train_category\"+str(i+0),\" = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='5.0')]\",\"\\n\"+\n",
        " \"train_category\"+str(i+1),\" = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='4.5-5.0')]\",\"\\n\"+\n",
        "\"train_category\"+str(i+2),\" = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='4.0-4.5')]\",\"\\n\"+\n",
        "\"train_category\"+str(i+3),\" = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='3.5-4.0')]\",\"\\n\"+\n",
        "\"train_category\"+str(i+4),\" = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='3.0-3.5')]\",\"\\n\"+\n",
        "\"train_category\"+str(i+5),\" = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='2.5-3.0')]\",\"\\n\"+\n",
        "\"train_category\"+str(i+6),\" = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='2.0-2.5')]\",\"\\n\"+ \n",
        "\"train_category\"+str(i+7),\" = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='1.5-2.0')]\",\"\\n\"+\n",
        "\"train_category\"+str(i+8),\" = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='1.0-1.5')]\",\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_category28  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='5.0')] \n",
            "train_category29  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='4.5-5.0')] \n",
            "train_category30  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='4.0-4.5')] \n",
            "train_category31  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='3.5-4.0')] \n",
            "train_category32  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='3.0-3.5')] \n",
            "train_category33  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='2.5-3.0')] \n",
            "train_category34  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='2.0-2.5')] \n",
            "train_category35  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='1.5-2.0')] \n",
            "train_category36  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='1.0-1.5')] \n",
            "\n",
            "train_category37  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='5.0')] \n",
            "train_category38  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='4.5-5.0')] \n",
            "train_category39  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='4.0-4.5')] \n",
            "train_category40  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='3.5-4.0')] \n",
            "train_category41  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='3.0-3.5')] \n",
            "train_category42  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='2.5-3.0')] \n",
            "train_category43  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='2.0-2.5')] \n",
            "train_category44  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='1.5-2.0')] \n",
            "train_category45  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='1.0-1.5')] \n",
            "\n",
            "train_category46  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='5.0')] \n",
            "train_category47  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='4.5-5.0')] \n",
            "train_category48  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='4.0-4.5')] \n",
            "train_category49  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='3.5-4.0')] \n",
            "train_category50  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='3.0-3.5')] \n",
            "train_category51  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='2.5-3.0')] \n",
            "train_category52  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='2.0-2.5')] \n",
            "train_category53  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='1.5-2.0')] \n",
            "train_category54  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='1.0-1.5')] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKZs6CFxcIxC",
        "outputId": "d2f4fd23-9343-4718-e127-f937a4721eb8"
      },
      "source": [
        "train_category1  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='5.0')] \n",
        "train_category2  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='4.5-5.0')] \n",
        "train_category3  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='4.0-4.5')] \n",
        "train_category4  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='3.5-4.0')] \n",
        "train_category5  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='3.0-3.5')] \n",
        "train_category6  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='2.5-3.0')] \n",
        "train_category7  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='2.0-2.5')] \n",
        "train_category8  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='1.5-2.0')] \n",
        "train_category9  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='1.0-1.5')] \n",
        "\n",
        "train_category10  = train.loc[(train['STUD_GROUP']==1) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='5.0')] \n",
        "train_category11  = train.loc[(train['STUD_GROUP']==1) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='4.5-5.0')] \n",
        "train_category12  = train.loc[(train['STUD_GROUP']==1) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='4.0-4.5')] \n",
        "train_category13  = train.loc[(train['STUD_GROUP']==1) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='3.5-4.0')] \n",
        "train_category14  = train.loc[(train['STUD_GROUP']==1) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='3.0-3.5')] \n",
        "train_category15  = train.loc[(train['STUD_GROUP']==1) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='2.5-3.0')] \n",
        "train_category16  = train.loc[(train['STUD_GROUP']==1) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='2.0-2.5')] \n",
        "train_category17  = train.loc[(train['STUD_GROUP']==1) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='1.5-2.0')] \n",
        "train_category18  = train.loc[(train['STUD_GROUP']==1) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='1.0-1.5')] \n",
        "\n",
        "train_category19  = train.loc[(train['STUD_GROUP']==2) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='5.0')] \n",
        "train_category20  = train.loc[(train['STUD_GROUP']==2) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='4.5-5.0')] \n",
        "train_category21  = train.loc[(train['STUD_GROUP']==2) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='4.0-4.5')] \n",
        "train_category22  = train.loc[(train['STUD_GROUP']==2) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='3.5-4.0')] \n",
        "train_category23  = train.loc[(train['STUD_GROUP']==2) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='3.0-3.5')] \n",
        "train_category24  = train.loc[(train['STUD_GROUP']==2) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='2.5-3.0')] \n",
        "train_category25  = train.loc[(train['STUD_GROUP']==2) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='2.0-2.5')] \n",
        "train_category26  = train.loc[(train['STUD_GROUP']==2) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='1.5-2.0')] \n",
        "train_category27  = train.loc[(train['STUD_GROUP']==2) &(train['SEX']==0)& (train['SSC_GPA_CATEGORY']=='1.0-1.5')] \n",
        "\n",
        "train_category28  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='5.0')] \n",
        "train_category29  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='4.5-5.0')] \n",
        "train_category30  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='4.0-4.5')] \n",
        "train_category31  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='3.5-4.0')] \n",
        "train_category32  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='3.0-3.5')] \n",
        "train_category33  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='2.5-3.0')] \n",
        "train_category34  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='2.0-2.5')] \n",
        "train_category35  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='1.5-2.0')] \n",
        "train_category36  = train.loc[(train['STUD_GROUP']==0) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='1.0-1.5')] \n",
        "\n",
        "train_category37  = train.loc[(train['STUD_GROUP']==1) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='5.0')] \n",
        "train_category38  = train.loc[(train['STUD_GROUP']==1) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='4.5-5.0')] \n",
        "train_category39  = train.loc[(train['STUD_GROUP']==1) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='4.0-4.5')] \n",
        "train_category40  = train.loc[(train['STUD_GROUP']==1) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='3.5-4.0')] \n",
        "train_category41  = train.loc[(train['STUD_GROUP']==1) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='3.0-3.5')] \n",
        "train_category42  = train.loc[(train['STUD_GROUP']==1) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='2.5-3.0')] \n",
        "train_category43  = train.loc[(train['STUD_GROUP']==1) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='2.0-2.5')] \n",
        "train_category44  = train.loc[(train['STUD_GROUP']==1) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='1.5-2.0')] \n",
        "train_category45  = train.loc[(train['STUD_GROUP']==1) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='1.0-1.5')] \n",
        "\n",
        "train_category46  = train.loc[(train['STUD_GROUP']==2) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='5.0')] \n",
        "train_category47  = train.loc[(train['STUD_GROUP']==2) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='4.5-5.0')] \n",
        "train_category48  = train.loc[(train['STUD_GROUP']==2) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='4.0-4.5')] \n",
        "train_category49  = train.loc[(train['STUD_GROUP']==2) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='3.5-4.0')] \n",
        "train_category50  = train.loc[(train['STUD_GROUP']==2) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='3.0-3.5')] \n",
        "train_category51  = train.loc[(train['STUD_GROUP']==2) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='2.5-3.0')] \n",
        "train_category52  = train.loc[(train['STUD_GROUP']==2) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='2.0-2.5')] \n",
        "train_category53  = train.loc[(train['STUD_GROUP']==2) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='1.5-2.0')] \n",
        "train_category54  = train.loc[(train['STUD_GROUP']==2) &(train['SEX']==1)& (train['SSC_GPA_CATEGORY']=='1.0-1.5')] \n",
        "train_category54.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pb-QQplcwc8",
        "outputId": "504c96eb-1c0b-45ea-c118-4adfa51caa92"
      },
      "source": [
        "test_category1  = test.loc[(test['STUD_GROUP']==0) &(test['SEX']==0)& (test['SSC_GPA_CATEGORY']=='5.0')] \n",
        "test_category2  = test.loc[(test['STUD_GROUP']==0) &(test['SEX']==0)& (test['SSC_GPA_CATEGORY']=='4.5-5.0')] \n",
        "test_category3  = test.loc[(test['STUD_GROUP']==0) &(test['SEX']==0)& (test['SSC_GPA_CATEGORY']=='4.0-4.5')] \n",
        "test_category4  = test.loc[(test['STUD_GROUP']==0) &(test['SEX']==0)& (test['SSC_GPA_CATEGORY']=='3.5-4.0')] \n",
        "test_category5  = test.loc[(test['STUD_GROUP']==0) &(test['SEX']==0)& (test['SSC_GPA_CATEGORY']=='3.0-3.5')] \n",
        "test_category6  = test.loc[(test['STUD_GROUP']==0) &(test['SEX']==0)& (test['SSC_GPA_CATEGORY']=='2.5-3.0')] \n",
        "test_category7  = test.loc[(test['STUD_GROUP']==0) &(test['SEX']==0)& (test['SSC_GPA_CATEGORY']=='2.0-2.5')] \n",
        "test_category8  = test.loc[(test['STUD_GROUP']==0) &(test['SEX']==0)& (test['SSC_GPA_CATEGORY']=='1.5-2.0')] \n",
        "test_category9  = test.loc[(test['STUD_GROUP']==0) &(test['SEX']==0)& (test['SSC_GPA_CATEGORY']=='1.0-1.5')] \n",
        "\n",
        "test_category10  = test.loc[(test['STUD_GROUP']==1) &(test['SEX']==0)& (test['SSC_GPA_CATEGORY']=='5.0')] \n",
        "test_category11  = test.loc[(test['STUD_GROUP']==1) &(test['SEX']==0)& (test['SSC_GPA_CATEGORY']=='4.5-5.0')] \n",
        "test_category12  = test.loc[(test['STUD_GROUP']==1) &(test['SEX']==0)& (test['SSC_GPA_CATEGORY']=='4.0-4.5')] \n",
        "test_category13  = test.loc[(test['STUD_GROUP']==1) &(test['SEX']==0)& (test['SSC_GPA_CATEGORY']=='3.5-4.0')] \n",
        "test_category14  = test.loc[(test['STUD_GROUP']==1) &(test['SEX']==0)& (test['SSC_GPA_CATEGORY']=='3.0-3.5')] \n",
        "test_category15  = test.loc[(test['STUD_GROUP']==1) &(test['SEX']==0)& (test['SSC_GPA_CATEGORY']=='2.5-3.0')] \n",
        "test_category16  = test.loc[(test['STUD_GROUP']==1) &(test['SEX']==0)& (test['SSC_GPA_CATEGORY']=='2.0-2.5')] \n",
        "test_category17  = test.loc[(test['STUD_GROUP']==1) &(test['SEX']==0)& (test['SSC_GPA_CATEGORY']=='1.5-2.0')] \n",
        "test_category18  = test.loc[(test['STUD_GROUP']==1) &(test['SEX']==0)& (test['SSC_GPA_CATEGORY']=='1.0-1.5')] \n",
        "\n",
        "test_category19  = test.loc[(test['STUD_GROUP']==2) &(test['SEX']==0)& (test['SSC_GPA_CATEGORY']=='5.0')] \n",
        "test_category20  = test.loc[(test['STUD_GROUP']==2) &(test['SEX']==0)& (test['SSC_GPA_CATEGORY']=='4.5-5.0')] \n",
        "test_category21  = test.loc[(test['STUD_GROUP']==2) &(test['SEX']==0)& (test['SSC_GPA_CATEGORY']=='4.0-4.5')] \n",
        "test_category22  = test.loc[(test['STUD_GROUP']==2) &(test['SEX']==0)& (test['SSC_GPA_CATEGORY']=='3.5-4.0')] \n",
        "test_category23  = test.loc[(test['STUD_GROUP']==2) &(test['SEX']==0)& (test['SSC_GPA_CATEGORY']=='3.0-3.5')] \n",
        "test_category24  = test.loc[(test['STUD_GROUP']==2) &(test['SEX']==0)& (test['SSC_GPA_CATEGORY']=='2.5-3.0')] \n",
        "test_category25  = test.loc[(test['STUD_GROUP']==2) &(test['SEX']==0)& (test['SSC_GPA_CATEGORY']=='2.0-2.5')] \n",
        "test_category26  = test.loc[(test['STUD_GROUP']==2) &(test['SEX']==0)& (test['SSC_GPA_CATEGORY']=='1.5-2.0')] \n",
        "test_category27  = test.loc[(test['STUD_GROUP']==2) &(test['SEX']==0)& (test['SSC_GPA_CATEGORY']=='1.0-1.5')] \n",
        "\n",
        "test_category28  = test.loc[(test['STUD_GROUP']==0) &(test['SEX']==1)& (test['SSC_GPA_CATEGORY']=='5.0')] \n",
        "test_category29  = test.loc[(test['STUD_GROUP']==0) &(test['SEX']==1)& (test['SSC_GPA_CATEGORY']=='4.5-5.0')] \n",
        "test_category30  = test.loc[(test['STUD_GROUP']==0) &(test['SEX']==1)& (test['SSC_GPA_CATEGORY']=='4.0-4.5')] \n",
        "test_category31  = test.loc[(test['STUD_GROUP']==0) &(test['SEX']==1)& (test['SSC_GPA_CATEGORY']=='3.5-4.0')] \n",
        "test_category32  = test.loc[(test['STUD_GROUP']==0) &(test['SEX']==1)& (test['SSC_GPA_CATEGORY']=='3.0-3.5')] \n",
        "test_category33  = test.loc[(test['STUD_GROUP']==0) &(test['SEX']==1)& (test['SSC_GPA_CATEGORY']=='2.5-3.0')] \n",
        "test_category34  = test.loc[(test['STUD_GROUP']==0) &(test['SEX']==1)& (test['SSC_GPA_CATEGORY']=='2.0-2.5')] \n",
        "test_category35  = test.loc[(test['STUD_GROUP']==0) &(test['SEX']==1)& (test['SSC_GPA_CATEGORY']=='1.5-2.0')] \n",
        "test_category36  = test.loc[(test['STUD_GROUP']==0) &(test['SEX']==1)& (test['SSC_GPA_CATEGORY']=='1.0-1.5')] \n",
        "\n",
        "test_category37  = test.loc[(test['STUD_GROUP']==1) &(test['SEX']==1)& (test['SSC_GPA_CATEGORY']=='5.0')] \n",
        "test_category38  = test.loc[(test['STUD_GROUP']==1) &(test['SEX']==1)& (test['SSC_GPA_CATEGORY']=='4.5-5.0')] \n",
        "test_category39  = test.loc[(test['STUD_GROUP']==1) &(test['SEX']==1)& (test['SSC_GPA_CATEGORY']=='4.0-4.5')] \n",
        "test_category40  = test.loc[(test['STUD_GROUP']==1) &(test['SEX']==1)& (test['SSC_GPA_CATEGORY']=='3.5-4.0')] \n",
        "test_category41  = test.loc[(test['STUD_GROUP']==1) &(test['SEX']==1)& (test['SSC_GPA_CATEGORY']=='3.0-3.5')] \n",
        "test_category42  = test.loc[(test['STUD_GROUP']==1) &(test['SEX']==1)& (test['SSC_GPA_CATEGORY']=='2.5-3.0')] \n",
        "test_category43  = test.loc[(test['STUD_GROUP']==1) &(test['SEX']==1)& (test['SSC_GPA_CATEGORY']=='2.0-2.5')] \n",
        "test_category44  = test.loc[(test['STUD_GROUP']==1) &(test['SEX']==1)& (test['SSC_GPA_CATEGORY']=='1.5-2.0')] \n",
        "test_category45  = test.loc[(test['STUD_GROUP']==1) &(test['SEX']==1)& (test['SSC_GPA_CATEGORY']=='1.0-1.5')] \n",
        "\n",
        "test_category46  = test.loc[(test['STUD_GROUP']==2) &(test['SEX']==1)& (test['SSC_GPA_CATEGORY']=='5.0')] \n",
        "test_category47  = test.loc[(test['STUD_GROUP']==2) &(test['SEX']==1)& (test['SSC_GPA_CATEGORY']=='4.5-5.0')] \n",
        "test_category48  = test.loc[(test['STUD_GROUP']==2) &(test['SEX']==1)& (test['SSC_GPA_CATEGORY']=='4.0-4.5')] \n",
        "test_category49  = test.loc[(test['STUD_GROUP']==2) &(test['SEX']==1)& (test['SSC_GPA_CATEGORY']=='3.5-4.0')] \n",
        "test_category50  = test.loc[(test['STUD_GROUP']==2) &(test['SEX']==1)& (test['SSC_GPA_CATEGORY']=='3.0-3.5')] \n",
        "test_category51  = test.loc[(test['STUD_GROUP']==2) &(test['SEX']==1)& (test['SSC_GPA_CATEGORY']=='2.5-3.0')] \n",
        "test_category52  = test.loc[(test['STUD_GROUP']==2) &(test['SEX']==1)& (test['SSC_GPA_CATEGORY']=='2.0-2.5')] \n",
        "test_category53  = test.loc[(test['STUD_GROUP']==2) &(test['SEX']==1)& (test['SSC_GPA_CATEGORY']=='1.5-2.0')] \n",
        "test_category54  = test.loc[(test['STUD_GROUP']==2) &(test['SEX']==1)& (test['SSC_GPA_CATEGORY']=='1.0-1.5')] \n",
        "test_category27.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCi5skZ-1KGI"
      },
      "source": [
        "for i in range(1,1):\n",
        "  print(\"train_category\"+str(i)+\"['CATEGORY']=\"+str(i))\n",
        "  \n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTdPRaMO1hEq",
        "outputId": "95f4bd36-f345-4413-b2d9-3ba26de64ded"
      },
      "source": [
        "for i in range(1,2):\n",
        "    print(\"test_category\"+str(i)+\"['CATEGORY']=\"+str(i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_category1['CATEGORY']=1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bguVmRSdlx6",
        "outputId": "2d9077b8-9fed-4569-e702-a2560e0441a0"
      },
      "source": [
        "train_category1['CATEGORY']=1\n",
        "train_category2['CATEGORY']=2\n",
        "train_category3['CATEGORY']=3\n",
        "train_category4['CATEGORY']=4\n",
        "train_category5['CATEGORY']=5\n",
        "train_category6['CATEGORY']=6\n",
        "train_category7['CATEGORY']=7\n",
        "train_category8['CATEGORY']=8\n",
        "train_category9['CATEGORY']=9\n",
        "train_category10['CATEGORY']=10\n",
        "train_category11['CATEGORY']=11\n",
        "train_category12['CATEGORY']=12\n",
        "train_category13['CATEGORY']=13\n",
        "train_category14['CATEGORY']=14\n",
        "train_category15['CATEGORY']=15\n",
        "train_category16['CATEGORY']=16\n",
        "train_category17['CATEGORY']=17\n",
        "train_category18['CATEGORY']=18\n",
        "train_category19['CATEGORY']=19\n",
        "train_category20['CATEGORY']=20\n",
        "train_category21['CATEGORY']=21\n",
        "train_category22['CATEGORY']=22\n",
        "train_category23['CATEGORY']=23\n",
        "train_category24['CATEGORY']=24\n",
        "train_category25['CATEGORY']=25\n",
        "train_category26['CATEGORY']=26\n",
        "train_category27['CATEGORY']=27\n",
        "train_category28['CATEGORY']=28\n",
        "train_category29['CATEGORY']=29\n",
        "train_category30['CATEGORY']=30\n",
        "train_category31['CATEGORY']=31\n",
        "train_category32['CATEGORY']=32\n",
        "train_category33['CATEGORY']=33\n",
        "train_category34['CATEGORY']=34\n",
        "train_category35['CATEGORY']=35\n",
        "train_category36['CATEGORY']=36\n",
        "train_category37['CATEGORY']=37\n",
        "train_category38['CATEGORY']=38\n",
        "train_category39['CATEGORY']=39\n",
        "train_category40['CATEGORY']=40\n",
        "train_category41['CATEGORY']=41\n",
        "train_category42['CATEGORY']=42\n",
        "train_category43['CATEGORY']=43\n",
        "train_category44['CATEGORY']=44\n",
        "train_category45['CATEGORY']=45\n",
        "train_category46['CATEGORY']=46\n",
        "train_category47['CATEGORY']=47\n",
        "train_category48['CATEGORY']=48\n",
        "train_category49['CATEGORY']=49\n",
        "train_category50['CATEGORY']=50\n",
        "train_category51['CATEGORY']=51\n",
        "train_category52['CATEGORY']=52\n",
        "train_category53['CATEGORY']=53\n",
        "train_category54['CATEGORY']=54"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bqeYLLJIvL1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53b78ddc-1e1c-4406-ebcd-5b46c4fcd1b0"
      },
      "source": [
        "test_category1['CATEGORY']=1\n",
        "test_category2['CATEGORY']=2\n",
        "test_category3['CATEGORY']=3\n",
        "test_category4['CATEGORY']=4\n",
        "test_category5['CATEGORY']=5\n",
        "test_category6['CATEGORY']=6\n",
        "test_category7['CATEGORY']=7\n",
        "test_category8['CATEGORY']=8\n",
        "test_category9['CATEGORY']=9\n",
        "test_category10['CATEGORY']=10\n",
        "test_category11['CATEGORY']=11\n",
        "test_category12['CATEGORY']=12\n",
        "test_category13['CATEGORY']=13\n",
        "test_category14['CATEGORY']=14\n",
        "test_category15['CATEGORY']=15\n",
        "test_category16['CATEGORY']=16\n",
        "test_category17['CATEGORY']=17\n",
        "test_category18['CATEGORY']=18\n",
        "test_category19['CATEGORY']=19\n",
        "test_category20['CATEGORY']=20\n",
        "test_category21['CATEGORY']=21\n",
        "test_category22['CATEGORY']=22\n",
        "test_category23['CATEGORY']=23\n",
        "test_category24['CATEGORY']=24\n",
        "test_category25['CATEGORY']=25\n",
        "test_category26['CATEGORY']=26\n",
        "test_category27['CATEGORY']=27\n",
        "test_category28['CATEGORY']=28\n",
        "test_category29['CATEGORY']=29\n",
        "test_category30['CATEGORY']=30\n",
        "test_category31['CATEGORY']=31\n",
        "test_category32['CATEGORY']=32\n",
        "test_category33['CATEGORY']=33\n",
        "test_category34['CATEGORY']=34\n",
        "test_category35['CATEGORY']=35\n",
        "test_category36['CATEGORY']=36\n",
        "test_category37['CATEGORY']=37\n",
        "test_category38['CATEGORY']=38\n",
        "test_category39['CATEGORY']=39\n",
        "test_category40['CATEGORY']=40\n",
        "test_category41['CATEGORY']=41\n",
        "test_category42['CATEGORY']=42\n",
        "test_category43['CATEGORY']=43\n",
        "test_category44['CATEGORY']=44\n",
        "test_category45['CATEGORY']=45\n",
        "test_category46['CATEGORY']=46\n",
        "test_category47['CATEGORY']=47\n",
        "test_category48['CATEGORY']=48\n",
        "test_category49['CATEGORY']=49\n",
        "test_category50['CATEGORY']=50\n",
        "test_category51['CATEGORY']=51\n",
        "test_category52['CATEGORY']=52\n",
        "test_category53['CATEGORY']=53\n",
        "test_category54['CATEGORY']=54"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpYqVGGJ_QPB",
        "outputId": "268b6552-0dc3-4b7b-beb2-7125b37c4fa0"
      },
      "source": [
        "for i in range(43,55):\n",
        "    print(\"test_category\"+str(i)+\",\",end=\" \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_category43, test_category44, test_category45, test_category46, test_category47, test_category48, test_category49, test_category50, test_category51, test_category52, test_category53, test_category54, "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvIfW9zm2ed9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac7d09da-7ce2-4380-cd13-dcbd7c5f6cda"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80996, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCBHoPyH2b7r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0334d7e-9541-4192-8bf6-89cb86827174"
      },
      "source": [
        "test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48939, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn-DPXFK2ZOV",
        "outputId": "901ce698-d107-4db8-e504-2b9404b80a08"
      },
      "source": [
        "train_cate_frame =[train_category1, train_category2, train_category3, train_category4, train_category5, train_category6, train_category7, train_category8, train_category9, train_category10, train_category11, train_category12, train_category13, train_category14, train_category15, train_category16, train_category17, train_category18, train_category19, train_category20, train_category21, train_category22, train_category23, train_category24, train_category25, train_category26, train_category27, train_category28, train_category29, train_category30, train_category31, train_category32, train_category33, train_category34, train_category35, train_category36, train_category37, train_category38, train_category39, train_category40, train_category41, train_category42,train_category43, train_category44, train_category45, train_category46, train_category47, train_category48, train_category49, train_category50, train_category51, train_category52, train_category53, train_category54]\n",
        "merge_cate_train =pd.concat(train_cate_frame)\n",
        "merge_cate_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80996, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ghi06UW0d3p",
        "outputId": "54c63614-a194-4368-b949-1b349ff778b7"
      },
      "source": [
        "test_cate_frame = [test_category1, test_category2, test_category3, test_category4, test_category5, test_category6, test_category7, test_category8, test_category9, test_category10, test_category11, test_category12, test_category13, test_category14, test_category15, test_category16, test_category17, test_category18, test_category19, test_category20, test_category21, test_category22, test_category23, test_category24, test_category25, test_category26, test_category27, test_category28, test_category29, test_category30, test_category31, test_category32, test_category33, test_category34, test_category35, test_category36, test_category37, test_category38, test_category39, test_category40, test_category41, test_category42,test_category43, test_category44, test_category45, test_category46, test_category47, test_category48, test_category49, test_category50, test_category51, test_category52, test_category53, test_category54]\n",
        "merge_cate_test =pd.concat(test_cate_frame)\n",
        "merge_cate_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48939, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFuT1RyJ_ztf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f80d0221-9309-4407-9689-538857cd76fb"
      },
      "source": [
        "cat1 = merge_cate_train['CATEGORY'].value_counts()\n",
        "cat1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41    9700\n",
              "42    7685\n",
              "40    7435\n",
              "14    6774\n",
              "13    5631\n",
              "15    4526\n",
              "39    3762\n",
              "43    3438\n",
              "12    2890\n",
              "3     2281\n",
              "2     2213\n",
              "1     2136\n",
              "30    1989\n",
              "29    1899\n",
              "16    1771\n",
              "4     1538\n",
              "28    1433\n",
              "38    1378\n",
              "31    1307\n",
              "22    1173\n",
              "21    1035\n",
              "11     934\n",
              "23     925\n",
              "44     687\n",
              "5      648\n",
              "48     635\n",
              "49     633\n",
              "32     619\n",
              "20     616\n",
              "50     488\n",
              "24     444\n",
              "47     376\n",
              "17     319\n",
              "51     252\n",
              "6      215\n",
              "19     199\n",
              "37     195\n",
              "33     189\n",
              "25     150\n",
              "46     138\n",
              "10     117\n",
              "52      74\n",
              "45      35\n",
              "34      35\n",
              "7       35\n",
              "26      14\n",
              "18      12\n",
              "53      11\n",
              "27       3\n",
              "8        2\n",
              "35       2\n",
              "Name: CATEGORY, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnzqNHGs__Up",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "e6bf25e7-b194-41e9-c66a-924da7e5677f"
      },
      "source": [
        "cat1.plot(kind='bar',stacked=True, figsize=(15,7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7b5a24d110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmDqZQgbJk8m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "outputId": "ed63ccdb-3800-49ec-d580-fa4faed3cb57"
      },
      "source": [
        "cat1.plot(kind='pie', stacked=True, figsize=(15,10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7b5a108890>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhZ9vcrjADjZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE8ULFrEAJXo"
      },
      "source": [
        "**Deviation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbQa-P6R_WWJ"
      },
      "source": [
        "for number in range(1,1) :  \n",
        "    print( \n",
        "        \"train_count\"+str(number),\"=\",\"train_category\"+str(number)+\"['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1')\",\"\\n\"+\n",
        "        \"train_gpa\"+str(number),\"=\" ,\"train_category\"+str(number)+\".groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean()\",\"\\n\"+\n",
        "\"train_gpa\"+str(number), \"=\",\"train_gpa\"+str(number)+\".reset_index()\",\"\\n\"+\n",
        "\"train_hsc\"+str(number),\"=\",\"pd.merge(train_count\"+str(number)+\",\"+\"train_gpa\"+str(number)+\")\",\"\\n\"+\n",
        "\"train_hsc\"+str(number),\"=\",\"train_hsc\"+str(number)+\".loc[(train_hsc\"+str(number),\"['Number of students in training year']>=40)]\",\"\\n\"+\n",
        "\"train_hsc\"+str(number)+\"['Deviation of training year'] = train_hsc\"+str(number),\"['GPA.1'] - train_hsc\"+str(number)+\"['GPA']\",\"\\n\"+\n",
        "          \n",
        "\"train_hsc\"+str(number),\"=\",\"pd.concat([train_hsc\"+str(number)+\"[train_hsc\"+str(number),\"['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False),\",\"\\n\"+\n",
        "                              \"train_hsc\"+str(number)+\"[train_hsc\"+str(number)+\"['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)])\",\"\\n\"+\n",
        "\"train_hsc\"+str(number), \"=\",\"train_hsc\"+str(number)+\".reset_index()\",\"\\n\"+\n",
        "\"features_drop\"+str(number), \"=\",\"['GPA','GPA.1','index','Number of students in training year']\",\"\\n\"+          \n",
        "\"train_hsc\"+str(number), \"=\",\"train_hsc\"+str(number)+\".drop(features_drop\"+str(number),\",axis=1)\",\"\\n\"+\n",
        "\"train_hsc\"+str(number)+\".head()\",\"\\n\")        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogXup-Pr_cKA"
      },
      "source": [
        "for number in range(1,1) :  \n",
        "    print(\"test_count\"+str(number),\"=\",\"test_category\"+str(number)+\"['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1')\",\"\\n\"+\n",
        "\"test_gpa\"+str(number),\"=\" ,\"test_category\"+str(number)+\".groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean()\",\"\\n\"+      \n",
        "\"test_gpa\"+str(number), \"=\",\"test_gpa\"+str(number)+\".reset_index()\",\"\\n\"+\n",
        "          \n",
        "\"test_hsc\"+str(number),\"=\",\"pd.merge(test_count\"+str(number)+\",\"+\"test_gpa\"+str(number)+\")\",\"\\n\"+\n",
        "\"test_hsc\"+str(number),\"=\",\"test_hsc\"+str(number)+\".loc[(test_hsc\"+str(number),\"['Number of students in testing year']>=20)]\",\"\\n\"+\n",
        "\n",
        "\"test_hsc\"+str(number)+\"['Deviation of testing year'] = test_hsc\"+str(number)+\"['GPA.1'] - test_hsc\"+str(number)+\"['GPA']\",\"\\n\"+\n",
        "          \n",
        "\"test_hsc\"+str(number),\"=\",\"pd.concat([test_hsc\"+str(number)+\"[test_hsc\"+str(number),\"['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False),\",\"\\n\"+\n",
        "                              \"test_hsc\"+str(number)+\"[test_hsc\"+str(number)+\"['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)])\",\"\\n\"+\n",
        "\"test_hsc\"+str(number), \"=\",\"test_hsc\"+str(number)+\".reset_index()\",\"\\n\"+\n",
        "\"features_drop\"+str(number), \"=\",\"['GPA','GPA.1','index','Number of students in testing year']\",\"\\n\"+          \n",
        "\"test_hsc\"+str(number), \"=\",\"test_hsc\"+str(number)+\".drop(features_drop\"+str(number),\",axis=1)\",\"\\n\"+\n",
        "\"test_hsc\"+str(number)+\".head()\",\"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "id": "6lTKW_LsebDc",
        "outputId": "b721fa1f-8f81-441b-c866-5d0f5048a285"
      },
      "source": [
        "train_count1 = train_category1['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa1 = train_category1.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa1 = train_gpa1.reset_index() \n",
        "train_hsc1 = pd.merge(train_count1,train_gpa1) \n",
        "train_hsc1 = train_hsc1.loc[(train_hsc1 ['Number of students in training year']>=40)] \n",
        "train_hsc1['Deviation of training year'] = train_hsc1 ['GPA.1'] - train_hsc1['GPA'] \n",
        "train_hsc1 = pd.concat([train_hsc1[train_hsc1 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc1[train_hsc1['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc1 = train_hsc1.reset_index() \n",
        "features_drop1 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc1 = train_hsc1.drop(features_drop1 ,axis=1) \n",
        "train_hsc1.head() \n",
        "\n",
        "train_count2 = train_category2['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa2 = train_category2.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa2 = train_gpa2.reset_index() \n",
        "train_hsc2 = pd.merge(train_count2,train_gpa2) \n",
        "train_hsc2 = train_hsc2.loc[(train_hsc2 ['Number of students in training year']>=40)] \n",
        "train_hsc2['Deviation of training year'] = train_hsc2 ['GPA.1'] - train_hsc2['GPA'] \n",
        "train_hsc2 = pd.concat([train_hsc2[train_hsc2 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc2[train_hsc2['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc2 = train_hsc2.reset_index() \n",
        "features_drop2 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc2 = train_hsc2.drop(features_drop2 ,axis=1) \n",
        "train_hsc2.head() \n",
        "\n",
        "train_count3 = train_category3['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa3 = train_category3.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa3 = train_gpa3.reset_index() \n",
        "train_hsc3 = pd.merge(train_count3,train_gpa3) \n",
        "train_hsc3 = train_hsc3.loc[(train_hsc3 ['Number of students in training year']>=40)] \n",
        "train_hsc3['Deviation of training year'] = train_hsc3 ['GPA.1'] - train_hsc3['GPA'] \n",
        "train_hsc3 = pd.concat([train_hsc3[train_hsc3 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc3[train_hsc3['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc3 = train_hsc3.reset_index() \n",
        "features_drop3 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc3 = train_hsc3.drop(features_drop3 ,axis=1) \n",
        "train_hsc3.head() \n",
        "\n",
        "train_count4 = train_category4['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa4 = train_category4.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa4 = train_gpa4.reset_index() \n",
        "train_hsc4 = pd.merge(train_count4,train_gpa4) \n",
        "train_hsc4 = train_hsc4.loc[(train_hsc4 ['Number of students in training year']>=40)] \n",
        "train_hsc4['Deviation of training year'] = train_hsc4 ['GPA.1'] - train_hsc4['GPA'] \n",
        "train_hsc4 = pd.concat([train_hsc4[train_hsc4 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc4[train_hsc4['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc4 = train_hsc4.reset_index() \n",
        "features_drop4 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc4 = train_hsc4.drop(features_drop4 ,axis=1) \n",
        "train_hsc4.head() \n",
        "\n",
        "train_count5 = train_category5['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa5 = train_category5.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa5 = train_gpa5.reset_index() \n",
        "train_hsc5 = pd.merge(train_count5,train_gpa5) \n",
        "train_hsc5 = train_hsc5.loc[(train_hsc5 ['Number of students in training year']>=40)] \n",
        "train_hsc5['Deviation of training year'] = train_hsc5 ['GPA.1'] - train_hsc5['GPA'] \n",
        "train_hsc5 = pd.concat([train_hsc5[train_hsc5 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc5[train_hsc5['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc5 = train_hsc5.reset_index() \n",
        "features_drop5 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc5 = train_hsc5.drop(features_drop5 ,axis=1) \n",
        "train_hsc5.head() \n",
        "\n",
        "train_count6 = train_category6['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa6 = train_category6.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa6 = train_gpa6.reset_index() \n",
        "train_hsc6 = pd.merge(train_count6,train_gpa6) \n",
        "train_hsc6 = train_hsc6.loc[(train_hsc6 ['Number of students in training year']>=40)] \n",
        "train_hsc6['Deviation of training year'] = train_hsc6 ['GPA.1'] - train_hsc6['GPA'] \n",
        "train_hsc6 = pd.concat([train_hsc6[train_hsc6 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc6[train_hsc6['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc6 = train_hsc6.reset_index() \n",
        "features_drop6 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc6 = train_hsc6.drop(features_drop6 ,axis=1) \n",
        "train_hsc6.head() \n",
        "\n",
        "train_count7 = train_category7['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa7 = train_category7.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa7 = train_gpa7.reset_index() \n",
        "train_hsc7 = pd.merge(train_count7,train_gpa7) \n",
        "train_hsc7 = train_hsc7.loc[(train_hsc7 ['Number of students in training year']>=40)] \n",
        "train_hsc7['Deviation of training year'] = train_hsc7 ['GPA.1'] - train_hsc7['GPA'] \n",
        "train_hsc7 = pd.concat([train_hsc7[train_hsc7 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc7[train_hsc7['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc7 = train_hsc7.reset_index() \n",
        "features_drop7 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc7 = train_hsc7.drop(features_drop7 ,axis=1) \n",
        "train_hsc7.head() \n",
        "\n",
        "train_count8 = train_category8['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa8 = train_category8.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa8 = train_gpa8.reset_index() \n",
        "train_hsc8 = pd.merge(train_count8,train_gpa8) \n",
        "train_hsc8 = train_hsc8.loc[(train_hsc8 ['Number of students in training year']>=40)] \n",
        "train_hsc8['Deviation of training year'] = train_hsc8 ['GPA.1'] - train_hsc8['GPA'] \n",
        "train_hsc8 = pd.concat([train_hsc8[train_hsc8 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc8[train_hsc8['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc8 = train_hsc8.reset_index() \n",
        "features_drop8 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc8 = train_hsc8.drop(features_drop8 ,axis=1) \n",
        "train_hsc8.head() \n",
        "\n",
        "train_count9 = train_category9['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa9 = train_category9.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa9 = train_gpa9.reset_index() \n",
        "train_hsc9 = pd.merge(train_count9,train_gpa9) \n",
        "train_hsc9 = train_hsc9.loc[(train_hsc9 ['Number of students in training year']>=40)] \n",
        "train_hsc9['Deviation of training year'] = train_hsc9 ['GPA.1'] - train_hsc9['GPA'] \n",
        "train_hsc9 = pd.concat([train_hsc9[train_hsc9 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc9[train_hsc9['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc9 = train_hsc9.reset_index() \n",
        "features_drop9 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc9 = train_hsc9.drop(features_drop9 ,axis=1) \n",
        "train_hsc9.head() \n",
        "\n",
        "train_count10 = train_category10['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa10 = train_category10.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa10 = train_gpa10.reset_index() \n",
        "train_hsc10 = pd.merge(train_count10,train_gpa10) \n",
        "train_hsc10 = train_hsc10.loc[(train_hsc10 ['Number of students in training year']>=40)] \n",
        "train_hsc10['Deviation of training year'] = train_hsc10 ['GPA.1'] - train_hsc10['GPA'] \n",
        "train_hsc10 = pd.concat([train_hsc10[train_hsc10 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc10[train_hsc10['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc10 = train_hsc10.reset_index() \n",
        "features_drop10 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc10 = train_hsc10.drop(features_drop10 ,axis=1) \n",
        "train_hsc10.head() \n",
        "\n",
        "train_count11 = train_category11['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa11 = train_category11.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa11 = train_gpa11.reset_index() \n",
        "train_hsc11 = pd.merge(train_count11,train_gpa11) \n",
        "train_hsc11 = train_hsc11.loc[(train_hsc11 ['Number of students in training year']>=40)] \n",
        "train_hsc11['Deviation of training year'] = train_hsc11 ['GPA.1'] - train_hsc11['GPA'] \n",
        "train_hsc11 = pd.concat([train_hsc11[train_hsc11 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc11[train_hsc11['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc11 = train_hsc11.reset_index() \n",
        "features_drop11 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc11 = train_hsc11.drop(features_drop11 ,axis=1) \n",
        "train_hsc11.head() \n",
        "\n",
        "train_count12 = train_category12['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa12 = train_category12.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa12 = train_gpa12.reset_index() \n",
        "train_hsc12 = pd.merge(train_count12,train_gpa12) \n",
        "train_hsc12 = train_hsc12.loc[(train_hsc12 ['Number of students in training year']>=40)] \n",
        "train_hsc12['Deviation of training year'] = train_hsc12 ['GPA.1'] - train_hsc12['GPA'] \n",
        "train_hsc12 = pd.concat([train_hsc12[train_hsc12 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc12[train_hsc12['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc12 = train_hsc12.reset_index() \n",
        "features_drop12 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc12 = train_hsc12.drop(features_drop12 ,axis=1) \n",
        "train_hsc12.head() \n",
        "\n",
        "train_count13 = train_category13['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa13 = train_category13.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa13 = train_gpa13.reset_index() \n",
        "train_hsc13 = pd.merge(train_count13,train_gpa13) \n",
        "train_hsc13 = train_hsc13.loc[(train_hsc13 ['Number of students in training year']>=40)] \n",
        "train_hsc13['Deviation of training year'] = train_hsc13 ['GPA.1'] - train_hsc13['GPA'] \n",
        "train_hsc13 = pd.concat([train_hsc13[train_hsc13 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc13[train_hsc13['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc13 = train_hsc13.reset_index() \n",
        "features_drop13 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc13 = train_hsc13.drop(features_drop13 ,axis=1) \n",
        "train_hsc13.head() \n",
        "\n",
        "train_count14 = train_category14['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa14 = train_category14.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa14 = train_gpa14.reset_index() \n",
        "train_hsc14 = pd.merge(train_count14,train_gpa14) \n",
        "train_hsc14 = train_hsc14.loc[(train_hsc14 ['Number of students in training year']>=40)] \n",
        "train_hsc14['Deviation of training year'] = train_hsc14 ['GPA.1'] - train_hsc14['GPA'] \n",
        "train_hsc14 = pd.concat([train_hsc14[train_hsc14 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc14[train_hsc14['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc14 = train_hsc14.reset_index() \n",
        "features_drop14 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc14 = train_hsc14.drop(features_drop14 ,axis=1) \n",
        "train_hsc14.head() \n",
        "\n",
        "train_count15 = train_category15['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa15 = train_category15.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa15 = train_gpa15.reset_index() \n",
        "train_hsc15 = pd.merge(train_count15,train_gpa15) \n",
        "train_hsc15 = train_hsc15.loc[(train_hsc15 ['Number of students in training year']>=40)] \n",
        "train_hsc15['Deviation of training year'] = train_hsc15 ['GPA.1'] - train_hsc15['GPA'] \n",
        "train_hsc15 = pd.concat([train_hsc15[train_hsc15 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc15[train_hsc15['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc15 = train_hsc15.reset_index() \n",
        "features_drop15 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc15 = train_hsc15.drop(features_drop15 ,axis=1) \n",
        "train_hsc15.head() \n",
        "\n",
        "train_count16 = train_category16['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa16 = train_category16.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa16 = train_gpa16.reset_index() \n",
        "train_hsc16 = pd.merge(train_count16,train_gpa16) \n",
        "train_hsc16 = train_hsc16.loc[(train_hsc16 ['Number of students in training year']>=40)] \n",
        "train_hsc16['Deviation of training year'] = train_hsc16 ['GPA.1'] - train_hsc16['GPA'] \n",
        "train_hsc16 = pd.concat([train_hsc16[train_hsc16 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc16[train_hsc16['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc16 = train_hsc16.reset_index() \n",
        "features_drop16 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc16 = train_hsc16.drop(features_drop16 ,axis=1) \n",
        "train_hsc16.head() \n",
        "\n",
        "train_count17 = train_category17['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa17 = train_category17.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa17 = train_gpa17.reset_index() \n",
        "train_hsc17 = pd.merge(train_count17,train_gpa17) \n",
        "train_hsc17 = train_hsc17.loc[(train_hsc17 ['Number of students in training year']>=40)] \n",
        "train_hsc17['Deviation of training year'] = train_hsc17 ['GPA.1'] - train_hsc17['GPA'] \n",
        "train_hsc17 = pd.concat([train_hsc17[train_hsc17 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc17[train_hsc17['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc17 = train_hsc17.reset_index() \n",
        "features_drop17 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc17 = train_hsc17.drop(features_drop17 ,axis=1) \n",
        "train_hsc17.head() \n",
        "\n",
        "train_count18 = train_category18['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa18 = train_category18.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa18 = train_gpa18.reset_index() \n",
        "train_hsc18 = pd.merge(train_count18,train_gpa18) \n",
        "train_hsc18 = train_hsc18.loc[(train_hsc18 ['Number of students in training year']>=40)] \n",
        "train_hsc18['Deviation of training year'] = train_hsc18 ['GPA.1'] - train_hsc18['GPA'] \n",
        "train_hsc18 = pd.concat([train_hsc18[train_hsc18 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc18[train_hsc18['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc18 = train_hsc18.reset_index() \n",
        "features_drop18 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc18 = train_hsc18.drop(features_drop18 ,axis=1) \n",
        "train_hsc18.head() \n",
        "\n",
        "train_count19 = train_category19['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa19 = train_category19.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa19 = train_gpa19.reset_index() \n",
        "train_hsc19 = pd.merge(train_count19,train_gpa19) \n",
        "train_hsc19 = train_hsc19.loc[(train_hsc19 ['Number of students in training year']>=40)] \n",
        "train_hsc19['Deviation of training year'] = train_hsc19 ['GPA.1'] - train_hsc19['GPA'] \n",
        "train_hsc19 = pd.concat([train_hsc19[train_hsc19 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc19[train_hsc19['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc19 = train_hsc19.reset_index() \n",
        "features_drop19 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc19 = train_hsc19.drop(features_drop19 ,axis=1) \n",
        "train_hsc19.head() \n",
        "\n",
        "train_count20 = train_category20['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa20 = train_category20.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa20 = train_gpa20.reset_index() \n",
        "train_hsc20 = pd.merge(train_count20,train_gpa20) \n",
        "train_hsc20 = train_hsc20.loc[(train_hsc20 ['Number of students in training year']>=40)] \n",
        "train_hsc20['Deviation of training year'] = train_hsc20 ['GPA.1'] - train_hsc20['GPA'] \n",
        "train_hsc20 = pd.concat([train_hsc20[train_hsc20 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc20[train_hsc20['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc20 = train_hsc20.reset_index() \n",
        "features_drop20 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc20 = train_hsc20.drop(features_drop20 ,axis=1) \n",
        "train_hsc20.head() \n",
        "\n",
        "train_count21 = train_category21['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa21 = train_category21.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa21 = train_gpa21.reset_index() \n",
        "train_hsc21 = pd.merge(train_count21,train_gpa21) \n",
        "train_hsc21 = train_hsc21.loc[(train_hsc21 ['Number of students in training year']>=40)] \n",
        "train_hsc21['Deviation of training year'] = train_hsc21 ['GPA.1'] - train_hsc21['GPA'] \n",
        "train_hsc21 = pd.concat([train_hsc21[train_hsc21 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc21[train_hsc21['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc21 = train_hsc21.reset_index() \n",
        "features_drop21 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc21 = train_hsc21.drop(features_drop21 ,axis=1) \n",
        "train_hsc21.head() \n",
        "\n",
        "train_count22 = train_category22['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa22 = train_category22.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa22 = train_gpa22.reset_index() \n",
        "train_hsc22 = pd.merge(train_count22,train_gpa22) \n",
        "train_hsc22 = train_hsc22.loc[(train_hsc22 ['Number of students in training year']>=40)] \n",
        "train_hsc22['Deviation of training year'] = train_hsc22 ['GPA.1'] - train_hsc22['GPA'] \n",
        "train_hsc22 = pd.concat([train_hsc22[train_hsc22 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc22[train_hsc22['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc22 = train_hsc22.reset_index() \n",
        "features_drop22 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc22 = train_hsc22.drop(features_drop22 ,axis=1) \n",
        "train_hsc22.head() \n",
        "\n",
        "train_count23 = train_category23['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa23 = train_category23.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa23 = train_gpa23.reset_index() \n",
        "train_hsc23 = pd.merge(train_count23,train_gpa23) \n",
        "train_hsc23 = train_hsc23.loc[(train_hsc23 ['Number of students in training year']>=40)] \n",
        "train_hsc23['Deviation of training year'] = train_hsc23 ['GPA.1'] - train_hsc23['GPA'] \n",
        "train_hsc23 = pd.concat([train_hsc23[train_hsc23 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc23[train_hsc23['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc23 = train_hsc23.reset_index() \n",
        "features_drop23 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc23 = train_hsc23.drop(features_drop23 ,axis=1) \n",
        "train_hsc23.head() \n",
        "\n",
        "train_count24 = train_category24['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa24 = train_category24.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa24 = train_gpa24.reset_index() \n",
        "train_hsc24 = pd.merge(train_count24,train_gpa24) \n",
        "train_hsc24 = train_hsc24.loc[(train_hsc24 ['Number of students in training year']>=40)] \n",
        "train_hsc24['Deviation of training year'] = train_hsc24 ['GPA.1'] - train_hsc24['GPA'] \n",
        "train_hsc24 = pd.concat([train_hsc24[train_hsc24 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc24[train_hsc24['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc24 = train_hsc24.reset_index() \n",
        "features_drop24 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc24 = train_hsc24.drop(features_drop24 ,axis=1) \n",
        "train_hsc24.head() \n",
        "\n",
        "train_count25 = train_category25['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa25 = train_category25.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa25 = train_gpa25.reset_index() \n",
        "train_hsc25 = pd.merge(train_count25,train_gpa25) \n",
        "train_hsc25 = train_hsc25.loc[(train_hsc25 ['Number of students in training year']>=40)] \n",
        "train_hsc25['Deviation of training year'] = train_hsc25 ['GPA.1'] - train_hsc25['GPA'] \n",
        "train_hsc25 = pd.concat([train_hsc25[train_hsc25 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc25[train_hsc25['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc25 = train_hsc25.reset_index() \n",
        "features_drop25 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc25 = train_hsc25.drop(features_drop25 ,axis=1) \n",
        "train_hsc25.head() \n",
        "\n",
        "train_count26 = train_category26['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa26 = train_category26.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa26 = train_gpa26.reset_index() \n",
        "train_hsc26 = pd.merge(train_count26,train_gpa26) \n",
        "train_hsc26 = train_hsc26.loc[(train_hsc26 ['Number of students in training year']>=40)] \n",
        "train_hsc26['Deviation of training year'] = train_hsc26 ['GPA.1'] - train_hsc26['GPA'] \n",
        "train_hsc26 = pd.concat([train_hsc26[train_hsc26 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc26[train_hsc26['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc26 = train_hsc26.reset_index() \n",
        "features_drop26 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc26 = train_hsc26.drop(features_drop26 ,axis=1) \n",
        "train_hsc26.head() \n",
        "\n",
        "train_count27 = train_category27['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa27 = train_category27.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa27 = train_gpa27.reset_index() \n",
        "train_hsc27 = pd.merge(train_count27,train_gpa27) \n",
        "train_hsc27 = train_hsc27.loc[(train_hsc27 ['Number of students in training year']>=40)] \n",
        "train_hsc27['Deviation of training year'] = train_hsc27 ['GPA.1'] - train_hsc27['GPA'] \n",
        "train_hsc27 = pd.concat([train_hsc27[train_hsc27 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc27[train_hsc27['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc27 = train_hsc27.reset_index() \n",
        "features_drop27 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc27 = train_hsc27.drop(features_drop27 ,axis=1) \n",
        "train_hsc27.head() \n",
        "\n",
        "train_count28 = train_category28['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa28 = train_category28.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa28 = train_gpa28.reset_index() \n",
        "train_hsc28 = pd.merge(train_count28,train_gpa28) \n",
        "train_hsc28 = train_hsc28.loc[(train_hsc28 ['Number of students in training year']>=40)] \n",
        "train_hsc28['Deviation of training year'] = train_hsc28 ['GPA.1'] - train_hsc28['GPA'] \n",
        "train_hsc28 = pd.concat([train_hsc28[train_hsc28 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc28[train_hsc28['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc28 = train_hsc28.reset_index() \n",
        "features_drop28 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc28 = train_hsc28.drop(features_drop28 ,axis=1) \n",
        "train_hsc28.head() \n",
        "\n",
        "train_count29 = train_category29['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa29 = train_category29.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa29 = train_gpa29.reset_index() \n",
        "train_hsc29 = pd.merge(train_count29,train_gpa29) \n",
        "train_hsc29 = train_hsc29.loc[(train_hsc29 ['Number of students in training year']>=40)] \n",
        "train_hsc29['Deviation of training year'] = train_hsc29 ['GPA.1'] - train_hsc29['GPA'] \n",
        "train_hsc29 = pd.concat([train_hsc29[train_hsc29 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc29[train_hsc29['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc29 = train_hsc29.reset_index() \n",
        "features_drop29 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc29 = train_hsc29.drop(features_drop29 ,axis=1) \n",
        "train_hsc29.head() \n",
        "\n",
        "train_count30 = train_category30['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa30 = train_category30.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa30 = train_gpa30.reset_index() \n",
        "train_hsc30 = pd.merge(train_count30,train_gpa30) \n",
        "train_hsc30 = train_hsc30.loc[(train_hsc30 ['Number of students in training year']>=40)] \n",
        "train_hsc30['Deviation of training year'] = train_hsc30 ['GPA.1'] - train_hsc30['GPA'] \n",
        "train_hsc30 = pd.concat([train_hsc30[train_hsc30 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc30[train_hsc30['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc30 = train_hsc30.reset_index() \n",
        "features_drop30 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc30 = train_hsc30.drop(features_drop30 ,axis=1) \n",
        "train_hsc30.head() \n",
        "\n",
        "train_count31 = train_category31['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa31 = train_category31.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa31 = train_gpa31.reset_index() \n",
        "train_hsc31 = pd.merge(train_count31,train_gpa31) \n",
        "train_hsc31 = train_hsc31.loc[(train_hsc31 ['Number of students in training year']>=40)] \n",
        "train_hsc31['Deviation of training year'] = train_hsc31 ['GPA.1'] - train_hsc31['GPA'] \n",
        "train_hsc31 = pd.concat([train_hsc31[train_hsc31 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc31[train_hsc31['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc31 = train_hsc31.reset_index() \n",
        "features_drop31 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc31 = train_hsc31.drop(features_drop31 ,axis=1) \n",
        "train_hsc31.head() \n",
        "\n",
        "train_count32 = train_category32['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa32 = train_category32.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa32 = train_gpa32.reset_index() \n",
        "train_hsc32 = pd.merge(train_count32,train_gpa32) \n",
        "train_hsc32 = train_hsc32.loc[(train_hsc32 ['Number of students in training year']>=40)] \n",
        "train_hsc32['Deviation of training year'] = train_hsc32 ['GPA.1'] - train_hsc32['GPA'] \n",
        "train_hsc32 = pd.concat([train_hsc32[train_hsc32 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc32[train_hsc32['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc32 = train_hsc32.reset_index() \n",
        "features_drop32 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc32 = train_hsc32.drop(features_drop32 ,axis=1) \n",
        "train_hsc32.head() \n",
        "\n",
        "train_count33 = train_category33['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa33 = train_category33.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa33 = train_gpa33.reset_index() \n",
        "train_hsc33 = pd.merge(train_count33,train_gpa33) \n",
        "train_hsc33 = train_hsc33.loc[(train_hsc33 ['Number of students in training year']>=40)] \n",
        "train_hsc33['Deviation of training year'] = train_hsc33 ['GPA.1'] - train_hsc33['GPA'] \n",
        "train_hsc33 = pd.concat([train_hsc33[train_hsc33 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc33[train_hsc33['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc33 = train_hsc33.reset_index() \n",
        "features_drop33 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc33 = train_hsc33.drop(features_drop33 ,axis=1) \n",
        "train_hsc33.head() \n",
        "\n",
        "train_count34 = train_category34['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa34 = train_category34.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa34 = train_gpa34.reset_index() \n",
        "train_hsc34 = pd.merge(train_count34,train_gpa34) \n",
        "train_hsc34 = train_hsc34.loc[(train_hsc34 ['Number of students in training year']>=40)] \n",
        "train_hsc34['Deviation of training year'] = train_hsc34 ['GPA.1'] - train_hsc34['GPA'] \n",
        "train_hsc34 = pd.concat([train_hsc34[train_hsc34 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc34[train_hsc34['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc34 = train_hsc34.reset_index() \n",
        "features_drop34 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc34 = train_hsc34.drop(features_drop34 ,axis=1) \n",
        "train_hsc34.head() \n",
        "\n",
        "train_count35 = train_category35['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa35 = train_category35.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa35 = train_gpa35.reset_index() \n",
        "train_hsc35 = pd.merge(train_count35,train_gpa35) \n",
        "train_hsc35 = train_hsc35.loc[(train_hsc35 ['Number of students in training year']>=40)] \n",
        "train_hsc35['Deviation of training year'] = train_hsc35 ['GPA.1'] - train_hsc35['GPA'] \n",
        "train_hsc35 = pd.concat([train_hsc35[train_hsc35 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc35[train_hsc35['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc35 = train_hsc35.reset_index() \n",
        "features_drop35 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc35 = train_hsc35.drop(features_drop35 ,axis=1) \n",
        "train_hsc35.head() \n",
        "\n",
        "train_count36 = train_category36['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa36 = train_category36.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa36 = train_gpa36.reset_index() \n",
        "train_hsc36 = pd.merge(train_count36,train_gpa36) \n",
        "train_hsc36 = train_hsc36.loc[(train_hsc36 ['Number of students in training year']>=40)] \n",
        "train_hsc36['Deviation of training year'] = train_hsc36 ['GPA.1'] - train_hsc36['GPA'] \n",
        "train_hsc36 = pd.concat([train_hsc36[train_hsc36 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc36[train_hsc36['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc36 = train_hsc36.reset_index() \n",
        "features_drop36 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc36 = train_hsc36.drop(features_drop36 ,axis=1) \n",
        "train_hsc36.head() \n",
        "\n",
        "train_count37 = train_category37['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa37 = train_category37.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa37 = train_gpa37.reset_index() \n",
        "train_hsc37 = pd.merge(train_count37,train_gpa37) \n",
        "train_hsc37 = train_hsc37.loc[(train_hsc37 ['Number of students in training year']>=40)] \n",
        "train_hsc37['Deviation of training year'] = train_hsc37 ['GPA.1'] - train_hsc37['GPA'] \n",
        "train_hsc37 = pd.concat([train_hsc37[train_hsc37 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc37[train_hsc37['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc37 = train_hsc37.reset_index() \n",
        "features_drop37 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc37 = train_hsc37.drop(features_drop37 ,axis=1) \n",
        "train_hsc37.head() \n",
        "\n",
        "train_count38 = train_category38['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa38 = train_category38.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa38 = train_gpa38.reset_index() \n",
        "train_hsc38 = pd.merge(train_count38,train_gpa38) \n",
        "train_hsc38 = train_hsc38.loc[(train_hsc38 ['Number of students in training year']>=40)] \n",
        "train_hsc38['Deviation of training year'] = train_hsc38 ['GPA.1'] - train_hsc38['GPA'] \n",
        "train_hsc38 = pd.concat([train_hsc38[train_hsc38 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc38[train_hsc38['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc38 = train_hsc38.reset_index() \n",
        "features_drop38 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc38 = train_hsc38.drop(features_drop38 ,axis=1) \n",
        "train_hsc38.head() \n",
        "\n",
        "train_count39 = train_category39['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa39 = train_category39.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa39 = train_gpa39.reset_index() \n",
        "train_hsc39 = pd.merge(train_count39,train_gpa39) \n",
        "train_hsc39 = train_hsc39.loc[(train_hsc39 ['Number of students in training year']>=40)] \n",
        "train_hsc39['Deviation of training year'] = train_hsc39 ['GPA.1'] - train_hsc39['GPA'] \n",
        "train_hsc39 = pd.concat([train_hsc39[train_hsc39 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc39[train_hsc39['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc39 = train_hsc39.reset_index() \n",
        "features_drop39 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc39 = train_hsc39.drop(features_drop39 ,axis=1) \n",
        "train_hsc39.head() \n",
        "\n",
        "train_count40 = train_category40['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa40 = train_category40.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa40 = train_gpa40.reset_index() \n",
        "train_hsc40 = pd.merge(train_count40,train_gpa40) \n",
        "train_hsc40 = train_hsc40.loc[(train_hsc40 ['Number of students in training year']>=40)] \n",
        "train_hsc40['Deviation of training year'] = train_hsc40 ['GPA.1'] - train_hsc40['GPA'] \n",
        "train_hsc40 = pd.concat([train_hsc40[train_hsc40 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc40[train_hsc40['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc40 = train_hsc40.reset_index() \n",
        "features_drop40 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc40 = train_hsc40.drop(features_drop40 ,axis=1) \n",
        "train_hsc40.head() \n",
        "\n",
        "train_count41 = train_category41['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa41 = train_category41.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa41 = train_gpa41.reset_index() \n",
        "train_hsc41 = pd.merge(train_count41,train_gpa41) \n",
        "train_hsc41 = train_hsc41.loc[(train_hsc41 ['Number of students in training year']>=40)] \n",
        "train_hsc41['Deviation of training year'] = train_hsc41 ['GPA.1'] - train_hsc41['GPA'] \n",
        "train_hsc41 = pd.concat([train_hsc41[train_hsc41 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc41[train_hsc41['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc41 = train_hsc41.reset_index() \n",
        "features_drop41 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc41 = train_hsc41.drop(features_drop41 ,axis=1) \n",
        "train_hsc41.head() \n",
        "\n",
        "train_count42 = train_category42['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa42 = train_category42.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa42 = train_gpa42.reset_index() \n",
        "train_hsc42 = pd.merge(train_count42,train_gpa42) \n",
        "train_hsc42 = train_hsc42.loc[(train_hsc42 ['Number of students in training year']>=40)] \n",
        "train_hsc42['Deviation of training year'] = train_hsc42 ['GPA.1'] - train_hsc42['GPA'] \n",
        "train_hsc42 = pd.concat([train_hsc42[train_hsc42 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc42[train_hsc42['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc42 = train_hsc42.reset_index() \n",
        "features_drop42 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc42 = train_hsc42.drop(features_drop42 ,axis=1) \n",
        "train_hsc42.head() \n",
        "\n",
        "train_count43 = train_category43['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa43 = train_category43.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa43 = train_gpa43.reset_index() \n",
        "train_hsc43 = pd.merge(train_count43,train_gpa43) \n",
        "train_hsc43 = train_hsc43.loc[(train_hsc43 ['Number of students in training year']>=40)] \n",
        "train_hsc43['Deviation of training year'] = train_hsc43 ['GPA.1'] - train_hsc43['GPA'] \n",
        "train_hsc43 = pd.concat([train_hsc43[train_hsc43 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc43[train_hsc43['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc43 = train_hsc43.reset_index() \n",
        "features_drop43 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc43 = train_hsc43.drop(features_drop43 ,axis=1) \n",
        "train_hsc43.head() \n",
        "\n",
        "train_count44 = train_category44['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa44 = train_category44.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa44 = train_gpa44.reset_index() \n",
        "train_hsc44 = pd.merge(train_count44,train_gpa44) \n",
        "train_hsc44 = train_hsc44.loc[(train_hsc44 ['Number of students in training year']>=40)] \n",
        "train_hsc44['Deviation of training year'] = train_hsc44 ['GPA.1'] - train_hsc44['GPA'] \n",
        "train_hsc44 = pd.concat([train_hsc44[train_hsc44 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc44[train_hsc44['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc44 = train_hsc44.reset_index() \n",
        "features_drop44 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc44 = train_hsc44.drop(features_drop44 ,axis=1) \n",
        "train_hsc44.head() \n",
        "\n",
        "train_count45 = train_category45['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa45 = train_category45.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa45 = train_gpa45.reset_index() \n",
        "train_hsc45 = pd.merge(train_count45,train_gpa45) \n",
        "train_hsc45 = train_hsc45.loc[(train_hsc45 ['Number of students in training year']>=40)] \n",
        "train_hsc45['Deviation of training year'] = train_hsc45 ['GPA.1'] - train_hsc45['GPA'] \n",
        "train_hsc45 = pd.concat([train_hsc45[train_hsc45 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc45[train_hsc45['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc45 = train_hsc45.reset_index() \n",
        "features_drop45 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc45 = train_hsc45.drop(features_drop45 ,axis=1) \n",
        "train_hsc45.head() \n",
        "\n",
        "train_count46 = train_category46['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa46 = train_category46.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa46 = train_gpa46.reset_index() \n",
        "train_hsc46 = pd.merge(train_count46,train_gpa46) \n",
        "train_hsc46 = train_hsc46.loc[(train_hsc46 ['Number of students in training year']>=40)] \n",
        "train_hsc46['Deviation of training year'] = train_hsc46 ['GPA.1'] - train_hsc46['GPA'] \n",
        "train_hsc46 = pd.concat([train_hsc46[train_hsc46 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc46[train_hsc46['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc46 = train_hsc46.reset_index() \n",
        "features_drop46 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc46 = train_hsc46.drop(features_drop46 ,axis=1) \n",
        "train_hsc46.head() \n",
        "\n",
        "train_count47 = train_category47['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa47 = train_category47.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa47 = train_gpa47.reset_index() \n",
        "train_hsc47 = pd.merge(train_count47,train_gpa47) \n",
        "train_hsc47 = train_hsc47.loc[(train_hsc47 ['Number of students in training year']>=40)] \n",
        "train_hsc47['Deviation of training year'] = train_hsc47 ['GPA.1'] - train_hsc47['GPA'] \n",
        "train_hsc47 = pd.concat([train_hsc47[train_hsc47 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc47[train_hsc47['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc47 = train_hsc47.reset_index() \n",
        "features_drop47 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc47 = train_hsc47.drop(features_drop47 ,axis=1) \n",
        "train_hsc47.head() \n",
        "\n",
        "train_count48 = train_category48['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa48 = train_category48.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa48 = train_gpa48.reset_index() \n",
        "train_hsc48 = pd.merge(train_count48,train_gpa48) \n",
        "train_hsc48 = train_hsc48.loc[(train_hsc48 ['Number of students in training year']>=40)] \n",
        "train_hsc48['Deviation of training year'] = train_hsc48 ['GPA.1'] - train_hsc48['GPA'] \n",
        "train_hsc48 = pd.concat([train_hsc48[train_hsc48 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc48[train_hsc48['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc48 = train_hsc48.reset_index() \n",
        "features_drop48 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc48 = train_hsc48.drop(features_drop48 ,axis=1) \n",
        "train_hsc48.head() \n",
        "\n",
        "train_count49 = train_category49['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa49 = train_category49.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa49 = train_gpa49.reset_index() \n",
        "train_hsc49 = pd.merge(train_count49,train_gpa49) \n",
        "train_hsc49 = train_hsc49.loc[(train_hsc49 ['Number of students in training year']>=40)] \n",
        "train_hsc49['Deviation of training year'] = train_hsc49 ['GPA.1'] - train_hsc49['GPA'] \n",
        "train_hsc49 = pd.concat([train_hsc49[train_hsc49 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc49[train_hsc49['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc49 = train_hsc49.reset_index() \n",
        "features_drop49 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc49 = train_hsc49.drop(features_drop49 ,axis=1) \n",
        "train_hsc49.head() \n",
        "\n",
        "train_count50 = train_category50['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa50 = train_category50.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa50 = train_gpa50.reset_index() \n",
        "train_hsc50 = pd.merge(train_count50,train_gpa50) \n",
        "train_hsc50 = train_hsc50.loc[(train_hsc50 ['Number of students in training year']>=40)] \n",
        "train_hsc50['Deviation of training year'] = train_hsc50 ['GPA.1'] - train_hsc50['GPA'] \n",
        "train_hsc50 = pd.concat([train_hsc50[train_hsc50 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc50[train_hsc50['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc50 = train_hsc50.reset_index() \n",
        "features_drop50 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc50 = train_hsc50.drop(features_drop50 ,axis=1) \n",
        "train_hsc50.head() \n",
        "\n",
        "train_count51 = train_category51['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa51 = train_category51.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa51 = train_gpa51.reset_index() \n",
        "train_hsc51 = pd.merge(train_count51,train_gpa51) \n",
        "train_hsc51 = train_hsc51.loc[(train_hsc51 ['Number of students in training year']>=40)] \n",
        "train_hsc51['Deviation of training year'] = train_hsc51 ['GPA.1'] - train_hsc51['GPA'] \n",
        "train_hsc51 = pd.concat([train_hsc51[train_hsc51 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc51[train_hsc51['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc51 = train_hsc51.reset_index() \n",
        "features_drop51 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc51 = train_hsc51.drop(features_drop51 ,axis=1) \n",
        "train_hsc51.head() \n",
        "\n",
        "train_count52 = train_category52['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa52 = train_category52.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa52 = train_gpa52.reset_index() \n",
        "train_hsc52 = pd.merge(train_count52,train_gpa52) \n",
        "train_hsc52 = train_hsc52.loc[(train_hsc52 ['Number of students in training year']>=40)] \n",
        "train_hsc52['Deviation of training year'] = train_hsc52 ['GPA.1'] - train_hsc52['GPA'] \n",
        "train_hsc52 = pd.concat([train_hsc52[train_hsc52 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc52[train_hsc52['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc52 = train_hsc52.reset_index() \n",
        "features_drop52 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc52 = train_hsc52.drop(features_drop52 ,axis=1) \n",
        "train_hsc52.head() \n",
        "\n",
        "train_count53 = train_category53['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa53 = train_category53.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa53 = train_gpa53.reset_index() \n",
        "train_hsc53 = pd.merge(train_count53,train_gpa53) \n",
        "train_hsc53 = train_hsc53.loc[(train_hsc53 ['Number of students in training year']>=40)] \n",
        "train_hsc53['Deviation of training year'] = train_hsc53 ['GPA.1'] - train_hsc53['GPA'] \n",
        "train_hsc53 = pd.concat([train_hsc53[train_hsc53 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc53[train_hsc53['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc53 = train_hsc53.reset_index() \n",
        "features_drop53 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc53 = train_hsc53.drop(features_drop53 ,axis=1) \n",
        "train_hsc53.head() \n",
        "\n",
        "train_count54 = train_category54['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in training year').sort_values(by='INST_.1') \n",
        "train_gpa54 = train_category54.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "train_gpa54 = train_gpa54.reset_index() \n",
        "train_hsc54 = pd.merge(train_count54,train_gpa54) \n",
        "train_hsc54 = train_hsc54.loc[(train_hsc54 ['Number of students in training year']>=40)] \n",
        "train_hsc54['Deviation of training year'] = train_hsc54 ['GPA.1'] - train_hsc54['GPA'] \n",
        "train_hsc54 = pd.concat([train_hsc54[train_hsc54 ['Deviation of training year']>0].sort_values('Deviation of training year',ascending=False), \n",
        "train_hsc54[train_hsc54['Deviation of training year']< 0].sort_values('Deviation of training year',ascending=False)]) \n",
        "train_hsc54 = train_hsc54.reset_index() \n",
        "features_drop54 = ['GPA','GPA.1','index','Number of students in training year'] \n",
        "train_hsc54 = train_hsc54.drop(features_drop54 ,axis=1) \n",
        "train_hsc54.head() \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>INST_.1</th>\n",
              "      <th>STUD_GROUP</th>\n",
              "      <th>SEX</th>\n",
              "      <th>CATEGORY</th>\n",
              "      <th>Deviation of training year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [INST_.1, STUD_GROUP, SEX, CATEGORY, Deviation of training year]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "id": "maws2bv5a9eo",
        "outputId": "70ca595d-21c1-465b-8b70-fb6db4ca75c5"
      },
      "source": [
        "test_count1 = test_category1['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa1 = test_category1.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa1 = test_gpa1.reset_index() \n",
        "test_hsc1 = pd.merge(test_count1,test_gpa1) \n",
        "test_hsc1 = test_hsc1.loc[(test_hsc1 ['Number of students in testing year']>=20)] \n",
        "test_hsc1['Deviation of testing year'] = test_hsc1['GPA.1'] - test_hsc1['GPA'] \n",
        "test_hsc1 = pd.concat([test_hsc1[test_hsc1 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc1[test_hsc1['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc1 = test_hsc1.reset_index() \n",
        "features_drop1 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc1 = test_hsc1.drop(features_drop1 ,axis=1) \n",
        "test_hsc1.head() \n",
        "\n",
        "test_count2 = test_category2['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa2 = test_category2.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa2 = test_gpa2.reset_index() \n",
        "test_hsc2 = pd.merge(test_count2,test_gpa2) \n",
        "test_hsc2 = test_hsc2.loc[(test_hsc2 ['Number of students in testing year']>=20)] \n",
        "test_hsc2['Deviation of testing year'] = test_hsc2['GPA.1'] - test_hsc2['GPA'] \n",
        "test_hsc2 = pd.concat([test_hsc2[test_hsc2 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc2[test_hsc2['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc2 = test_hsc2.reset_index() \n",
        "features_drop2 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc2 = test_hsc2.drop(features_drop2 ,axis=1) \n",
        "test_hsc2.head() \n",
        "\n",
        "test_count3 = test_category3['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa3 = test_category3.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa3 = test_gpa3.reset_index() \n",
        "test_hsc3 = pd.merge(test_count3,test_gpa3) \n",
        "test_hsc3 = test_hsc3.loc[(test_hsc3 ['Number of students in testing year']>=20)] \n",
        "test_hsc3['Deviation of testing year'] = test_hsc3['GPA.1'] - test_hsc3['GPA'] \n",
        "test_hsc3 = pd.concat([test_hsc3[test_hsc3 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc3[test_hsc3['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc3 = test_hsc3.reset_index() \n",
        "features_drop3 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc3 = test_hsc3.drop(features_drop3 ,axis=1) \n",
        "test_hsc3.head() \n",
        "\n",
        "test_count4 = test_category4['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa4 = test_category4.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa4 = test_gpa4.reset_index() \n",
        "test_hsc4 = pd.merge(test_count4,test_gpa4) \n",
        "test_hsc4 = test_hsc4.loc[(test_hsc4 ['Number of students in testing year']>=20)] \n",
        "test_hsc4['Deviation of testing year'] = test_hsc4['GPA.1'] - test_hsc4['GPA'] \n",
        "test_hsc4 = pd.concat([test_hsc4[test_hsc4 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc4[test_hsc4['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc4 = test_hsc4.reset_index() \n",
        "features_drop4 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc4 = test_hsc4.drop(features_drop4 ,axis=1) \n",
        "test_hsc4.head() \n",
        "\n",
        "test_count5 = test_category5['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa5 = test_category5.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa5 = test_gpa5.reset_index() \n",
        "test_hsc5 = pd.merge(test_count5,test_gpa5) \n",
        "test_hsc5 = test_hsc5.loc[(test_hsc5 ['Number of students in testing year']>=20)] \n",
        "test_hsc5['Deviation of testing year'] = test_hsc5['GPA.1'] - test_hsc5['GPA'] \n",
        "test_hsc5 = pd.concat([test_hsc5[test_hsc5 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc5[test_hsc5['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc5 = test_hsc5.reset_index() \n",
        "features_drop5 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc5 = test_hsc5.drop(features_drop5 ,axis=1) \n",
        "test_hsc5.head() \n",
        "\n",
        "test_count6 = test_category6['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa6 = test_category6.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa6 = test_gpa6.reset_index() \n",
        "test_hsc6 = pd.merge(test_count6,test_gpa6) \n",
        "test_hsc6 = test_hsc6.loc[(test_hsc6 ['Number of students in testing year']>=20)] \n",
        "test_hsc6['Deviation of testing year'] = test_hsc6['GPA.1'] - test_hsc6['GPA'] \n",
        "test_hsc6 = pd.concat([test_hsc6[test_hsc6 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc6[test_hsc6['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc6 = test_hsc6.reset_index() \n",
        "features_drop6 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc6 = test_hsc6.drop(features_drop6 ,axis=1) \n",
        "test_hsc6.head() \n",
        "\n",
        "test_count7 = test_category7['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa7 = test_category7.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa7 = test_gpa7.reset_index() \n",
        "test_hsc7 = pd.merge(test_count7,test_gpa7) \n",
        "test_hsc7 = test_hsc7.loc[(test_hsc7 ['Number of students in testing year']>=20)] \n",
        "test_hsc7['Deviation of testing year'] = test_hsc7['GPA.1'] - test_hsc7['GPA'] \n",
        "test_hsc7 = pd.concat([test_hsc7[test_hsc7 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc7[test_hsc7['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc7 = test_hsc7.reset_index() \n",
        "features_drop7 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc7 = test_hsc7.drop(features_drop7 ,axis=1) \n",
        "test_hsc7.head() \n",
        "\n",
        "test_count8 = test_category8['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa8 = test_category8.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa8 = test_gpa8.reset_index() \n",
        "test_hsc8 = pd.merge(test_count8,test_gpa8) \n",
        "test_hsc8 = test_hsc8.loc[(test_hsc8 ['Number of students in testing year']>=20)] \n",
        "test_hsc8['Deviation of testing year'] = test_hsc8['GPA.1'] - test_hsc8['GPA'] \n",
        "test_hsc8 = pd.concat([test_hsc8[test_hsc8 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc8[test_hsc8['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc8 = test_hsc8.reset_index() \n",
        "features_drop8 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc8 = test_hsc8.drop(features_drop8 ,axis=1) \n",
        "test_hsc8.head() \n",
        "\n",
        "test_count9 = test_category9['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa9 = test_category9.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa9 = test_gpa9.reset_index() \n",
        "test_hsc9 = pd.merge(test_count9,test_gpa9) \n",
        "test_hsc9 = test_hsc9.loc[(test_hsc9 ['Number of students in testing year']>=20)] \n",
        "test_hsc9['Deviation of testing year'] = test_hsc9['GPA.1'] - test_hsc9['GPA'] \n",
        "test_hsc9 = pd.concat([test_hsc9[test_hsc9 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc9[test_hsc9['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc9 = test_hsc9.reset_index() \n",
        "features_drop9 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc9 = test_hsc9.drop(features_drop9 ,axis=1) \n",
        "test_hsc9.head() \n",
        "\n",
        "test_count10 = test_category10['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa10 = test_category10.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa10 = test_gpa10.reset_index() \n",
        "test_hsc10 = pd.merge(test_count10,test_gpa10) \n",
        "test_hsc10 = test_hsc10.loc[(test_hsc10 ['Number of students in testing year']>=20)] \n",
        "test_hsc10['Deviation of testing year'] = test_hsc10['GPA.1'] - test_hsc10['GPA'] \n",
        "test_hsc10 = pd.concat([test_hsc10[test_hsc10 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc10[test_hsc10['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc10 = test_hsc10.reset_index() \n",
        "features_drop10 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc10 = test_hsc10.drop(features_drop10 ,axis=1) \n",
        "test_hsc10.head() \n",
        "\n",
        "test_count11 = test_category11['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa11 = test_category11.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa11 = test_gpa11.reset_index() \n",
        "test_hsc11 = pd.merge(test_count11,test_gpa11) \n",
        "test_hsc11 = test_hsc11.loc[(test_hsc11 ['Number of students in testing year']>=20)] \n",
        "test_hsc11['Deviation of testing year'] = test_hsc11['GPA.1'] - test_hsc11['GPA'] \n",
        "test_hsc11 = pd.concat([test_hsc11[test_hsc11 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc11[test_hsc11['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc11 = test_hsc11.reset_index() \n",
        "features_drop11 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc11 = test_hsc11.drop(features_drop11 ,axis=1) \n",
        "test_hsc11.head() \n",
        "\n",
        "test_count12 = test_category12['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa12 = test_category12.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa12 = test_gpa12.reset_index() \n",
        "test_hsc12 = pd.merge(test_count12,test_gpa12) \n",
        "test_hsc12 = test_hsc12.loc[(test_hsc12 ['Number of students in testing year']>=20)] \n",
        "test_hsc12['Deviation of testing year'] = test_hsc12['GPA.1'] - test_hsc12['GPA'] \n",
        "test_hsc12 = pd.concat([test_hsc12[test_hsc12 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc12[test_hsc12['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc12 = test_hsc12.reset_index() \n",
        "features_drop12 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc12 = test_hsc12.drop(features_drop12 ,axis=1) \n",
        "test_hsc12.head() \n",
        "\n",
        "test_count13 = test_category13['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa13 = test_category13.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa13 = test_gpa13.reset_index() \n",
        "test_hsc13 = pd.merge(test_count13,test_gpa13) \n",
        "test_hsc13 = test_hsc13.loc[(test_hsc13 ['Number of students in testing year']>=20)] \n",
        "test_hsc13['Deviation of testing year'] = test_hsc13['GPA.1'] - test_hsc13['GPA'] \n",
        "test_hsc13 = pd.concat([test_hsc13[test_hsc13 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc13[test_hsc13['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc13 = test_hsc13.reset_index() \n",
        "features_drop13 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc13 = test_hsc13.drop(features_drop13 ,axis=1) \n",
        "test_hsc13.head() \n",
        "\n",
        "test_count14 = test_category14['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa14 = test_category14.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa14 = test_gpa14.reset_index() \n",
        "test_hsc14 = pd.merge(test_count14,test_gpa14) \n",
        "test_hsc14 = test_hsc14.loc[(test_hsc14 ['Number of students in testing year']>=20)] \n",
        "test_hsc14['Deviation of testing year'] = test_hsc14['GPA.1'] - test_hsc14['GPA'] \n",
        "test_hsc14 = pd.concat([test_hsc14[test_hsc14 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc14[test_hsc14['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc14 = test_hsc14.reset_index() \n",
        "features_drop14 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc14 = test_hsc14.drop(features_drop14 ,axis=1) \n",
        "test_hsc14.head() \n",
        "\n",
        "test_count15 = test_category15['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa15 = test_category15.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa15 = test_gpa15.reset_index() \n",
        "test_hsc15 = pd.merge(test_count15,test_gpa15) \n",
        "test_hsc15 = test_hsc15.loc[(test_hsc15 ['Number of students in testing year']>=20)] \n",
        "test_hsc15['Deviation of testing year'] = test_hsc15['GPA.1'] - test_hsc15['GPA'] \n",
        "test_hsc15 = pd.concat([test_hsc15[test_hsc15 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc15[test_hsc15['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc15 = test_hsc15.reset_index() \n",
        "features_drop15 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc15 = test_hsc15.drop(features_drop15 ,axis=1) \n",
        "test_hsc15.head() \n",
        "\n",
        "test_count16 = test_category16['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa16 = test_category16.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa16 = test_gpa16.reset_index() \n",
        "test_hsc16 = pd.merge(test_count16,test_gpa16) \n",
        "test_hsc16 = test_hsc16.loc[(test_hsc16 ['Number of students in testing year']>=20)] \n",
        "test_hsc16['Deviation of testing year'] = test_hsc16['GPA.1'] - test_hsc16['GPA'] \n",
        "test_hsc16 = pd.concat([test_hsc16[test_hsc16 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc16[test_hsc16['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc16 = test_hsc16.reset_index() \n",
        "features_drop16 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc16 = test_hsc16.drop(features_drop16 ,axis=1) \n",
        "test_hsc16.head() \n",
        "\n",
        "test_count17 = test_category17['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa17 = test_category17.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa17 = test_gpa17.reset_index() \n",
        "test_hsc17 = pd.merge(test_count17,test_gpa17) \n",
        "test_hsc17 = test_hsc17.loc[(test_hsc17 ['Number of students in testing year']>=20)] \n",
        "test_hsc17['Deviation of testing year'] = test_hsc17['GPA.1'] - test_hsc17['GPA'] \n",
        "test_hsc17 = pd.concat([test_hsc17[test_hsc17 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc17[test_hsc17['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc17 = test_hsc17.reset_index() \n",
        "features_drop17 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc17 = test_hsc17.drop(features_drop17 ,axis=1) \n",
        "test_hsc17.head() \n",
        "\n",
        "test_count18 = test_category18['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa18 = test_category18.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa18 = test_gpa18.reset_index() \n",
        "test_hsc18 = pd.merge(test_count18,test_gpa18) \n",
        "test_hsc18 = test_hsc18.loc[(test_hsc18 ['Number of students in testing year']>=20)] \n",
        "test_hsc18['Deviation of testing year'] = test_hsc18['GPA.1'] - test_hsc18['GPA'] \n",
        "test_hsc18 = pd.concat([test_hsc18[test_hsc18 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc18[test_hsc18['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc18 = test_hsc18.reset_index() \n",
        "features_drop18 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc18 = test_hsc18.drop(features_drop18 ,axis=1) \n",
        "test_hsc18.head() \n",
        "\n",
        "test_count19 = test_category19['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa19 = test_category19.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa19 = test_gpa19.reset_index() \n",
        "test_hsc19 = pd.merge(test_count19,test_gpa19) \n",
        "test_hsc19 = test_hsc19.loc[(test_hsc19 ['Number of students in testing year']>=20)] \n",
        "test_hsc19['Deviation of testing year'] = test_hsc19['GPA.1'] - test_hsc19['GPA'] \n",
        "test_hsc19 = pd.concat([test_hsc19[test_hsc19 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc19[test_hsc19['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc19 = test_hsc19.reset_index() \n",
        "features_drop19 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc19 = test_hsc19.drop(features_drop19 ,axis=1) \n",
        "test_hsc19.head() \n",
        "\n",
        "test_count20 = test_category20['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa20 = test_category20.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa20 = test_gpa20.reset_index() \n",
        "test_hsc20 = pd.merge(test_count20,test_gpa20) \n",
        "test_hsc20 = test_hsc20.loc[(test_hsc20 ['Number of students in testing year']>=20)] \n",
        "test_hsc20['Deviation of testing year'] = test_hsc20['GPA.1'] - test_hsc20['GPA'] \n",
        "test_hsc20 = pd.concat([test_hsc20[test_hsc20 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc20[test_hsc20['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc20 = test_hsc20.reset_index() \n",
        "features_drop20 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc20 = test_hsc20.drop(features_drop20 ,axis=1) \n",
        "test_hsc20.head() \n",
        "\n",
        "test_count21 = test_category21['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa21 = test_category21.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa21 = test_gpa21.reset_index() \n",
        "test_hsc21 = pd.merge(test_count21,test_gpa21) \n",
        "test_hsc21 = test_hsc21.loc[(test_hsc21 ['Number of students in testing year']>=20)] \n",
        "test_hsc21['Deviation of testing year'] = test_hsc21['GPA.1'] - test_hsc21['GPA'] \n",
        "test_hsc21 = pd.concat([test_hsc21[test_hsc21 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc21[test_hsc21['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc21 = test_hsc21.reset_index() \n",
        "features_drop21 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc21 = test_hsc21.drop(features_drop21 ,axis=1) \n",
        "test_hsc21.head() \n",
        "\n",
        "test_count22 = test_category22['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa22 = test_category22.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa22 = test_gpa22.reset_index() \n",
        "test_hsc22 = pd.merge(test_count22,test_gpa22) \n",
        "test_hsc22 = test_hsc22.loc[(test_hsc22 ['Number of students in testing year']>=20)] \n",
        "test_hsc22['Deviation of testing year'] = test_hsc22['GPA.1'] - test_hsc22['GPA'] \n",
        "test_hsc22 = pd.concat([test_hsc22[test_hsc22 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc22[test_hsc22['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc22 = test_hsc22.reset_index() \n",
        "features_drop22 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc22 = test_hsc22.drop(features_drop22 ,axis=1) \n",
        "test_hsc22.head() \n",
        "\n",
        "test_count23 = test_category23['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa23 = test_category23.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa23 = test_gpa23.reset_index() \n",
        "test_hsc23 = pd.merge(test_count23,test_gpa23) \n",
        "test_hsc23 = test_hsc23.loc[(test_hsc23 ['Number of students in testing year']>=20)] \n",
        "test_hsc23['Deviation of testing year'] = test_hsc23['GPA.1'] - test_hsc23['GPA'] \n",
        "test_hsc23 = pd.concat([test_hsc23[test_hsc23 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc23[test_hsc23['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc23 = test_hsc23.reset_index() \n",
        "features_drop23 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc23 = test_hsc23.drop(features_drop23 ,axis=1) \n",
        "test_hsc23.head() \n",
        "\n",
        "test_count24 = test_category24['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa24 = test_category24.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa24 = test_gpa24.reset_index() \n",
        "test_hsc24 = pd.merge(test_count24,test_gpa24) \n",
        "test_hsc24 = test_hsc24.loc[(test_hsc24 ['Number of students in testing year']>=20)] \n",
        "test_hsc24['Deviation of testing year'] = test_hsc24['GPA.1'] - test_hsc24['GPA'] \n",
        "test_hsc24 = pd.concat([test_hsc24[test_hsc24 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc24[test_hsc24['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc24 = test_hsc24.reset_index() \n",
        "features_drop24 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc24 = test_hsc24.drop(features_drop24 ,axis=1) \n",
        "test_hsc24.head() \n",
        "\n",
        "test_count25 = test_category25['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa25 = test_category25.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa25 = test_gpa25.reset_index() \n",
        "test_hsc25 = pd.merge(test_count25,test_gpa25) \n",
        "test_hsc25 = test_hsc25.loc[(test_hsc25 ['Number of students in testing year']>=20)] \n",
        "test_hsc25['Deviation of testing year'] = test_hsc25['GPA.1'] - test_hsc25['GPA'] \n",
        "test_hsc25 = pd.concat([test_hsc25[test_hsc25 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc25[test_hsc25['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc25 = test_hsc25.reset_index() \n",
        "features_drop25 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc25 = test_hsc25.drop(features_drop25 ,axis=1) \n",
        "test_hsc25.head() \n",
        "\n",
        "test_count26 = test_category26['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa26 = test_category26.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa26 = test_gpa26.reset_index() \n",
        "test_hsc26 = pd.merge(test_count26,test_gpa26) \n",
        "test_hsc26 = test_hsc26.loc[(test_hsc26 ['Number of students in testing year']>=20)] \n",
        "test_hsc26['Deviation of testing year'] = test_hsc26['GPA.1'] - test_hsc26['GPA'] \n",
        "test_hsc26 = pd.concat([test_hsc26[test_hsc26 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc26[test_hsc26['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc26 = test_hsc26.reset_index() \n",
        "features_drop26 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc26 = test_hsc26.drop(features_drop26 ,axis=1) \n",
        "test_hsc26.head() \n",
        "\n",
        "test_count27 = test_category27['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa27 = test_category27.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa27 = test_gpa27.reset_index() \n",
        "test_hsc27 = pd.merge(test_count27,test_gpa27) \n",
        "test_hsc27 = test_hsc27.loc[(test_hsc27 ['Number of students in testing year']>=20)] \n",
        "test_hsc27['Deviation of testing year'] = test_hsc27['GPA.1'] - test_hsc27['GPA'] \n",
        "test_hsc27 = pd.concat([test_hsc27[test_hsc27 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc27[test_hsc27['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc27 = test_hsc27.reset_index() \n",
        "features_drop27 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc27 = test_hsc27.drop(features_drop27 ,axis=1) \n",
        "test_hsc27.head() \n",
        "\n",
        "test_count28 = test_category28['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa28 = test_category28.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa28 = test_gpa28.reset_index() \n",
        "test_hsc28 = pd.merge(test_count28,test_gpa28) \n",
        "test_hsc28 = test_hsc28.loc[(test_hsc28 ['Number of students in testing year']>=20)] \n",
        "test_hsc28['Deviation of testing year'] = test_hsc28['GPA.1'] - test_hsc28['GPA'] \n",
        "test_hsc28 = pd.concat([test_hsc28[test_hsc28 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc28[test_hsc28['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc28 = test_hsc28.reset_index() \n",
        "features_drop28 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc28 = test_hsc28.drop(features_drop28 ,axis=1) \n",
        "test_hsc28.head() \n",
        "\n",
        "test_count29 = test_category29['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa29 = test_category29.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa29 = test_gpa29.reset_index() \n",
        "test_hsc29 = pd.merge(test_count29,test_gpa29) \n",
        "test_hsc29 = test_hsc29.loc[(test_hsc29 ['Number of students in testing year']>=20)] \n",
        "test_hsc29['Deviation of testing year'] = test_hsc29['GPA.1'] - test_hsc29['GPA'] \n",
        "test_hsc29 = pd.concat([test_hsc29[test_hsc29 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc29[test_hsc29['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc29 = test_hsc29.reset_index() \n",
        "features_drop29 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc29 = test_hsc29.drop(features_drop29 ,axis=1) \n",
        "test_hsc29.head() \n",
        "\n",
        "test_count30 = test_category30['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa30 = test_category30.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa30 = test_gpa30.reset_index() \n",
        "test_hsc30 = pd.merge(test_count30,test_gpa30) \n",
        "test_hsc30 = test_hsc30.loc[(test_hsc30 ['Number of students in testing year']>=20)] \n",
        "test_hsc30['Deviation of testing year'] = test_hsc30['GPA.1'] - test_hsc30['GPA'] \n",
        "test_hsc30 = pd.concat([test_hsc30[test_hsc30 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc30[test_hsc30['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc30 = test_hsc30.reset_index() \n",
        "features_drop30 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc30 = test_hsc30.drop(features_drop30 ,axis=1) \n",
        "test_hsc30.head() \n",
        "\n",
        "test_count31 = test_category31['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa31 = test_category31.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa31 = test_gpa31.reset_index() \n",
        "test_hsc31 = pd.merge(test_count31,test_gpa31) \n",
        "test_hsc31 = test_hsc31.loc[(test_hsc31 ['Number of students in testing year']>=20)] \n",
        "test_hsc31['Deviation of testing year'] = test_hsc31['GPA.1'] - test_hsc31['GPA'] \n",
        "test_hsc31 = pd.concat([test_hsc31[test_hsc31 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc31[test_hsc31['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc31 = test_hsc31.reset_index() \n",
        "features_drop31 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc31 = test_hsc31.drop(features_drop31 ,axis=1) \n",
        "test_hsc31.head() \n",
        "\n",
        "test_count32 = test_category32['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa32 = test_category32.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa32 = test_gpa32.reset_index() \n",
        "test_hsc32 = pd.merge(test_count32,test_gpa32) \n",
        "test_hsc32 = test_hsc32.loc[(test_hsc32 ['Number of students in testing year']>=20)] \n",
        "test_hsc32['Deviation of testing year'] = test_hsc32['GPA.1'] - test_hsc32['GPA'] \n",
        "test_hsc32 = pd.concat([test_hsc32[test_hsc32 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc32[test_hsc32['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc32 = test_hsc32.reset_index() \n",
        "features_drop32 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc32 = test_hsc32.drop(features_drop32 ,axis=1) \n",
        "test_hsc32.head() \n",
        "\n",
        "test_count33 = test_category33['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa33 = test_category33.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa33 = test_gpa33.reset_index() \n",
        "test_hsc33 = pd.merge(test_count33,test_gpa33) \n",
        "test_hsc33 = test_hsc33.loc[(test_hsc33 ['Number of students in testing year']>=20)] \n",
        "test_hsc33['Deviation of testing year'] = test_hsc33['GPA.1'] - test_hsc33['GPA'] \n",
        "test_hsc33 = pd.concat([test_hsc33[test_hsc33 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc33[test_hsc33['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc33 = test_hsc33.reset_index() \n",
        "features_drop33 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc33 = test_hsc33.drop(features_drop33 ,axis=1) \n",
        "test_hsc33.head() \n",
        "\n",
        "test_count34 = test_category34['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa34 = test_category34.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa34 = test_gpa34.reset_index() \n",
        "test_hsc34 = pd.merge(test_count34,test_gpa34) \n",
        "test_hsc34 = test_hsc34.loc[(test_hsc34 ['Number of students in testing year']>=20)] \n",
        "test_hsc34['Deviation of testing year'] = test_hsc34['GPA.1'] - test_hsc34['GPA'] \n",
        "test_hsc34 = pd.concat([test_hsc34[test_hsc34 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc34[test_hsc34['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc34 = test_hsc34.reset_index() \n",
        "features_drop34 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc34 = test_hsc34.drop(features_drop34 ,axis=1) \n",
        "test_hsc34.head() \n",
        "\n",
        "test_count35 = test_category35['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa35 = test_category35.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa35 = test_gpa35.reset_index() \n",
        "test_hsc35 = pd.merge(test_count35,test_gpa35) \n",
        "test_hsc35 = test_hsc35.loc[(test_hsc35 ['Number of students in testing year']>=20)] \n",
        "test_hsc35['Deviation of testing year'] = test_hsc35['GPA.1'] - test_hsc35['GPA'] \n",
        "test_hsc35 = pd.concat([test_hsc35[test_hsc35 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc35[test_hsc35['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc35 = test_hsc35.reset_index() \n",
        "features_drop35 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc35 = test_hsc35.drop(features_drop35 ,axis=1) \n",
        "test_hsc35.head() \n",
        "\n",
        "test_count36 = test_category36['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa36 = test_category36.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa36 = test_gpa36.reset_index() \n",
        "test_hsc36 = pd.merge(test_count36,test_gpa36) \n",
        "test_hsc36 = test_hsc36.loc[(test_hsc36 ['Number of students in testing year']>=20)] \n",
        "test_hsc36['Deviation of testing year'] = test_hsc36['GPA.1'] - test_hsc36['GPA'] \n",
        "test_hsc36 = pd.concat([test_hsc36[test_hsc36 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc36[test_hsc36['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc36 = test_hsc36.reset_index() \n",
        "features_drop36 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc36 = test_hsc36.drop(features_drop36 ,axis=1) \n",
        "test_hsc36.head() \n",
        "\n",
        "test_count37 = test_category37['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa37 = test_category37.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa37 = test_gpa37.reset_index() \n",
        "test_hsc37 = pd.merge(test_count37,test_gpa37) \n",
        "test_hsc37 = test_hsc37.loc[(test_hsc37 ['Number of students in testing year']>=20)] \n",
        "test_hsc37['Deviation of testing year'] = test_hsc37['GPA.1'] - test_hsc37['GPA'] \n",
        "test_hsc37 = pd.concat([test_hsc37[test_hsc37 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc37[test_hsc37['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc37 = test_hsc37.reset_index() \n",
        "features_drop37 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc37 = test_hsc37.drop(features_drop37 ,axis=1) \n",
        "test_hsc37.head() \n",
        "\n",
        "test_count38 = test_category38['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa38 = test_category38.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa38 = test_gpa38.reset_index() \n",
        "test_hsc38 = pd.merge(test_count38,test_gpa38) \n",
        "test_hsc38 = test_hsc38.loc[(test_hsc38 ['Number of students in testing year']>=20)] \n",
        "test_hsc38['Deviation of testing year'] = test_hsc38['GPA.1'] - test_hsc38['GPA'] \n",
        "test_hsc38 = pd.concat([test_hsc38[test_hsc38 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc38[test_hsc38['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc38 = test_hsc38.reset_index() \n",
        "features_drop38 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc38 = test_hsc38.drop(features_drop38 ,axis=1) \n",
        "test_hsc38.head() \n",
        "\n",
        "test_count39 = test_category39['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa39 = test_category39.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa39 = test_gpa39.reset_index() \n",
        "test_hsc39 = pd.merge(test_count39,test_gpa39) \n",
        "test_hsc39 = test_hsc39.loc[(test_hsc39 ['Number of students in testing year']>=20)] \n",
        "test_hsc39['Deviation of testing year'] = test_hsc39['GPA.1'] - test_hsc39['GPA'] \n",
        "test_hsc39 = pd.concat([test_hsc39[test_hsc39 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc39[test_hsc39['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc39 = test_hsc39.reset_index() \n",
        "features_drop39 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc39 = test_hsc39.drop(features_drop39 ,axis=1) \n",
        "test_hsc39.head() \n",
        "\n",
        "test_count40 = test_category40['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa40 = test_category40.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa40 = test_gpa40.reset_index() \n",
        "test_hsc40 = pd.merge(test_count40,test_gpa40) \n",
        "test_hsc40 = test_hsc40.loc[(test_hsc40 ['Number of students in testing year']>=20)] \n",
        "test_hsc40['Deviation of testing year'] = test_hsc40['GPA.1'] - test_hsc40['GPA'] \n",
        "test_hsc40 = pd.concat([test_hsc40[test_hsc40 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc40[test_hsc40['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc40 = test_hsc40.reset_index() \n",
        "features_drop40 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc40 = test_hsc40.drop(features_drop40 ,axis=1) \n",
        "test_hsc40.head() \n",
        "\n",
        "test_count41 = test_category41['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa41 = test_category41.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa41 = test_gpa41.reset_index() \n",
        "test_hsc41 = pd.merge(test_count41,test_gpa41) \n",
        "test_hsc41 = test_hsc41.loc[(test_hsc41 ['Number of students in testing year']>=20)] \n",
        "test_hsc41['Deviation of testing year'] = test_hsc41['GPA.1'] - test_hsc41['GPA'] \n",
        "test_hsc41 = pd.concat([test_hsc41[test_hsc41 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc41[test_hsc41['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc41 = test_hsc41.reset_index() \n",
        "features_drop41 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc41 = test_hsc41.drop(features_drop41 ,axis=1) \n",
        "test_hsc41.head() \n",
        "\n",
        "test_count42 = test_category42['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa42 = test_category42.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa42 = test_gpa42.reset_index() \n",
        "test_hsc42 = pd.merge(test_count42,test_gpa42) \n",
        "test_hsc42 = test_hsc42.loc[(test_hsc42 ['Number of students in testing year']>=20)] \n",
        "test_hsc42['Deviation of testing year'] = test_hsc42['GPA.1'] - test_hsc42['GPA'] \n",
        "test_hsc42 = pd.concat([test_hsc42[test_hsc42 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc42[test_hsc42['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc42 = test_hsc42.reset_index() \n",
        "features_drop42 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc42 = test_hsc42.drop(features_drop42 ,axis=1) \n",
        "test_hsc42.head() \n",
        "\n",
        "test_count43 = test_category43['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa43 = test_category43.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa43 = test_gpa43.reset_index() \n",
        "test_hsc43 = pd.merge(test_count43,test_gpa43) \n",
        "test_hsc43 = test_hsc43.loc[(test_hsc43 ['Number of students in testing year']>=20)] \n",
        "test_hsc43['Deviation of testing year'] = test_hsc43['GPA.1'] - test_hsc43['GPA'] \n",
        "test_hsc43 = pd.concat([test_hsc43[test_hsc43 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc43[test_hsc43['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc43 = test_hsc43.reset_index() \n",
        "features_drop43 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc43 = test_hsc43.drop(features_drop43 ,axis=1) \n",
        "test_hsc43.head() \n",
        "\n",
        "test_count44 = test_category44['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa44 = test_category44.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa44 = test_gpa44.reset_index() \n",
        "test_hsc44 = pd.merge(test_count44,test_gpa44) \n",
        "test_hsc44 = test_hsc44.loc[(test_hsc44 ['Number of students in testing year']>=20)] \n",
        "test_hsc44['Deviation of testing year'] = test_hsc44['GPA.1'] - test_hsc44['GPA'] \n",
        "test_hsc44 = pd.concat([test_hsc44[test_hsc44 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc44[test_hsc44['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc44 = test_hsc44.reset_index() \n",
        "features_drop44 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc44 = test_hsc44.drop(features_drop44 ,axis=1) \n",
        "test_hsc44.head() \n",
        "\n",
        "test_count45 = test_category45['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa45 = test_category45.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa45 = test_gpa45.reset_index() \n",
        "test_hsc45 = pd.merge(test_count45,test_gpa45) \n",
        "test_hsc45 = test_hsc45.loc[(test_hsc45 ['Number of students in testing year']>=20)] \n",
        "test_hsc45['Deviation of testing year'] = test_hsc45['GPA.1'] - test_hsc45['GPA'] \n",
        "test_hsc45 = pd.concat([test_hsc45[test_hsc45 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc45[test_hsc45['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc45 = test_hsc45.reset_index() \n",
        "features_drop45 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc45 = test_hsc45.drop(features_drop45 ,axis=1) \n",
        "test_hsc45.head() \n",
        "\n",
        "test_count46 = test_category46['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa46 = test_category46.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa46 = test_gpa46.reset_index() \n",
        "test_hsc46 = pd.merge(test_count46,test_gpa46) \n",
        "test_hsc46 = test_hsc46.loc[(test_hsc46 ['Number of students in testing year']>=20)] \n",
        "test_hsc46['Deviation of testing year'] = test_hsc46['GPA.1'] - test_hsc46['GPA'] \n",
        "test_hsc46 = pd.concat([test_hsc46[test_hsc46 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc46[test_hsc46['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc46 = test_hsc46.reset_index() \n",
        "features_drop46 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc46 = test_hsc46.drop(features_drop46 ,axis=1) \n",
        "test_hsc46.head() \n",
        "\n",
        "test_count47 = test_category47['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa47 = test_category47.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa47 = test_gpa47.reset_index() \n",
        "test_hsc47 = pd.merge(test_count47,test_gpa47) \n",
        "test_hsc47 = test_hsc47.loc[(test_hsc47 ['Number of students in testing year']>=20)] \n",
        "test_hsc47['Deviation of testing year'] = test_hsc47['GPA.1'] - test_hsc47['GPA'] \n",
        "test_hsc47 = pd.concat([test_hsc47[test_hsc47 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc47[test_hsc47['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc47 = test_hsc47.reset_index() \n",
        "features_drop47 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc47 = test_hsc47.drop(features_drop47 ,axis=1) \n",
        "test_hsc47.head() \n",
        "\n",
        "test_count48 = test_category48['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa48 = test_category48.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa48 = test_gpa48.reset_index() \n",
        "test_hsc48 = pd.merge(test_count48,test_gpa48) \n",
        "test_hsc48 = test_hsc48.loc[(test_hsc48 ['Number of students in testing year']>=20)] \n",
        "test_hsc48['Deviation of testing year'] = test_hsc48['GPA.1'] - test_hsc48['GPA'] \n",
        "test_hsc48 = pd.concat([test_hsc48[test_hsc48 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc48[test_hsc48['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc48 = test_hsc48.reset_index() \n",
        "features_drop48 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc48 = test_hsc48.drop(features_drop48 ,axis=1) \n",
        "test_hsc48.head() \n",
        "\n",
        "test_count49 = test_category49['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa49 = test_category49.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa49 = test_gpa49.reset_index() \n",
        "test_hsc49 = pd.merge(test_count49,test_gpa49) \n",
        "test_hsc49 = test_hsc49.loc[(test_hsc49 ['Number of students in testing year']>=20)] \n",
        "test_hsc49['Deviation of testing year'] = test_hsc49['GPA.1'] - test_hsc49['GPA'] \n",
        "test_hsc49 = pd.concat([test_hsc49[test_hsc49 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc49[test_hsc49['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc49 = test_hsc49.reset_index() \n",
        "features_drop49 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc49 = test_hsc49.drop(features_drop49 ,axis=1) \n",
        "test_hsc49.head() \n",
        "\n",
        "test_count50 = test_category50['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa50 = test_category50.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa50 = test_gpa50.reset_index() \n",
        "test_hsc50 = pd.merge(test_count50,test_gpa50) \n",
        "test_hsc50 = test_hsc50.loc[(test_hsc50 ['Number of students in testing year']>=20)] \n",
        "test_hsc50['Deviation of testing year'] = test_hsc50['GPA.1'] - test_hsc50['GPA'] \n",
        "test_hsc50 = pd.concat([test_hsc50[test_hsc50 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc50[test_hsc50['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc50 = test_hsc50.reset_index() \n",
        "features_drop50 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc50 = test_hsc50.drop(features_drop50 ,axis=1) \n",
        "test_hsc50.head() \n",
        "\n",
        "test_count51 = test_category51['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa51 = test_category51.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa51 = test_gpa51.reset_index() \n",
        "test_hsc51 = pd.merge(test_count51,test_gpa51) \n",
        "test_hsc51 = test_hsc51.loc[(test_hsc51 ['Number of students in testing year']>=20)] \n",
        "test_hsc51['Deviation of testing year'] = test_hsc51['GPA.1'] - test_hsc51['GPA'] \n",
        "test_hsc51 = pd.concat([test_hsc51[test_hsc51 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc51[test_hsc51['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc51 = test_hsc51.reset_index() \n",
        "features_drop51 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc51 = test_hsc51.drop(features_drop51 ,axis=1) \n",
        "test_hsc51.head() \n",
        "\n",
        "test_count52 = test_category52['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa52 = test_category52.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa52 = test_gpa52.reset_index() \n",
        "test_hsc52 = pd.merge(test_count52,test_gpa52) \n",
        "test_hsc52 = test_hsc52.loc[(test_hsc52 ['Number of students in testing year']>=20)] \n",
        "test_hsc52['Deviation of testing year'] = test_hsc52['GPA.1'] - test_hsc52['GPA'] \n",
        "test_hsc52 = pd.concat([test_hsc52[test_hsc52 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc52[test_hsc52['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc52 = test_hsc52.reset_index() \n",
        "features_drop52 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc52 = test_hsc52.drop(features_drop52 ,axis=1) \n",
        "test_hsc52.head() \n",
        "\n",
        "test_count53 = test_category53['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa53 = test_category53.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa53 = test_gpa53.reset_index() \n",
        "test_hsc53 = pd.merge(test_count53,test_gpa53) \n",
        "test_hsc53 = test_hsc53.loc[(test_hsc53 ['Number of students in testing year']>=20)] \n",
        "test_hsc53['Deviation of testing year'] = test_hsc53['GPA.1'] - test_hsc53['GPA'] \n",
        "test_hsc53 = pd.concat([test_hsc53[test_hsc53 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc53[test_hsc53['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc53 = test_hsc53.reset_index() \n",
        "features_drop53 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc53 = test_hsc53.drop(features_drop53 ,axis=1) \n",
        "test_hsc53.head() \n",
        "\n",
        "test_count54 = test_category54['INST_.1'].value_counts().rename_axis('INST_.1').reset_index(name='Number of students in testing year').sort_values(by='INST_.1') \n",
        "test_gpa54 = test_category54.groupby('INST_.1', as_index=True)[['GPA', 'GPA.1','STUD_GROUP','SEX','CATEGORY']].mean() \n",
        "test_gpa54 = test_gpa54.reset_index() \n",
        "test_hsc54 = pd.merge(test_count54,test_gpa54) \n",
        "test_hsc54 = test_hsc54.loc[(test_hsc54 ['Number of students in testing year']>=20)] \n",
        "test_hsc54['Deviation of testing year'] = test_hsc54['GPA.1'] - test_hsc54['GPA'] \n",
        "test_hsc54 = pd.concat([test_hsc54[test_hsc54 ['Deviation of testing year']>0].sort_values('Deviation of testing year',ascending=False), \n",
        "test_hsc54[test_hsc54['Deviation of testing year']< 0].sort_values('Deviation of testing year',ascending=False)]) \n",
        "test_hsc54 = test_hsc54.reset_index() \n",
        "features_drop54 = ['GPA','GPA.1','index','Number of students in testing year'] \n",
        "test_hsc54 = test_hsc54.drop(features_drop54 ,axis=1) \n",
        "test_hsc54.head() \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>INST_.1</th>\n",
              "      <th>STUD_GROUP</th>\n",
              "      <th>SEX</th>\n",
              "      <th>CATEGORY</th>\n",
              "      <th>Deviation of testing year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [INST_.1, STUD_GROUP, SEX, CATEGORY, Deviation of testing year]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JM9rjooYKdVH",
        "outputId": "9bb9958b-d64a-4165-9a6d-8b2019d87f2b"
      },
      "source": [
        "for i in range(49,55):\n",
        "    print(\"train_hsc\"+str(i)+\",\",end=\" \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_hsc49, train_hsc50, train_hsc51, train_hsc52, train_hsc53, train_hsc54, "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAWfQKWKGu5u",
        "outputId": "183a978c-5f0c-4b36-e345-b6a3d62c593d"
      },
      "source": [
        "train_frame =[train_hsc1, train_hsc2, train_hsc3, train_hsc4, train_hsc5, train_hsc6, train_hsc7, train_hsc8, train_hsc9, train_hsc10, train_hsc11, train_hsc12, train_hsc13, train_hsc14, train_hsc15, train_hsc16, train_hsc17, train_hsc18, train_hsc19, train_hsc20, train_hsc21, train_hsc22, train_hsc23, train_hsc24, train_hsc25, train_hsc26, train_hsc27, train_hsc28, train_hsc29, train_hsc30, train_hsc31, train_hsc32, train_hsc33, train_hsc34, train_hsc35, train_hsc36, train_hsc37, train_hsc38, train_hsc39, train_hsc40, train_hsc41, train_hsc42, train_hsc43, train_hsc44, train_hsc45, train_hsc46, train_hsc47, train_hsc48,train_hsc49, train_hsc50, train_hsc51, train_hsc52, train_hsc53, train_hsc54]\n",
        "train_df =pd.concat(train_frame)\n",
        "train_df=train_df.reset_index()\n",
        "train_df = train_df.drop(labels = ['index'],axis = 1)\n",
        "train_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(562, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmhWP1SXLIND",
        "outputId": "f168cd21-9beb-403f-c52f-752320e97cfc"
      },
      "source": [
        "for i in range(49,55):\n",
        "    print(\"test_hsc\"+str(i)+\",\",end=\" \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_hsc49, test_hsc50, test_hsc51, test_hsc52, test_hsc53, test_hsc54, "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DGU4-l6wCya",
        "outputId": "69926edf-d22d-4515-b114-ec5adcc6ab29"
      },
      "source": [
        "test_frame =[test_hsc1, test_hsc2, test_hsc3, test_hsc4, test_hsc5, test_hsc6, test_hsc7, test_hsc8, test_hsc9, test_hsc10, test_hsc11, test_hsc12, test_hsc13, test_hsc14, test_hsc15, test_hsc16, test_hsc17, test_hsc18, test_hsc19, test_hsc20, test_hsc21, test_hsc22, test_hsc23, test_hsc24, test_hsc25, test_hsc26, test_hsc27, test_hsc28, test_hsc29, test_hsc30, test_hsc31, test_hsc32, test_hsc33, test_hsc34, test_hsc35, test_hsc36, test_hsc37, test_hsc38, test_hsc39, test_hsc40, test_hsc41, test_hsc42, test_hsc43, test_hsc44, test_hsc45, test_hsc46, test_hsc47, test_hsc48,test_hsc49, test_hsc50, test_hsc51, test_hsc52, test_hsc53, test_hsc54]\n",
        "test_df =pd.concat(test_frame)\n",
        "test_df =test_df.sort_values(by=\"Deviation of testing year\",ascending=True)\n",
        "test_df=test_df.reset_index()\n",
        "test_df = test_df.drop(labels = ['index'],axis = 1)\n",
        "test_df.shape\n",
        "#test_df = test_df.rename({'SEX': 'Gender', 'Deviation of testing year': 'Deviation of HSC 15'}, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(659, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceWF5D3i0vVY"
      },
      "source": [
        "**Pivot Table** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOpkgg0npZPr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "FiWzohTwiUZi",
        "outputId": "2d507059-c67c-450d-bdce-ef8152720311"
      },
      "source": [
        "train_matrix = train_df.pivot(columns='CATEGORY',index=['INST_.1'],values='Deviation of training year').fillna(0)\n",
        "train_matrix=train_matrix.reset_index()\n",
        "train_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>CATEGORY</th>\n",
              "      <th>INST_.1</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000</td>\n",
              "      <td>-0.706034</td>\n",
              "      <td>-0.993038</td>\n",
              "      <td>-1.069863</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.452523</td>\n",
              "      <td>-0.454834</td>\n",
              "      <td>-0.703333</td>\n",
              "      <td>-0.740217</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.903571</td>\n",
              "      <td>-0.696825</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.024255</td>\n",
              "      <td>-0.860566</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.572533</td>\n",
              "      <td>-0.523913</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1001</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.276190</td>\n",
              "      <td>-0.920896</td>\n",
              "      <td>-0.750577</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.139362</td>\n",
              "      <td>-0.947391</td>\n",
              "      <td>-0.646140</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1002</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.561702</td>\n",
              "      <td>-0.396296</td>\n",
              "      <td>-0.234792</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1004</td>\n",
              "      <td>-0.315862</td>\n",
              "      <td>-0.317793</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1025</td>\n",
              "      <td>-0.220045</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.093269</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>2625</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.790238</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.302174</td>\n",
              "      <td>0.385417</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>2650</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.742927</td>\n",
              "      <td>-0.908906</td>\n",
              "      <td>-0.822292</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.912273</td>\n",
              "      <td>-0.947290</td>\n",
              "      <td>-0.606489</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>2651</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.419811</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>2652</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.314146</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.437174</td>\n",
              "      <td>0.445946</td>\n",
              "      <td>0.675556</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>2675</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.202727</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>116 rows  32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "CATEGORY  INST_.1         1         2         3    4  ...   43   47   48   49   50\n",
              "0            1000 -0.706034 -0.993038 -1.069863  0.0  ...  0.0  0.0  0.0  0.0  0.0\n",
              "1            1001  0.000000  0.000000  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0\n",
              "2            1002  0.000000  0.000000  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0\n",
              "3            1004 -0.315862 -0.317793  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0\n",
              "4            1025 -0.220045  0.000000  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0\n",
              "..            ...       ...       ...       ...  ...  ...  ...  ...  ...  ...  ...\n",
              "111          2625  0.000000  0.000000  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0\n",
              "112          2650  0.000000  0.000000  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0\n",
              "113          2651  0.000000  0.000000  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0\n",
              "114          2652  0.000000  0.000000  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0\n",
              "115          2675  0.000000  0.000000  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0\n",
              "\n",
              "[116 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 437
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "xYFPQsdeoNpz",
        "outputId": "bca88559-4f73-407d-8751-9bc0245a11d2"
      },
      "source": [
        "test_matrix = test_df.pivot(columns='CATEGORY',index=['INST_.1'],values='Deviation of testing year').fillna(0)\n",
        "test_matrix =test_matrix.reset_index()\n",
        "test_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>CATEGORY</th>\n",
              "      <th>INST_.1</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000</td>\n",
              "      <td>-0.843770</td>\n",
              "      <td>-0.933793</td>\n",
              "      <td>-0.866</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.72</td>\n",
              "      <td>-0.743588</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.043235</td>\n",
              "      <td>-0.938298</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.915758</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.372400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.688519</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1001</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.197895</td>\n",
              "      <td>-0.986275</td>\n",
              "      <td>-0.98560</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.997436</td>\n",
              "      <td>-0.971818</td>\n",
              "      <td>-0.845714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1002</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.769545</td>\n",
              "      <td>-0.908710</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.748276</td>\n",
              "      <td>-0.573913</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1004</td>\n",
              "      <td>-0.399828</td>\n",
              "      <td>-0.491273</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1010</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.553500</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>2625</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.456154</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.560417</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.736818</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>2650</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.004857</td>\n",
              "      <td>-0.770133</td>\n",
              "      <td>-0.73697</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.360385</td>\n",
              "      <td>-0.436667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.640455</td>\n",
              "      <td>-0.848043</td>\n",
              "      <td>-0.732208</td>\n",
              "      <td>-0.538684</td>\n",
              "      <td>-0.396522</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>2651</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.625263</td>\n",
              "      <td>-0.865306</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.617727</td>\n",
              "      <td>-0.682800</td>\n",
              "      <td>-0.582500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>2652</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.269412</td>\n",
              "      <td>-0.034000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.170256</td>\n",
              "      <td>-0.014898</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>2675</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.394286</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.431563</td>\n",
              "      <td>-0.385862</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>141 rows  33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "CATEGORY  INST_.1         1         2      3  ...   47        48   49   50\n",
              "0            1000 -0.843770 -0.933793 -0.866  ...  0.0 -0.688519  0.0  0.0\n",
              "1            1001  0.000000  0.000000  0.000  ...  0.0  0.000000  0.0  0.0\n",
              "2            1002  0.000000  0.000000  0.000  ...  0.0  0.000000  0.0  0.0\n",
              "3            1004 -0.399828 -0.491273  0.000  ...  0.0  0.000000  0.0  0.0\n",
              "4            1010  0.000000  0.000000  0.000  ...  0.0  0.000000  0.0  0.0\n",
              "..            ...       ...       ...    ...  ...  ...       ...  ...  ...\n",
              "136          2625  0.000000  0.000000  0.000  ...  0.0  0.000000  0.0  0.0\n",
              "137          2650  0.000000  0.000000  0.000  ...  0.0  0.000000  0.0  0.0\n",
              "138          2651  0.000000  0.000000  0.000  ...  0.0  0.000000  0.0  0.0\n",
              "139          2652  0.000000  0.000000  0.000  ...  0.0  0.000000  0.0  0.0\n",
              "140          2675  0.000000  0.000000  0.000  ...  0.0  0.000000  0.0  0.0\n",
              "\n",
              "[141 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 439
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "wLvxwFpNlvyP",
        "outputId": "6d98fee6-70b1-410f-dcbd-56ed24db3a1c"
      },
      "source": [
        "'''train_matrix = train_df.pivot(columns='CATEGORY',index=['INST_.1'],values='Deviation of training year')\n",
        "train_matrix=train_matrix.reset_index()\n",
        "train_matrix.head(10)'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"train_matrix = train_df.pivot(columns='CATEGORY',index=['INST_.1'],values='Deviation of training year')\\ntrain_matrix=train_matrix.reset_index()\\ntrain_matrix.head(10)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 405
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeLltetIxwiE"
      },
      "source": [
        "**Pivot table to normal table**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "KQOJ-J6OGZex",
        "outputId": "4d136ebf-b4ce-4048-e32e-b66d7f9877ef"
      },
      "source": [
        "train_n = (train_matrix.set_index([\"INST_.1\"])\n",
        "         .stack()\n",
        "         .reset_index(name='Deviation of training year')\n",
        "         .rename(columns={'level_2':'CATEGORY'}))\n",
        "train_n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>INST_.1</th>\n",
              "      <th>CATEGORY</th>\n",
              "      <th>Deviation of training year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.706034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.993038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000</td>\n",
              "      <td>3</td>\n",
              "      <td>-1.069863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3591</th>\n",
              "      <td>2675</td>\n",
              "      <td>43</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3592</th>\n",
              "      <td>2675</td>\n",
              "      <td>47</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3593</th>\n",
              "      <td>2675</td>\n",
              "      <td>48</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3594</th>\n",
              "      <td>2675</td>\n",
              "      <td>49</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3595</th>\n",
              "      <td>2675</td>\n",
              "      <td>50</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3596 rows  3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      INST_.1  CATEGORY  Deviation of training year\n",
              "0        1000         1                   -0.706034\n",
              "1        1000         2                   -0.993038\n",
              "2        1000         3                   -1.069863\n",
              "3        1000         4                    0.000000\n",
              "4        1000         5                    0.000000\n",
              "...       ...       ...                         ...\n",
              "3591     2675        43                    0.000000\n",
              "3592     2675        47                    0.000000\n",
              "3593     2675        48                    0.000000\n",
              "3594     2675        49                    0.000000\n",
              "3595     2675        50                    0.000000\n",
              "\n",
              "[3596 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 438
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "OQbFXzTlwh5N",
        "outputId": "746e2ada-5bd9-44d0-d5b8-ffa39e052131"
      },
      "source": [
        "test_n = (test_matrix.set_index([\"INST_.1\"])\n",
        "         .stack()\n",
        "         .reset_index(name='Deviation of testing year')\n",
        "         .rename(columns={'level_2':'CATEGORY'}))\n",
        "test_n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>INST_.1</th>\n",
              "      <th>CATEGORY</th>\n",
              "      <th>Deviation of testing year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.843770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.933793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.866000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000</td>\n",
              "      <td>11</td>\n",
              "      <td>-0.720000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4507</th>\n",
              "      <td>2675</td>\n",
              "      <td>43</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4508</th>\n",
              "      <td>2675</td>\n",
              "      <td>47</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4509</th>\n",
              "      <td>2675</td>\n",
              "      <td>48</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4510</th>\n",
              "      <td>2675</td>\n",
              "      <td>49</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4511</th>\n",
              "      <td>2675</td>\n",
              "      <td>50</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4512 rows  3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      INST_.1  CATEGORY  Deviation of testing year\n",
              "0        1000         1                  -0.843770\n",
              "1        1000         2                  -0.933793\n",
              "2        1000         3                  -0.866000\n",
              "3        1000         4                   0.000000\n",
              "4        1000        11                  -0.720000\n",
              "...       ...       ...                        ...\n",
              "4507     2675        43                   0.000000\n",
              "4508     2675        47                   0.000000\n",
              "4509     2675        48                   0.000000\n",
              "4510     2675        49                   0.000000\n",
              "4511     2675        50                   0.000000\n",
              "\n",
              "[4512 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 440
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bevrw7-Ccjqf"
      },
      "source": [
        "train_n=train_n.round({\"Deviation of training year\":2}) \n",
        "test_n=test_n.round({\"Deviation of testing year\":2}) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOZd3baYPZdS"
      },
      "source": [
        "known_train =train_n.loc[(train_n['Deviation of training year']!=0)]\n",
        "known_test =test_n.loc[(test_n['Deviation of testing year']!=0)]\n",
        "\n",
        "unknown_train =train_n.loc[(train_n['Deviation of training year']==0)]\n",
        "unknown_test =test_n.loc[(test_n['Deviation of testing year']==0)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "HmHiUkpGp1xy",
        "outputId": "7a188fe3-1f62-4f9a-809b-b0f0570c684b"
      },
      "source": [
        "known_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>INST_.1</th>\n",
              "      <th>CATEGORY</th>\n",
              "      <th>Deviation of training year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.706034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.993038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000</td>\n",
              "      <td>3</td>\n",
              "      <td>-1.069863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1000</td>\n",
              "      <td>11</td>\n",
              "      <td>-0.452523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1000</td>\n",
              "      <td>12</td>\n",
              "      <td>-0.454834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3542</th>\n",
              "      <td>2652</td>\n",
              "      <td>14</td>\n",
              "      <td>0.314146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3557</th>\n",
              "      <td>2652</td>\n",
              "      <td>40</td>\n",
              "      <td>0.437174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3558</th>\n",
              "      <td>2652</td>\n",
              "      <td>41</td>\n",
              "      <td>0.445946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3559</th>\n",
              "      <td>2652</td>\n",
              "      <td>42</td>\n",
              "      <td>0.675556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3589</th>\n",
              "      <td>2675</td>\n",
              "      <td>41</td>\n",
              "      <td>-0.202727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>562 rows  3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      INST_.1  CATEGORY  Deviation of training year\n",
              "0        1000         1                   -0.706034\n",
              "1        1000         2                   -0.993038\n",
              "2        1000         3                   -1.069863\n",
              "5        1000        11                   -0.452523\n",
              "6        1000        12                   -0.454834\n",
              "...       ...       ...                         ...\n",
              "3542     2652        14                    0.314146\n",
              "3557     2652        40                    0.437174\n",
              "3558     2652        41                    0.445946\n",
              "3559     2652        42                    0.675556\n",
              "3589     2675        41                   -0.202727\n",
              "\n",
              "[562 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 442
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeXQGhxHffNQ",
        "outputId": "9e880854-c988-45e1-cd7f-e35379793deb"
      },
      "source": [
        "print(known_train.shape)\n",
        "print(unknown_train.shape)\n",
        "print(known_test.shape)\n",
        "print(unknown_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(562, 3)\n",
            "(3034, 3)\n",
            "(659, 3)\n",
            "(3853, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4zyHRyZcu8I",
        "outputId": "de49b928-cb8d-4b50-ba27-49515dbf9e60"
      },
      "source": [
        "n_items = train_df[\"INST_.1\"].unique().shape[0]\n",
        "n_users = train_df[\"CATEGORY\"].unique().shape[0]\n",
        "print (str(n_items) + ' items')\n",
        "print (str(n_users) + ' users')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "116 items\n",
            "31 users\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y58qZqip01pf"
      },
      "source": [
        "**Machine learning approach**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOKMiAwI3eTf"
      },
      "source": [
        "train_n=train_n.round({\"Deviation of training year\":3}) \n",
        "test_n=test_n.round({\"Deviation of testing year\":3}) \n",
        "\n",
        "known_train =train_n.loc[(train_n['Deviation of training year']!=0)]\n",
        "known_test =test_n.loc[(test_n['Deviation of testing year']!=0)]\n",
        "\n",
        "\n",
        "ytn = known_train[\"Deviation of training year\"]\n",
        "Xtn = known_train.drop(columns=[\"Deviation of training year\"])\n",
        "\n",
        "\n",
        "yts = known_test[\"Deviation of testing year\"]\n",
        "Xts = known_test.drop(columns=[\"Deviation of testing year\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-LgMO_6WH6j",
        "outputId": "fcfb495c-465c-4fa4-d56e-ebbce1628b0c"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import linear_model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "train_n=train_n.round({\"Deviation of training year\":3}) \n",
        "test_n=test_n.round({\"Deviation of testing year\":3}) \n",
        "\n",
        "known_train =train_n.loc[(train_n['Deviation of training year']!=0)]\n",
        "known_test =test_n.loc[(test_n['Deviation of testing year']!=0)]\n",
        "\n",
        "\n",
        "ytn = known_train[\"Deviation of training year\"]\n",
        "Xtn = known_train.drop(columns=[\"Deviation of training year\"])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xtn,ytn,test_size=0.2,random_state= 39)\n",
        "#model=  LinearRegression()\n",
        "RT =RandomForestRegressor(n_estimators= 100,random_state= 41)\n",
        "#model=SVR()\n",
        "knn = KNeighborsRegressor(n_neighbors= 2)\n",
        "knn.fit(X_train,y_train)\n",
        "knn.score(X_test,y_test)\n",
        "\n",
        "\n",
        "RT.fit(X_train,y_train)\n",
        "RT.score(X_test,y_test)\n",
        "\n",
        "print(knn.score(X_test,y_test))\n",
        "\n",
        "print(RT.score(X_test,y_test))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.39849223148343416\n",
            "0.3433707914581574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bVM4qLffG_C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H63351GDFvPG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3902259a-16ee-4c5f-b9a4-216d59b71ca5"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(Xts,yts,test_size=.2, random_state= 51)\n",
        "#model_test=  LinearRegression()\n",
        "model_test =RandomForestRegressor(n_estimators= 41)\n",
        "model_test.fit(X_train,y_train)\n",
        "model_test.score(X_test,y_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test,model_test.predict(X_test)))\n",
        "print(model_test.score(X_test,y_test))\n",
        "print(rmse)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.42902725605659453\n",
            "0.2691285619368844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bwXJCBowDnv"
      },
      "source": [
        "**CrossValidation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa2DwmTKv9ZT"
      },
      "source": [
        "train_n=train_n.round({\"Deviation of training year\":3}) \n",
        "test_n=test_n.round({\"Deviation of testing year\":3}) \n",
        "known_train =train_n.loc[(train_n['Deviation of training year']!=0)]\n",
        "known_test =test_n.loc[(test_n['Deviation of testing year']!=0)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fphFok1qv9ZT",
        "outputId": "bdb98fb1-cc64-45b1-98f1-35cb2378d3d9"
      },
      "source": [
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import cross_val_score\n",
        "y = known_train[\"Deviation of training year\"]\n",
        "X = known_train.drop(columns=[\"Deviation of training year\"])\n",
        "\n",
        "cv = ShuffleSplit(n_splits= 2, test_size=0.20,random_state= 39)\n",
        "'''cv = ShuffleSplit(n_splits= 5, test_size=0.10, random_state= 1000)\n",
        "score_rt = cross_val_score(RandomForestRegressor(n_estimators=49), X, y, cv=cv)\n",
        "cross_val_scores = cross_val_score(RandomForestRegressor(n_estimators=100), X, y,cv=cv)'''\n",
        "\n",
        "\n",
        "#score=cross_val_score(model, X, y, cv=cv)\n",
        "score_svr =cross_val_score(SVR(kernel='rbf'), X, y, cv=cv)\n",
        "score_dt =cross_val_score(DecisionTreeRegressor(max_depth=3), X, y, cv=cv)\n",
        "score_knn =cross_val_score(KNeighborsRegressor(n_neighbors= 2), X, y, cv=cv)\n",
        "\n",
        "#score_rt =cross_val_score(RandomForestRegressor(n_estimators= 41), X, y, cv=cv)\n",
        "score_rt = cross_val_score(RandomForestRegressor(n_estimators= 49), X, y, cv=cv)\n",
        "\n",
        "\n",
        "print(  \"SVM: \", score_svr.mean(),\"\\n\"\n",
        "  \"Decision Tree: \",score_dt.mean(),\"\\n\"\n",
        "  \"Random Forest: \",score_rt.mean(),\"\\n\"\n",
        "  \"KNN: \",score_knn.mean(),\"\\n\")\n",
        "#print(score_knn.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM:  0.006519096883382813 \n",
            "Decision Tree:  0.12054815006769154 \n",
            "Random Forest:  0.3956870739783535 \n",
            "KNN:  0.4180731996175115 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVrab_mnAaEb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5h7PjZ6Ab4R"
      },
      "source": [
        "**KNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "WWXlDdhCN__4",
        "outputId": "2e44f002-b476-4ed4-f0c5-53dda9c50001"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "y = known_train[\"Deviation of training year\"]\n",
        "X = known_train.drop(columns=[\"Deviation of training year\"])\n",
        "\n",
        "\n",
        "cv = ShuffleSplit(n_splits= 2, test_size=0.20,random_state= 39)\n",
        "# choose k between 1 to 31\n",
        "k_range = range(1, 31)\n",
        "k_scores = []\n",
        "# use iteration to caclulator different k in models, then return the average accuracy based on the cross validation\n",
        "for k in k_range:\n",
        "    knn = KNeighborsRegressor(n_neighbors=k)\n",
        "    scores = cross_val_score(knn, X, y, cv= cv)\n",
        "    k_scores.append(scores.mean())\n",
        "# plot to see clearly\n",
        "plt.plot(k_range, k_scores)\n",
        "plt.xlabel('Value of K for KNN')\n",
        "plt.ylabel('Cross-Validated Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWPQ9zCq5jL9",
        "outputId": "59b017dd-a9dd-4438-bc78-adb1f6a67f33"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import linear_model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "cv = ShuffleSplit(n_splits= 2, test_size=0.20,random_state= 39)\n",
        "\n",
        "y = known_train[\"Deviation of training year\"]\n",
        "X = known_train.drop(columns=[\"Deviation of training year\"])\n",
        "\n",
        "KNN = KNeighborsRegressor(n_neighbors = 2)\n",
        "knn = cross_val_score(KNN, X, y,cv=cv)\n",
        "y_pred = cross_val_predict(KNN, X, y, cv=2)\n",
        "knn_rmse = np.sqrt(mean_squared_error(y,y_pred))\n",
        "knn_mse = mean_squared_error(y,y_pred)\n",
        "knn_mae = mean_absolute_error(y,y_pred)\n",
        "\n",
        "\n",
        "print(knn)\n",
        "print(\"Accuracy of knn :\",knn.mean())\n",
        "print(\"knn of Model with Cross Validation is:\",knn.mean() * 100)\n",
        "\n",
        "\n",
        "print(\"knn_mse:\",knn_mse)\n",
        "print(\"knn_rmse: \",knn_rmse)\n",
        "print(\"knn_mae: \",knn_mae)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.39849223 0.43765417]\n",
            "Accuracy of knn : 0.4180731996175115\n",
            "knn of Model with Cross Validation is: 41.80731996175115\n",
            "knn_mse: 0.2319027815836299\n",
            "knn_rmse:  0.4815628532015628\n",
            "knn_mae:  0.4106076512455516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS6B7fJNTtes"
      },
      "source": [
        "unknown_train =train_n.loc[(train_n['Deviation of training year']==0)]\n",
        "unknown_df = unknown_train.drop(columns=[\"Deviation of training year\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4FQE6W6CA3R"
      },
      "source": [
        "**RandomForest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA1Q5l6XODC_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "c8268370-3d2f-4ad4-f2be-5b9d8e7b7bf2"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "cv = ShuffleSplit(n_splits= 2, test_size=0.20,random_state= 41)\n",
        "# choose k between 1 to 31\n",
        "k_range = range(50,100)\n",
        "k_scores = []\n",
        "# use iteration to caclulator different k in models, then return the average accuracy based on the cross validation\n",
        "for k in k_range:\n",
        "    knn = RandomForestRegressor(n_estimators =k,)\n",
        "    scores = cross_val_score(knn, X, y, cv= cv)\n",
        "    k_scores.append(scores.mean())\n",
        "# plot to see clearly\n",
        "plt.plot(k_range, k_scores)\n",
        "plt.xlabel('Value of K for random_forest')\n",
        "plt.ylabel('Cross-Validated Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4xVjAQev9ZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b15680b6-aa4f-419a-a79e-c63c3839e945"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "y = known_train[\"Deviation of training year\"]\n",
        "X = known_train.drop(columns=[\"Deviation of training year\"])\n",
        "\n",
        "cv = ShuffleSplit(n_splits= 2, test_size=0.20,random_state= 39)\n",
        "RandomForest = RandomForestRegressor(n_estimators= 97,random_state= 92)\n",
        "\n",
        "rt = cross_val_score(RandomForest ,X, y, cv=cv)\n",
        "#Knn =cross_val_score(KNeighborsRegressor(n_neighbors= 2), X, y, cv=cv)\n",
        "y_pred = cross_val_predict(RandomForest, X, y, cv=2)\n",
        "rt_rmse = np.sqrt(mean_squared_error(y,y_pred))\n",
        "mse=mean_squared_error(y,y_pred)\n",
        "\n",
        "print(rt)\n",
        "\n",
        "print(\"rt of Model with Cross Validation is:\",rt.mean() * 100)\n",
        "print(\"rt_rmse: \",rt_rmse)\n",
        "mse\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.34162172 0.4610881 ]\n",
            "rt of Model with Cross Validation is: 40.13549113153631\n",
            "rt_rmse:  0.46034893389633064\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.21192114093948822"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 421
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz5WURcaYvXX"
      },
      "source": [
        "known_train =train_n.loc[(train_n['Deviation of training year']!=0)]\n",
        "TRAIN_SIZE = 0.80\n",
        "# Create boolean mask\n",
        "# np.random creates a vector of random values between 0 and 1\n",
        "# Those values are filtered to create a binary mask\n",
        "msk = np.random.rand(len(known_train)) < TRAIN_SIZE\n",
        "\n",
        "train = known_train[msk]  \n",
        "test20 = known_train[~msk] \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDLGxjXBo2tC"
      },
      "source": [
        "**original**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "zkNmQ-4ZX6NX",
        "outputId": "b110580e-a42c-4147-d105-ca6d11a0ce4f"
      },
      "source": [
        "train_n= train_n.round({\"Deviation of training year\":3}) \n",
        "known_train =train_n.loc[(train_n['Deviation of training year']!=0)]\n",
        "\n",
        "ytn = known_train[\"Deviation of training year\"]\n",
        "Xtn = known_train.drop(columns=[\"Deviation of training year\"])\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xtn,ytn,test_size=0.2,random_state= 39)\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(Xtn,ytn,test_size=0.2,random_state= 39)\n",
        "#model=  LinearRegression()\n",
        "#model =RandomForestRegressor(n_estimators= 100,random_state= 41)\n",
        "model = KNeighborsRegressor(n_neighbors= 2)\n",
        "model.fit(X_train,y_train)\n",
        "model.score(X_test,y_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test,model.predict(X_test)))\n",
        "print(model.score(X_test,y_test))\n",
        "print(rmse)\n",
        "\n",
        "\n",
        "unknown_df = unknown_train.drop(columns=[\"Deviation of training year\"])\n",
        "y_pred = model.predict(unknown_df) \n",
        "y_pred  = pd.DataFrame(y_pred)\n",
        "y_pred = y_pred.rename({0: 'Deviation of training year'}, axis=1)\n",
        "y_pred\n",
        "unknown_df=unknown_df.reset_index()\n",
        "unknown_df=unknown_df.drop('index',axis=1)\n",
        "unknown_df\n",
        "df_out = pd.merge(unknown_df, y_pred, how = 'left', left_index = True, right_index = True)\n",
        "df_out\n",
        "known_train =known_train.reset_index()\n",
        "known_train=known_train.drop('index',axis=1)\n",
        "known_train\n",
        "train_frame =[known_train,df_out]\n",
        "reco_train =pd.concat(train_frame)\n",
        "original_train = reco_train.pivot(columns='CATEGORY',index='INST_.1',values='Deviation of training year')\n",
        "original_train\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.39849223148343416\n",
            "0.29692042153692244\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>CATEGORY</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>INST_.1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1000</th>\n",
              "      <td>-0.7060</td>\n",
              "      <td>-0.9930</td>\n",
              "      <td>-1.0700</td>\n",
              "      <td>-0.8495</td>\n",
              "      <td>-0.8495</td>\n",
              "      <td>-0.4530</td>\n",
              "      <td>-0.4550</td>\n",
              "      <td>-0.7030</td>\n",
              "      <td>-0.7400</td>\n",
              "      <td>-0.836</td>\n",
              "      <td>-0.8360</td>\n",
              "      <td>-0.8275</td>\n",
              "      <td>-0.9040</td>\n",
              "      <td>-0.6970</td>\n",
              "      <td>-0.9640</td>\n",
              "      <td>-0.9640</td>\n",
              "      <td>-0.9425</td>\n",
              "      <td>-1.0240</td>\n",
              "      <td>-0.8610</td>\n",
              "      <td>-0.9425</td>\n",
              "      <td>-0.9425</td>\n",
              "      <td>-0.5485</td>\n",
              "      <td>-0.5730</td>\n",
              "      <td>-0.5240</td>\n",
              "      <td>-0.8315</td>\n",
              "      <td>-0.3795</td>\n",
              "      <td>-0.3795</td>\n",
              "      <td>-0.3795</td>\n",
              "      <td>-0.3795</td>\n",
              "      <td>-0.3795</td>\n",
              "      <td>-0.3795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1001</th>\n",
              "      <td>-0.8495</td>\n",
              "      <td>-0.8495</td>\n",
              "      <td>-0.8495</td>\n",
              "      <td>-0.8495</td>\n",
              "      <td>-0.8495</td>\n",
              "      <td>-0.4540</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-1.2760</td>\n",
              "      <td>-0.9210</td>\n",
              "      <td>-0.751</td>\n",
              "      <td>-0.8360</td>\n",
              "      <td>-0.8275</td>\n",
              "      <td>-0.8275</td>\n",
              "      <td>-0.8275</td>\n",
              "      <td>-0.8275</td>\n",
              "      <td>-0.9640</td>\n",
              "      <td>-0.9425</td>\n",
              "      <td>-0.9425</td>\n",
              "      <td>-0.9425</td>\n",
              "      <td>-0.9425</td>\n",
              "      <td>-0.9425</td>\n",
              "      <td>-0.8560</td>\n",
              "      <td>-0.8560</td>\n",
              "      <td>-1.1390</td>\n",
              "      <td>-0.9470</td>\n",
              "      <td>-0.6460</td>\n",
              "      <td>-0.6870</td>\n",
              "      <td>-0.6870</td>\n",
              "      <td>-0.6870</td>\n",
              "      <td>-0.6870</td>\n",
              "      <td>-0.6870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1002</th>\n",
              "      <td>-0.5110</td>\n",
              "      <td>-0.6555</td>\n",
              "      <td>-0.6555</td>\n",
              "      <td>-0.6555</td>\n",
              "      <td>-0.6555</td>\n",
              "      <td>-0.8645</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-1.0985</td>\n",
              "      <td>-1.0985</td>\n",
              "      <td>-0.836</td>\n",
              "      <td>-0.8360</td>\n",
              "      <td>-0.8275</td>\n",
              "      <td>-0.8275</td>\n",
              "      <td>-0.8275</td>\n",
              "      <td>-0.8275</td>\n",
              "      <td>-0.9640</td>\n",
              "      <td>-0.9425</td>\n",
              "      <td>-0.9425</td>\n",
              "      <td>-0.9425</td>\n",
              "      <td>-0.9425</td>\n",
              "      <td>-0.9425</td>\n",
              "      <td>-0.5675</td>\n",
              "      <td>-0.8505</td>\n",
              "      <td>-0.5620</td>\n",
              "      <td>-0.3960</td>\n",
              "      <td>-0.2350</td>\n",
              "      <td>-0.3985</td>\n",
              "      <td>-0.3985</td>\n",
              "      <td>-0.3985</td>\n",
              "      <td>-0.3985</td>\n",
              "      <td>-0.3985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1004</th>\n",
              "      <td>-0.3160</td>\n",
              "      <td>-0.3180</td>\n",
              "      <td>-0.3170</td>\n",
              "      <td>-0.3170</td>\n",
              "      <td>-0.3170</td>\n",
              "      <td>-0.8645</td>\n",
              "      <td>-1.0985</td>\n",
              "      <td>-1.0985</td>\n",
              "      <td>-1.0985</td>\n",
              "      <td>-0.836</td>\n",
              "      <td>-0.8360</td>\n",
              "      <td>-0.8275</td>\n",
              "      <td>-0.8275</td>\n",
              "      <td>-0.8275</td>\n",
              "      <td>-0.8275</td>\n",
              "      <td>-0.9640</td>\n",
              "      <td>-0.9425</td>\n",
              "      <td>-0.9425</td>\n",
              "      <td>-0.9425</td>\n",
              "      <td>-0.9425</td>\n",
              "      <td>-0.9425</td>\n",
              "      <td>-0.8505</td>\n",
              "      <td>-0.8505</td>\n",
              "      <td>-0.3985</td>\n",
              "      <td>-0.3985</td>\n",
              "      <td>-0.3985</td>\n",
              "      <td>-0.3985</td>\n",
              "      <td>-0.3985</td>\n",
              "      <td>-0.3985</td>\n",
              "      <td>-0.3985</td>\n",
              "      <td>-0.3985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1025</th>\n",
              "      <td>-0.2200</td>\n",
              "      <td>-0.5280</td>\n",
              "      <td>-0.7395</td>\n",
              "      <td>-0.7395</td>\n",
              "      <td>-0.7395</td>\n",
              "      <td>-0.1650</td>\n",
              "      <td>-0.1650</td>\n",
              "      <td>-0.1650</td>\n",
              "      <td>-0.1650</td>\n",
              "      <td>-0.165</td>\n",
              "      <td>-0.1650</td>\n",
              "      <td>-0.1650</td>\n",
              "      <td>-0.1650</td>\n",
              "      <td>-0.1205</td>\n",
              "      <td>-0.3725</td>\n",
              "      <td>-0.3725</td>\n",
              "      <td>-0.0930</td>\n",
              "      <td>-0.3725</td>\n",
              "      <td>-0.3725</td>\n",
              "      <td>-0.3725</td>\n",
              "      <td>-0.3725</td>\n",
              "      <td>-0.5340</td>\n",
              "      <td>-0.5340</td>\n",
              "      <td>-0.5340</td>\n",
              "      <td>-0.5340</td>\n",
              "      <td>-0.5340</td>\n",
              "      <td>-0.5340</td>\n",
              "      <td>-0.5340</td>\n",
              "      <td>-0.5340</td>\n",
              "      <td>-0.5340</td>\n",
              "      <td>-0.5340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2625</th>\n",
              "      <td>0.0235</td>\n",
              "      <td>0.0235</td>\n",
              "      <td>0.0235</td>\n",
              "      <td>0.0235</td>\n",
              "      <td>0.0235</td>\n",
              "      <td>0.0235</td>\n",
              "      <td>0.0235</td>\n",
              "      <td>0.0235</td>\n",
              "      <td>0.0235</td>\n",
              "      <td>0.790</td>\n",
              "      <td>0.1935</td>\n",
              "      <td>0.5460</td>\n",
              "      <td>0.5460</td>\n",
              "      <td>0.5460</td>\n",
              "      <td>0.5460</td>\n",
              "      <td>0.5460</td>\n",
              "      <td>0.5460</td>\n",
              "      <td>0.3435</td>\n",
              "      <td>0.3435</td>\n",
              "      <td>0.3435</td>\n",
              "      <td>0.3435</td>\n",
              "      <td>0.3435</td>\n",
              "      <td>0.3435</td>\n",
              "      <td>0.3435</td>\n",
              "      <td>0.3020</td>\n",
              "      <td>0.3850</td>\n",
              "      <td>0.3435</td>\n",
              "      <td>0.3435</td>\n",
              "      <td>0.3435</td>\n",
              "      <td>0.3435</td>\n",
              "      <td>0.3435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2650</th>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.7430</td>\n",
              "      <td>-0.9090</td>\n",
              "      <td>-0.822</td>\n",
              "      <td>-0.2540</td>\n",
              "      <td>-0.2540</td>\n",
              "      <td>-0.2540</td>\n",
              "      <td>-0.2540</td>\n",
              "      <td>-0.2540</td>\n",
              "      <td>-0.2540</td>\n",
              "      <td>-0.2375</td>\n",
              "      <td>-0.2375</td>\n",
              "      <td>-0.2375</td>\n",
              "      <td>-0.2375</td>\n",
              "      <td>-0.2375</td>\n",
              "      <td>-0.2375</td>\n",
              "      <td>-0.9295</td>\n",
              "      <td>-0.9120</td>\n",
              "      <td>-0.9470</td>\n",
              "      <td>-0.6060</td>\n",
              "      <td>-0.7765</td>\n",
              "      <td>0.0350</td>\n",
              "      <td>0.0350</td>\n",
              "      <td>0.0350</td>\n",
              "      <td>0.0350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2651</th>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.254</td>\n",
              "      <td>-0.2540</td>\n",
              "      <td>-0.2540</td>\n",
              "      <td>-0.2540</td>\n",
              "      <td>-0.2540</td>\n",
              "      <td>-0.2540</td>\n",
              "      <td>-0.2540</td>\n",
              "      <td>-0.2375</td>\n",
              "      <td>-0.2375</td>\n",
              "      <td>-0.2375</td>\n",
              "      <td>-0.2375</td>\n",
              "      <td>-0.2375</td>\n",
              "      <td>-0.2375</td>\n",
              "      <td>-0.2375</td>\n",
              "      <td>-0.4200</td>\n",
              "      <td>-0.2550</td>\n",
              "      <td>0.0350</td>\n",
              "      <td>0.0350</td>\n",
              "      <td>0.0350</td>\n",
              "      <td>0.0350</td>\n",
              "      <td>0.0350</td>\n",
              "      <td>0.0350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2652</th>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>0.3140</td>\n",
              "      <td>-0.254</td>\n",
              "      <td>-0.2540</td>\n",
              "      <td>-0.2540</td>\n",
              "      <td>-0.2540</td>\n",
              "      <td>-0.2540</td>\n",
              "      <td>-0.2540</td>\n",
              "      <td>-0.2540</td>\n",
              "      <td>-0.2375</td>\n",
              "      <td>-0.2375</td>\n",
              "      <td>-0.2375</td>\n",
              "      <td>-0.2375</td>\n",
              "      <td>-0.2375</td>\n",
              "      <td>-0.2375</td>\n",
              "      <td>-0.2375</td>\n",
              "      <td>0.4370</td>\n",
              "      <td>0.4460</td>\n",
              "      <td>0.6760</td>\n",
              "      <td>0.0350</td>\n",
              "      <td>0.0350</td>\n",
              "      <td>0.0350</td>\n",
              "      <td>0.0350</td>\n",
              "      <td>0.0350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2675</th>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.2145</td>\n",
              "      <td>-0.254</td>\n",
              "      <td>0.0555</td>\n",
              "      <td>0.0555</td>\n",
              "      <td>0.0555</td>\n",
              "      <td>0.0555</td>\n",
              "      <td>0.0555</td>\n",
              "      <td>0.0555</td>\n",
              "      <td>0.1170</td>\n",
              "      <td>0.1170</td>\n",
              "      <td>0.1170</td>\n",
              "      <td>0.1170</td>\n",
              "      <td>0.1170</td>\n",
              "      <td>0.1170</td>\n",
              "      <td>0.1170</td>\n",
              "      <td>0.1170</td>\n",
              "      <td>-0.2030</td>\n",
              "      <td>0.2365</td>\n",
              "      <td>0.2365</td>\n",
              "      <td>0.2365</td>\n",
              "      <td>0.2365</td>\n",
              "      <td>0.2365</td>\n",
              "      <td>0.2365</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>116 rows  31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "CATEGORY      1       2       3       4   ...      47      48      49      50\n",
              "INST_.1                                   ...                                \n",
              "1000     -0.7060 -0.9930 -1.0700 -0.8495  ... -0.3795 -0.3795 -0.3795 -0.3795\n",
              "1001     -0.8495 -0.8495 -0.8495 -0.8495  ... -0.6870 -0.6870 -0.6870 -0.6870\n",
              "1002     -0.5110 -0.6555 -0.6555 -0.6555  ... -0.3985 -0.3985 -0.3985 -0.3985\n",
              "1004     -0.3160 -0.3180 -0.3170 -0.3170  ... -0.3985 -0.3985 -0.3985 -0.3985\n",
              "1025     -0.2200 -0.5280 -0.7395 -0.7395  ... -0.5340 -0.5340 -0.5340 -0.5340\n",
              "...          ...     ...     ...     ...  ...     ...     ...     ...     ...\n",
              "2625      0.0235  0.0235  0.0235  0.0235  ...  0.3435  0.3435  0.3435  0.3435\n",
              "2650     -0.2145 -0.2145 -0.2145 -0.2145  ...  0.0350  0.0350  0.0350  0.0350\n",
              "2651     -0.2145 -0.2145 -0.2145 -0.2145  ...  0.0350  0.0350  0.0350  0.0350\n",
              "2652     -0.2145 -0.2145 -0.2145 -0.2145  ...  0.0350  0.0350  0.0350  0.0350\n",
              "2675     -0.2145 -0.2145 -0.2145 -0.2145  ...  0.2365  0.2365  0.2365  0.2365\n",
              "\n",
              "[116 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 423
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "TUvoA6Iqluv7",
        "outputId": "4e02fdec-8d9c-4f72-81c3-eb0ea5e565a5"
      },
      "source": [
        "test_n=test_n.round({\"Deviation of testing year\":3}) \n",
        "known_test =test_n.loc[(test_n['Deviation of testing year']!=0)]\n",
        "\n",
        "yts = known_test[\"Deviation of testing year\"]\n",
        "Xts = known_test.drop(columns=[\"Deviation of testing year\"])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xts,yts,test_size=0.2,random_state= 51)\n",
        "#model=  LinearRegression()\n",
        "model =RandomForestRegressor(n_estimators= 33,random_state= 51)\n",
        "#model = KNeighborsRegressor(n_neighbors= 2)\n",
        "model.fit(X_train,y_train)\n",
        "model.score(X_test,y_test)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test,model.predict(X_test)))\n",
        "print(model.score(X_test,y_test))\n",
        "print(rmse)\n",
        "\n",
        "\n",
        "unknown_df = unknown_test.drop(columns=[\"Deviation of testing year\"])\n",
        "y_pred = model.predict(unknown_df) \n",
        "y_pred\n",
        "\n",
        "y_pred  = pd.DataFrame(y_pred)\n",
        "y_pred = y_pred.rename({0: 'Deviation of testing year'}, axis=1)\n",
        "y_pred\n",
        "unknown_df=unknown_df.reset_index()\n",
        "unknown_df=unknown_df.drop('index',axis=1)\n",
        "unknown_df\n",
        "df_out = pd.merge(unknown_df, y_pred, how = 'left', left_index = True, right_index = True)\n",
        "df_out\n",
        "known_test  =known_test.reset_index()\n",
        "known_test =known_test.drop('index',axis=1)\n",
        "test_frame =[known_test ,df_out]\n",
        "reco_test =pd.concat(test_frame)\n",
        "original_test = reco_test.pivot(columns='CATEGORY',index='INST_.1',values='Deviation of testing year')\n",
        "original_test\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4737617651917917\n",
            "0.2583707238208978\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>CATEGORY</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>INST_.1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1000</th>\n",
              "      <td>-0.844000</td>\n",
              "      <td>-0.934000</td>\n",
              "      <td>-0.866000</td>\n",
              "      <td>-0.864879</td>\n",
              "      <td>-0.720000</td>\n",
              "      <td>-0.744000</td>\n",
              "      <td>-0.767212</td>\n",
              "      <td>-0.926848</td>\n",
              "      <td>-0.911727</td>\n",
              "      <td>-0.908818</td>\n",
              "      <td>-0.943091</td>\n",
              "      <td>-1.043000</td>\n",
              "      <td>-0.938000</td>\n",
              "      <td>-0.914333</td>\n",
              "      <td>-0.906152</td>\n",
              "      <td>-0.888727</td>\n",
              "      <td>-0.801939</td>\n",
              "      <td>-0.916000</td>\n",
              "      <td>-0.808818</td>\n",
              "      <td>-0.751606</td>\n",
              "      <td>-0.751606</td>\n",
              "      <td>-0.545606</td>\n",
              "      <td>-0.545606</td>\n",
              "      <td>-0.372000</td>\n",
              "      <td>-0.707818</td>\n",
              "      <td>-0.761939</td>\n",
              "      <td>-0.718424</td>\n",
              "      <td>-0.649909</td>\n",
              "      <td>-0.655879</td>\n",
              "      <td>-0.689000</td>\n",
              "      <td>-0.656939</td>\n",
              "      <td>-0.632273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1001</th>\n",
              "      <td>-0.887758</td>\n",
              "      <td>-0.903394</td>\n",
              "      <td>-0.892091</td>\n",
              "      <td>-0.889606</td>\n",
              "      <td>-0.792576</td>\n",
              "      <td>-0.799121</td>\n",
              "      <td>-1.198000</td>\n",
              "      <td>-0.986000</td>\n",
              "      <td>-0.986000</td>\n",
              "      <td>-0.955424</td>\n",
              "      <td>-0.977939</td>\n",
              "      <td>-0.977939</td>\n",
              "      <td>-0.977939</td>\n",
              "      <td>-0.947727</td>\n",
              "      <td>-0.939545</td>\n",
              "      <td>-0.924576</td>\n",
              "      <td>-0.861970</td>\n",
              "      <td>-0.910333</td>\n",
              "      <td>-0.886909</td>\n",
              "      <td>-0.845394</td>\n",
              "      <td>-0.845394</td>\n",
              "      <td>-0.694727</td>\n",
              "      <td>-0.694727</td>\n",
              "      <td>-0.715667</td>\n",
              "      <td>-0.997000</td>\n",
              "      <td>-0.972000</td>\n",
              "      <td>-0.846000</td>\n",
              "      <td>-0.712030</td>\n",
              "      <td>-0.708394</td>\n",
              "      <td>-0.709455</td>\n",
              "      <td>-0.709455</td>\n",
              "      <td>-0.684788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1002</th>\n",
              "      <td>-0.834727</td>\n",
              "      <td>-0.844667</td>\n",
              "      <td>-0.825303</td>\n",
              "      <td>-0.822818</td>\n",
              "      <td>-0.743788</td>\n",
              "      <td>-0.750333</td>\n",
              "      <td>-0.770000</td>\n",
              "      <td>-0.909000</td>\n",
              "      <td>-0.825970</td>\n",
              "      <td>-0.800455</td>\n",
              "      <td>-0.822970</td>\n",
              "      <td>-0.822970</td>\n",
              "      <td>-0.854212</td>\n",
              "      <td>-0.818545</td>\n",
              "      <td>-0.791788</td>\n",
              "      <td>-0.769273</td>\n",
              "      <td>-0.716424</td>\n",
              "      <td>-0.757667</td>\n",
              "      <td>-0.736030</td>\n",
              "      <td>-0.694182</td>\n",
              "      <td>-0.694182</td>\n",
              "      <td>-0.549000</td>\n",
              "      <td>-0.549000</td>\n",
              "      <td>-0.570788</td>\n",
              "      <td>-0.748000</td>\n",
              "      <td>-0.574000</td>\n",
              "      <td>-0.678273</td>\n",
              "      <td>-0.557121</td>\n",
              "      <td>-0.581485</td>\n",
              "      <td>-0.582545</td>\n",
              "      <td>-0.582545</td>\n",
              "      <td>-0.557788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1004</th>\n",
              "      <td>-0.400000</td>\n",
              "      <td>-0.491000</td>\n",
              "      <td>-0.674485</td>\n",
              "      <td>-0.683364</td>\n",
              "      <td>-0.620364</td>\n",
              "      <td>-0.631667</td>\n",
              "      <td>-0.633576</td>\n",
              "      <td>-0.739545</td>\n",
              "      <td>-0.725818</td>\n",
              "      <td>-0.700303</td>\n",
              "      <td>-0.717667</td>\n",
              "      <td>-0.717667</td>\n",
              "      <td>-0.748909</td>\n",
              "      <td>-0.711697</td>\n",
              "      <td>-0.684939</td>\n",
              "      <td>-0.675515</td>\n",
              "      <td>-0.622333</td>\n",
              "      <td>-0.681121</td>\n",
              "      <td>-0.660091</td>\n",
              "      <td>-0.641152</td>\n",
              "      <td>-0.641152</td>\n",
              "      <td>-0.514333</td>\n",
              "      <td>-0.514333</td>\n",
              "      <td>-0.536121</td>\n",
              "      <td>-0.657939</td>\n",
              "      <td>-0.664061</td>\n",
              "      <td>-0.678273</td>\n",
              "      <td>-0.557121</td>\n",
              "      <td>-0.581485</td>\n",
              "      <td>-0.582545</td>\n",
              "      <td>-0.582545</td>\n",
              "      <td>-0.557788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1010</th>\n",
              "      <td>-0.516667</td>\n",
              "      <td>-0.484545</td>\n",
              "      <td>-0.605000</td>\n",
              "      <td>-0.633667</td>\n",
              "      <td>-0.557242</td>\n",
              "      <td>-0.567818</td>\n",
              "      <td>-0.519364</td>\n",
              "      <td>-0.554000</td>\n",
              "      <td>-0.550636</td>\n",
              "      <td>-0.542667</td>\n",
              "      <td>-0.596242</td>\n",
              "      <td>-0.596242</td>\n",
              "      <td>-0.631182</td>\n",
              "      <td>-0.592485</td>\n",
              "      <td>-0.569970</td>\n",
              "      <td>-0.560545</td>\n",
              "      <td>-0.507697</td>\n",
              "      <td>-0.566485</td>\n",
              "      <td>-0.570121</td>\n",
              "      <td>-0.551182</td>\n",
              "      <td>-0.551182</td>\n",
              "      <td>-0.484606</td>\n",
              "      <td>-0.484606</td>\n",
              "      <td>-0.509909</td>\n",
              "      <td>-0.608939</td>\n",
              "      <td>-0.658636</td>\n",
              "      <td>-0.672848</td>\n",
              "      <td>-0.552909</td>\n",
              "      <td>-0.577273</td>\n",
              "      <td>-0.578333</td>\n",
              "      <td>-0.578333</td>\n",
              "      <td>-0.553576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2625</th>\n",
              "      <td>-0.234970</td>\n",
              "      <td>-0.276364</td>\n",
              "      <td>-0.225879</td>\n",
              "      <td>-0.245545</td>\n",
              "      <td>-0.286242</td>\n",
              "      <td>-0.286242</td>\n",
              "      <td>-0.332818</td>\n",
              "      <td>0.456000</td>\n",
              "      <td>0.067485</td>\n",
              "      <td>0.186788</td>\n",
              "      <td>0.192970</td>\n",
              "      <td>0.175455</td>\n",
              "      <td>0.175455</td>\n",
              "      <td>0.117000</td>\n",
              "      <td>0.094273</td>\n",
              "      <td>0.118515</td>\n",
              "      <td>0.090364</td>\n",
              "      <td>-0.014061</td>\n",
              "      <td>-0.115636</td>\n",
              "      <td>-0.139333</td>\n",
              "      <td>-0.171879</td>\n",
              "      <td>-0.091424</td>\n",
              "      <td>-0.091424</td>\n",
              "      <td>-0.035303</td>\n",
              "      <td>-0.046667</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.226909</td>\n",
              "      <td>0.737000</td>\n",
              "      <td>0.431061</td>\n",
              "      <td>0.431061</td>\n",
              "      <td>0.431061</td>\n",
              "      <td>0.459970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2650</th>\n",
              "      <td>-0.745242</td>\n",
              "      <td>-0.786636</td>\n",
              "      <td>-0.736152</td>\n",
              "      <td>-0.797818</td>\n",
              "      <td>-0.880515</td>\n",
              "      <td>-0.880515</td>\n",
              "      <td>-1.005000</td>\n",
              "      <td>-0.770000</td>\n",
              "      <td>-0.737000</td>\n",
              "      <td>-0.621667</td>\n",
              "      <td>-0.423121</td>\n",
              "      <td>-0.425364</td>\n",
              "      <td>-0.425364</td>\n",
              "      <td>-0.360000</td>\n",
              "      <td>-0.437000</td>\n",
              "      <td>-0.396182</td>\n",
              "      <td>-0.417212</td>\n",
              "      <td>-0.498788</td>\n",
              "      <td>-0.615727</td>\n",
              "      <td>-0.645030</td>\n",
              "      <td>-0.776758</td>\n",
              "      <td>-0.725636</td>\n",
              "      <td>-0.725636</td>\n",
              "      <td>-0.640000</td>\n",
              "      <td>-0.848000</td>\n",
              "      <td>-0.732000</td>\n",
              "      <td>-0.539000</td>\n",
              "      <td>-0.397000</td>\n",
              "      <td>-0.319212</td>\n",
              "      <td>-0.319212</td>\n",
              "      <td>-0.319212</td>\n",
              "      <td>-0.290303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2651</th>\n",
              "      <td>-0.753879</td>\n",
              "      <td>-0.795273</td>\n",
              "      <td>-0.744788</td>\n",
              "      <td>-0.806455</td>\n",
              "      <td>-0.889152</td>\n",
              "      <td>-0.889152</td>\n",
              "      <td>-0.625000</td>\n",
              "      <td>-0.865000</td>\n",
              "      <td>-0.739303</td>\n",
              "      <td>-0.656333</td>\n",
              "      <td>-0.456606</td>\n",
              "      <td>-0.458848</td>\n",
              "      <td>-0.458848</td>\n",
              "      <td>-0.404970</td>\n",
              "      <td>-0.448697</td>\n",
              "      <td>-0.409152</td>\n",
              "      <td>-0.422697</td>\n",
              "      <td>-0.504273</td>\n",
              "      <td>-0.614242</td>\n",
              "      <td>-0.629606</td>\n",
              "      <td>-0.719515</td>\n",
              "      <td>-0.658455</td>\n",
              "      <td>-0.658455</td>\n",
              "      <td>-0.606121</td>\n",
              "      <td>-0.618000</td>\n",
              "      <td>-0.683000</td>\n",
              "      <td>-0.582000</td>\n",
              "      <td>-0.313242</td>\n",
              "      <td>-0.328545</td>\n",
              "      <td>-0.328545</td>\n",
              "      <td>-0.328545</td>\n",
              "      <td>-0.299636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2652</th>\n",
              "      <td>-0.362273</td>\n",
              "      <td>-0.403939</td>\n",
              "      <td>-0.368727</td>\n",
              "      <td>-0.390030</td>\n",
              "      <td>-0.411545</td>\n",
              "      <td>-0.411545</td>\n",
              "      <td>-0.269000</td>\n",
              "      <td>-0.034000</td>\n",
              "      <td>-0.196879</td>\n",
              "      <td>-0.153667</td>\n",
              "      <td>-0.142242</td>\n",
              "      <td>-0.142515</td>\n",
              "      <td>-0.142515</td>\n",
              "      <td>-0.121364</td>\n",
              "      <td>-0.141758</td>\n",
              "      <td>-0.102212</td>\n",
              "      <td>-0.173303</td>\n",
              "      <td>-0.205061</td>\n",
              "      <td>-0.327242</td>\n",
              "      <td>-0.306152</td>\n",
              "      <td>-0.310273</td>\n",
              "      <td>-0.272182</td>\n",
              "      <td>-0.272182</td>\n",
              "      <td>-0.217970</td>\n",
              "      <td>-0.170000</td>\n",
              "      <td>-0.015000</td>\n",
              "      <td>-0.295152</td>\n",
              "      <td>-0.166697</td>\n",
              "      <td>-0.182000</td>\n",
              "      <td>-0.182000</td>\n",
              "      <td>-0.182000</td>\n",
              "      <td>-0.153091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2675</th>\n",
              "      <td>-0.407242</td>\n",
              "      <td>-0.448909</td>\n",
              "      <td>-0.413697</td>\n",
              "      <td>-0.435000</td>\n",
              "      <td>-0.456515</td>\n",
              "      <td>-0.456515</td>\n",
              "      <td>-0.489091</td>\n",
              "      <td>-0.394000</td>\n",
              "      <td>-0.379212</td>\n",
              "      <td>-0.336000</td>\n",
              "      <td>-0.324576</td>\n",
              "      <td>-0.324848</td>\n",
              "      <td>-0.324848</td>\n",
              "      <td>-0.307061</td>\n",
              "      <td>-0.327455</td>\n",
              "      <td>-0.287909</td>\n",
              "      <td>-0.332485</td>\n",
              "      <td>-0.352848</td>\n",
              "      <td>-0.464121</td>\n",
              "      <td>-0.432121</td>\n",
              "      <td>-0.425333</td>\n",
              "      <td>-0.387242</td>\n",
              "      <td>-0.387242</td>\n",
              "      <td>-0.333030</td>\n",
              "      <td>-0.338818</td>\n",
              "      <td>-0.432000</td>\n",
              "      <td>-0.386000</td>\n",
              "      <td>-0.233242</td>\n",
              "      <td>-0.248545</td>\n",
              "      <td>-0.248545</td>\n",
              "      <td>-0.248545</td>\n",
              "      <td>-0.219636</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>141 rows  32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "CATEGORY        1         2         3   ...        48        49        50\n",
              "INST_.1                                 ...                              \n",
              "1000     -0.844000 -0.934000 -0.866000  ... -0.689000 -0.656939 -0.632273\n",
              "1001     -0.887758 -0.903394 -0.892091  ... -0.709455 -0.709455 -0.684788\n",
              "1002     -0.834727 -0.844667 -0.825303  ... -0.582545 -0.582545 -0.557788\n",
              "1004     -0.400000 -0.491000 -0.674485  ... -0.582545 -0.582545 -0.557788\n",
              "1010     -0.516667 -0.484545 -0.605000  ... -0.578333 -0.578333 -0.553576\n",
              "...            ...       ...       ...  ...       ...       ...       ...\n",
              "2625     -0.234970 -0.276364 -0.225879  ...  0.431061  0.431061  0.459970\n",
              "2650     -0.745242 -0.786636 -0.736152  ... -0.319212 -0.319212 -0.290303\n",
              "2651     -0.753879 -0.795273 -0.744788  ... -0.328545 -0.328545 -0.299636\n",
              "2652     -0.362273 -0.403939 -0.368727  ... -0.182000 -0.182000 -0.153091\n",
              "2675     -0.407242 -0.448909 -0.413697  ... -0.248545 -0.248545 -0.219636\n",
              "\n",
              "[141 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 424
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqpSzIkH-9UC"
      },
      "source": [
        "for i in range(1,1):\n",
        "  print(\"train_f\"+str(i)+\" = original_train[\"+str(i)+\"]\",\"\\n\"\n",
        "\"train_f\"+str(i)+\"= train_f\"+str(i)+\".reset_index()\",\"\\n\"\n",
        "\"train_f\"+str(i)+\" =train_f\"+str(i)+\".sort_values(by=\"+str(i)+\", ascending= False)\",\"\\n\"\n",
        "\"train_f\"+str(i)+\" =train_f\"+str(i)+\".reset_index()\",\"\\n\"\n",
        "\"train_f\"+str(i)+\" =train_f\"+str(i)+\".drop('index',axis=1)\",\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB8nCU87Kdn4"
      },
      "source": [
        "for i in range(1,1):\n",
        "  print(\"test_f\"+str(i)+\" = original_test[\"+str(i)+\"]\",\"\\n\"\n",
        "\"test_f\"+str(i)+\"= test_f\"+str(i)+\".reset_index()\",\"\\n\"\n",
        "\"test_f\"+str(i)+\" =test_f\"+str(i)+\".sort_values(by=\"+str(i)+\", ascending= False)\",\"\\n\"\n",
        "\"test_f\"+str(i)+\" =test_f\"+str(i)+\".reset_index()\",\"\\n\"\n",
        "\"test_f\"+str(i)+\" =test_f\"+str(i)+\".drop('index',axis=1)\",\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDvvbKFt__Hz"
      },
      "source": [
        "for i in range(1,1):\n",
        "  print(\"f_df\"+str(i)+\" = pd.merge(train_f\"+str(i)+\",test_hsc\"+str(i)+\",how='inner',on='INST_.1')\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0V-uz3gnkfB"
      },
      "source": [
        " def lcs(s1, s2, s1Index, s2Index, arr):\n",
        "    \n",
        "    if s1Index ==-1 or s2Index == -1:\n",
        "        return 0\n",
        "    if(arr[s1Index][s2Index] != None):\n",
        "        return arr[s1Index][s2Index]\n",
        "\n",
        "    if s1[s1Index] == s2 [s2Index]:\n",
        "        result = 1+ lcs(s1, s2, s1Index -1, s2Index -1, arr)\n",
        "    else:\n",
        "        result= max(lcs(s1, s2, s1Index -1, s2Index, arr), lcs(s1, s2, s1Index, s2Index -1, arr))\n",
        "    arr[s1Index][s2Index] = result\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5urtPWMEheZ"
      },
      "source": [
        "for number in range(1,1) : \n",
        "    print(\"s1 = train_f\"+str(number)+\"['INST_.1'].astype(str)\",\"\\n\"+\n",
        "          \"s2= test_hsc\"+str(number)+\"['INST_.1'].astype(str)\",\"\\n\"+\n",
        "\"a = [[None for i in range(len(s2))] for j in range(len(s1))]\",\"\\n\"+\n",
        "\"print('Category:',\"+str(number)+\")\",\"\\n\"+\n",
        "\n",
        "\"print('Length of LCS is :',lcs(s1, s2, len(s1)-1, len(s2)-1, a))\",\"\\n\"+\n",
        "\"print('Number of colleges common in both strings :',len(f_df\"+str(number)+\"))\",\"\\n\"+                     \n",
        "\"print('Length of string 1 :',len(train_f\"+str(number)+\"))\",\"\\n\"+\n",
        "\"print('Length of string 2 :',len(test_hsc\"+str(number)+\"))\",\"\\n\"+         \n",
        " \"print('\\\\n')\",\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwRqJkqlZCk9"
      },
      "source": [
        "for number in range(1,1) : \n",
        "    print(\"s1 = train_f\"+str(number)+\"['INST_.1'].astype(str)\",\"\\n\"+\n",
        "          \"s2= test_hsc\"+str(number)+\"['INST_.1'].astype(str)\",\"\\n\"+\n",
        "\"a = [[None for i in range(len(s2))] for j in range(len(s1))]\",\"\\n\"+\n",
        "\"print('Category:',\"+str(number)+\")\",\"\\n\"+\n",
        "\"accuracy\"+str(number)+\"= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df\"+str(number)+\")\",\"\\n\"+\n",
        "\"print('Length of LCS is :',lcs(s1, s2, len(s1)-1, len(s2)-1, a))\",\"\\n\"+\n",
        "\"print('Number of colleges common in both strings :',len(f_df\"+str(number)+\"))\",\"\\n\"+ \n",
        "\"print('accuracy\"+str(number)+\":',accuracy\"+str(number)+\")\",\"\\n\"+                        \n",
        "\"print('\\\\n')\",\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a_EfRTSe4it"
      },
      "source": [
        "for number in range(1,1):\n",
        "        print(\"s1 = train_f\"+str(number)+\"['INST_.1'].astype(str)\",\"\\n\"+\n",
        "          \"s2= test_hsc\"+str(number)+\"['INST_.1'].astype(str)\",\"\\n\"+\n",
        "\"a = [[None for i in range(len(s2))] for j in range(len(s1))]\",\"\\n\"+   \n",
        "\"print(\"+str(number)+\" ,',',len(f_df\"+str(number)+\"),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',accuracy\"+str(number)+\")\",\"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-DraRcjN1xS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea3e021f-fb10-48da-85b0-6826e10f5cf7"
      },
      "source": [
        "test_matrix.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['INST_.1',         1,         2,         3,         4,        11,\n",
              "              12,        13,        14,        15,        16,        19,\n",
              "              20,        21,        22,        23,        24,        28,\n",
              "              29,        30,        31,        32,        37,        38,\n",
              "              39,        40,        41,        42,        43,        47,\n",
              "              48,        49,        50],\n",
              "      dtype='object', name='CATEGORY')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 432
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Imig_HCGOW9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ba8b718-831c-4194-f04d-6c19f0870599"
      },
      "source": [
        "train_matrix.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['INST_.1',         1,         2,         3,         4,         5,\n",
              "              11,        12,        13,        14,        15,        16,\n",
              "              19,        20,        21,        22,        23,        28,\n",
              "              29,        30,        31,        32,        38,        39,\n",
              "              40,        41,        42,        43,        47,        48,\n",
              "              49,        50],\n",
              "      dtype='object', name='CATEGORY')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 433
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uj-_9GxA8If4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4whVJgSFiYl1"
      },
      "source": [
        "**Start**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5wmrdfYztLK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hL3WtW3Rw23o"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import linear_model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsF4wXTM78bO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PLH7AB179Nn"
      },
      "source": [
        "**KNN model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "CqaSgQReuPQr",
        "outputId": "e0691ae9-6819-41cc-9f50-d309e1f9b361"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import linear_model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "train_n= train_n.round({\"Deviation of training year\":3}) \n",
        "known_train =train_n.loc[(train_n['Deviation of training year']!=0)]\n",
        "\n",
        "ytn = known_train[\"Deviation of training year\"]\n",
        "Xtn = known_train.drop(columns=[\"Deviation of training year\"])\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xtn,ytn,test_size=0.2,random_state= 0)\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(Xtn,ytn,test_size=0.2,random_state= 39)\n",
        "#model=  LinearRegression()\n",
        "#model = DecisionTreeRegressor(max_depth=2)\n",
        "#model =RandomForestRegressor(n_estimators= 100,random_state= 41)\n",
        "model = KNeighborsRegressor(n_neighbors= 2)\n",
        "model.fit(X_train,y_train)\n",
        "model.score(X_test,y_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test,model.predict(X_test)))\n",
        "print(model.score(X_test,y_test))\n",
        "print(rmse)\n",
        "\n",
        "\n",
        "unknown_df = unknown_train.drop(columns=[\"Deviation of training year\"])\n",
        "y_pred = model.predict(unknown_df) \n",
        "y_pred  = pd.DataFrame(y_pred)\n",
        "y_pred = y_pred.rename({0: 'Deviation of training year'}, axis=1)\n",
        "y_pred\n",
        "unknown_df=unknown_df.reset_index()\n",
        "unknown_df=unknown_df.drop('index',axis=1)\n",
        "unknown_df\n",
        "df_out = pd.merge(unknown_df, y_pred, how = 'left', left_index = True, right_index = True)\n",
        "df_out\n",
        "known_train =known_train.reset_index()\n",
        "known_train=known_train.drop('index',axis=1)\n",
        "known_train\n",
        "train_frame =[known_train,df_out]\n",
        "reco_train =pd.concat(train_frame)\n",
        "original_train = reco_train.pivot(columns='CATEGORY',index='INST_.1',values='Deviation of training year')\n",
        "original_train\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.37575091188585685\n",
            "0.2921579877788879\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>CATEGORY</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>INST_.1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1000</th>\n",
              "      <td>-0.7060</td>\n",
              "      <td>-0.9930</td>\n",
              "      <td>-1.0700</td>\n",
              "      <td>-0.8880</td>\n",
              "      <td>-0.8880</td>\n",
              "      <td>-0.4530</td>\n",
              "      <td>-0.4550</td>\n",
              "      <td>-0.7030</td>\n",
              "      <td>-0.7400</td>\n",
              "      <td>-0.8305</td>\n",
              "      <td>-0.8305</td>\n",
              "      <td>-0.8005</td>\n",
              "      <td>-0.9040</td>\n",
              "      <td>-0.6970</td>\n",
              "      <td>-0.8005</td>\n",
              "      <td>-0.8005</td>\n",
              "      <td>-0.8605</td>\n",
              "      <td>-1.0240</td>\n",
              "      <td>-0.8610</td>\n",
              "      <td>-0.7985</td>\n",
              "      <td>-0.7985</td>\n",
              "      <td>-0.8560</td>\n",
              "      <td>-0.5730</td>\n",
              "      <td>-0.5240</td>\n",
              "      <td>-0.8925</td>\n",
              "      <td>-0.521</td>\n",
              "      <td>-0.5210</td>\n",
              "      <td>-0.5210</td>\n",
              "      <td>-0.5210</td>\n",
              "      <td>-0.5210</td>\n",
              "      <td>-0.5210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1001</th>\n",
              "      <td>-0.8880</td>\n",
              "      <td>-0.8880</td>\n",
              "      <td>-0.8880</td>\n",
              "      <td>-0.8880</td>\n",
              "      <td>-0.8880</td>\n",
              "      <td>-0.4540</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-1.2760</td>\n",
              "      <td>-0.9210</td>\n",
              "      <td>-0.7510</td>\n",
              "      <td>-0.8305</td>\n",
              "      <td>-0.8005</td>\n",
              "      <td>-0.8005</td>\n",
              "      <td>-0.8005</td>\n",
              "      <td>-0.8005</td>\n",
              "      <td>-0.8005</td>\n",
              "      <td>-0.8605</td>\n",
              "      <td>-0.8605</td>\n",
              "      <td>-0.8605</td>\n",
              "      <td>-0.7985</td>\n",
              "      <td>-0.7985</td>\n",
              "      <td>-0.8560</td>\n",
              "      <td>-0.8560</td>\n",
              "      <td>-1.1390</td>\n",
              "      <td>-0.9470</td>\n",
              "      <td>-0.646</td>\n",
              "      <td>-0.5210</td>\n",
              "      <td>-0.5210</td>\n",
              "      <td>-0.5210</td>\n",
              "      <td>-0.5210</td>\n",
              "      <td>-0.5210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1002</th>\n",
              "      <td>-0.5110</td>\n",
              "      <td>-0.3170</td>\n",
              "      <td>-0.6940</td>\n",
              "      <td>-0.6940</td>\n",
              "      <td>-0.6940</td>\n",
              "      <td>-0.4540</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-1.0985</td>\n",
              "      <td>-1.0985</td>\n",
              "      <td>-0.8305</td>\n",
              "      <td>-0.8305</td>\n",
              "      <td>-0.8005</td>\n",
              "      <td>-0.8005</td>\n",
              "      <td>-0.8005</td>\n",
              "      <td>-0.8005</td>\n",
              "      <td>-0.8005</td>\n",
              "      <td>-0.8605</td>\n",
              "      <td>-0.8605</td>\n",
              "      <td>-0.8605</td>\n",
              "      <td>-0.7985</td>\n",
              "      <td>-0.7985</td>\n",
              "      <td>-0.8505</td>\n",
              "      <td>-0.8505</td>\n",
              "      <td>-0.5620</td>\n",
              "      <td>-0.3960</td>\n",
              "      <td>-0.235</td>\n",
              "      <td>-0.5210</td>\n",
              "      <td>-0.5210</td>\n",
              "      <td>-0.5210</td>\n",
              "      <td>-0.5210</td>\n",
              "      <td>-0.5210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1004</th>\n",
              "      <td>-0.3160</td>\n",
              "      <td>-0.3180</td>\n",
              "      <td>-0.3170</td>\n",
              "      <td>-0.3170</td>\n",
              "      <td>-0.3170</td>\n",
              "      <td>-0.8645</td>\n",
              "      <td>-1.0985</td>\n",
              "      <td>-1.0985</td>\n",
              "      <td>-1.0985</td>\n",
              "      <td>-1.0985</td>\n",
              "      <td>-1.0985</td>\n",
              "      <td>-0.8005</td>\n",
              "      <td>-0.8005</td>\n",
              "      <td>-0.8005</td>\n",
              "      <td>-0.8005</td>\n",
              "      <td>-0.8005</td>\n",
              "      <td>-0.8605</td>\n",
              "      <td>-0.8605</td>\n",
              "      <td>-0.8605</td>\n",
              "      <td>-0.7985</td>\n",
              "      <td>-0.7985</td>\n",
              "      <td>-0.4790</td>\n",
              "      <td>-0.4790</td>\n",
              "      <td>-0.4790</td>\n",
              "      <td>-0.4790</td>\n",
              "      <td>-0.479</td>\n",
              "      <td>-0.5210</td>\n",
              "      <td>-0.5210</td>\n",
              "      <td>-0.5210</td>\n",
              "      <td>-0.5210</td>\n",
              "      <td>-0.5210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1025</th>\n",
              "      <td>-0.2200</td>\n",
              "      <td>-0.5280</td>\n",
              "      <td>-0.7395</td>\n",
              "      <td>-0.7395</td>\n",
              "      <td>-0.7395</td>\n",
              "      <td>-0.1650</td>\n",
              "      <td>-0.1650</td>\n",
              "      <td>-0.1650</td>\n",
              "      <td>-0.1650</td>\n",
              "      <td>-0.1650</td>\n",
              "      <td>-0.1650</td>\n",
              "      <td>-0.1650</td>\n",
              "      <td>-0.1650</td>\n",
              "      <td>-0.1205</td>\n",
              "      <td>-0.3725</td>\n",
              "      <td>-0.3725</td>\n",
              "      <td>-0.0930</td>\n",
              "      <td>-0.3725</td>\n",
              "      <td>-0.3725</td>\n",
              "      <td>-0.3725</td>\n",
              "      <td>-0.3725</td>\n",
              "      <td>-0.5340</td>\n",
              "      <td>-0.5340</td>\n",
              "      <td>-0.5340</td>\n",
              "      <td>-0.5340</td>\n",
              "      <td>-0.534</td>\n",
              "      <td>-0.5340</td>\n",
              "      <td>-0.5340</td>\n",
              "      <td>-0.5340</td>\n",
              "      <td>-0.5340</td>\n",
              "      <td>-0.5340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2625</th>\n",
              "      <td>0.0235</td>\n",
              "      <td>0.0235</td>\n",
              "      <td>0.0235</td>\n",
              "      <td>0.0235</td>\n",
              "      <td>0.0235</td>\n",
              "      <td>0.0235</td>\n",
              "      <td>0.0235</td>\n",
              "      <td>0.0235</td>\n",
              "      <td>0.0880</td>\n",
              "      <td>0.7900</td>\n",
              "      <td>0.5460</td>\n",
              "      <td>0.5460</td>\n",
              "      <td>0.5460</td>\n",
              "      <td>0.5460</td>\n",
              "      <td>0.5460</td>\n",
              "      <td>0.5460</td>\n",
              "      <td>0.5460</td>\n",
              "      <td>0.3435</td>\n",
              "      <td>0.3435</td>\n",
              "      <td>0.3435</td>\n",
              "      <td>0.3435</td>\n",
              "      <td>0.3435</td>\n",
              "      <td>0.3435</td>\n",
              "      <td>0.3435</td>\n",
              "      <td>0.3020</td>\n",
              "      <td>0.385</td>\n",
              "      <td>0.3435</td>\n",
              "      <td>0.3435</td>\n",
              "      <td>0.3435</td>\n",
              "      <td>0.3435</td>\n",
              "      <td>0.3435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2650</th>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.7430</td>\n",
              "      <td>-0.9090</td>\n",
              "      <td>-0.8220</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>-0.6835</td>\n",
              "      <td>-0.9120</td>\n",
              "      <td>-0.9470</td>\n",
              "      <td>-0.606</td>\n",
              "      <td>-0.7765</td>\n",
              "      <td>0.0350</td>\n",
              "      <td>0.0350</td>\n",
              "      <td>0.0350</td>\n",
              "      <td>0.0350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2651</th>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>-0.4200</td>\n",
              "      <td>-0.6835</td>\n",
              "      <td>0.035</td>\n",
              "      <td>0.0350</td>\n",
              "      <td>0.0350</td>\n",
              "      <td>0.0350</td>\n",
              "      <td>0.0350</td>\n",
              "      <td>0.0350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2652</th>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8260</td>\n",
              "      <td>0.3140</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.4370</td>\n",
              "      <td>0.4460</td>\n",
              "      <td>0.676</td>\n",
              "      <td>0.5610</td>\n",
              "      <td>0.0350</td>\n",
              "      <td>0.0350</td>\n",
              "      <td>0.0350</td>\n",
              "      <td>0.0350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2675</th>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8260</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>-0.8655</td>\n",
              "      <td>0.4415</td>\n",
              "      <td>0.4415</td>\n",
              "      <td>0.4415</td>\n",
              "      <td>0.4415</td>\n",
              "      <td>0.4415</td>\n",
              "      <td>0.4415</td>\n",
              "      <td>0.4415</td>\n",
              "      <td>0.4415</td>\n",
              "      <td>-0.2030</td>\n",
              "      <td>0.561</td>\n",
              "      <td>0.5610</td>\n",
              "      <td>0.5610</td>\n",
              "      <td>0.5610</td>\n",
              "      <td>0.5610</td>\n",
              "      <td>0.5610</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>116 rows  31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "CATEGORY      1       2       3       4   ...      47      48      49      50\n",
              "INST_.1                                   ...                                \n",
              "1000     -0.7060 -0.9930 -1.0700 -0.8880  ... -0.5210 -0.5210 -0.5210 -0.5210\n",
              "1001     -0.8880 -0.8880 -0.8880 -0.8880  ... -0.5210 -0.5210 -0.5210 -0.5210\n",
              "1002     -0.5110 -0.3170 -0.6940 -0.6940  ... -0.5210 -0.5210 -0.5210 -0.5210\n",
              "1004     -0.3160 -0.3180 -0.3170 -0.3170  ... -0.5210 -0.5210 -0.5210 -0.5210\n",
              "1025     -0.2200 -0.5280 -0.7395 -0.7395  ... -0.5340 -0.5340 -0.5340 -0.5340\n",
              "...          ...     ...     ...     ...  ...     ...     ...     ...     ...\n",
              "2625      0.0235  0.0235  0.0235  0.0235  ...  0.3435  0.3435  0.3435  0.3435\n",
              "2650     -0.8260 -0.8260 -0.8260 -0.8260  ...  0.0350  0.0350  0.0350  0.0350\n",
              "2651     -0.8260 -0.8260 -0.8260 -0.8260  ...  0.0350  0.0350  0.0350  0.0350\n",
              "2652     -0.8260 -0.8260 -0.8260 -0.8260  ...  0.0350  0.0350  0.0350  0.0350\n",
              "2675     -0.8260 -0.8260 -0.8260 -0.8260  ...  0.5610  0.5610  0.5610  0.5610\n",
              "\n",
              "[116 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 464
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JUEFKgzi4k4",
        "outputId": "8430aaa5-8ed7-4e98-a3cc-097e512bd171"
      },
      "source": [
        "a= (train_matrix.columns)&(test_matrix.columns)\n",
        "print(a)\n",
        "print(len(a))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['INST_.1',         1,         2,         3,         4,        11,\n",
            "              12,        13,        14,        15,        16,        19,\n",
            "              20,        21,        22,        23,        28,        29,\n",
            "              30,        31,        32,        38,        39,        40,\n",
            "              41,        42,        43,        47,        48,        49,\n",
            "              50],\n",
            "      dtype='object', name='CATEGORY')\n",
            "31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9wjahZzrVw9"
      },
      "source": [
        "for i in range(1,1):\n",
        "  print(\"train_f\"+str(i)+\" = original_train[\"+str(i)+\"]\",\"\\n\"\n",
        "\"train_f\"+str(i)+\"= train_f\"+str(i)+\".reset_index()\",\"\\n\"\n",
        "\"train_f\"+str(i)+\" =train_f\"+str(i)+\".sort_values(by=\"+str(i)+\", ascending= False)\",\"\\n\"\n",
        "\"train_f\"+str(i)+\" =train_f\"+str(i)+\".reset_index()\",\"\\n\"\n",
        "\"train_f\"+str(i)+\" =train_f\"+str(i)+\".drop('index',axis=1)\",\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqy97hBgrV6T"
      },
      "source": [
        "for i in range(1,1):\n",
        "  print(\"f_df\"+str(i)+\" = pd.merge(train_f\"+str(i)+\",test_hsc\"+str(i)+\",how='inner',on='INST_.1')\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmVyqiL2iW4C",
        "outputId": "bdb89b02-1754-4aa6-bd13-c05168f6399d"
      },
      "source": [
        "for number in range(34,35):\n",
        "        print(\"s1 = train_f\"+str(number)+\"['INST_.1'].astype(str)\",\"\\n\"+\n",
        "          \"s2= test_hsc\"+str(number)+\"['INST_.1'].astype(str)\",\"\\n\"+\n",
        "\"a = [[None for i in range(len(s2))] for j in range(len(s1))]\",\"\\n\"+\n",
        "\"accuracy\"+str(number)+\"= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df\"+str(number)+\")\",\"\\n\"+   \n",
        "\"print(\"+str(number)+\" ,',',len(f_df\"+str(number)+\"),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy\"+str(number)+\",2))\",\"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "s1 = train_f34['INST_.1'].astype(str) \n",
            "s2= test_hsc34['INST_.1'].astype(str) \n",
            "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
            "accuracy34= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df34) \n",
            "print(34 ,',',len(f_df34),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy34,2)) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLNhd0ZAjTe0",
        "outputId": "a6120ce1-6b81-4279-bdb9-9fd4dab2e6be"
      },
      "source": [
        "train_f1 = original_train[1] \n",
        "train_f1= train_f1.reset_index() \n",
        "train_f1 =train_f1.sort_values(by=1, ascending= False) \n",
        "train_f1 =train_f1.reset_index() \n",
        "train_f1 =train_f1.drop('index',axis=1) \n",
        "\n",
        "train_f2 = original_train[2] \n",
        "train_f2= train_f2.reset_index() \n",
        "train_f2 =train_f2.sort_values(by=2, ascending= False) \n",
        "train_f2 =train_f2.reset_index() \n",
        "train_f2 =train_f2.drop('index',axis=1) \n",
        "\n",
        "train_f3 = original_train[3] \n",
        "train_f3= train_f3.reset_index() \n",
        "train_f3 =train_f3.sort_values(by=3, ascending= False) \n",
        "train_f3 =train_f3.reset_index() \n",
        "train_f3 =train_f3.drop('index',axis=1) \n",
        "\n",
        "train_f4 = original_train[4] \n",
        "train_f4= train_f4.reset_index() \n",
        "train_f4 =train_f4.sort_values(by=4, ascending= False) \n",
        "train_f4 =train_f4.reset_index() \n",
        "train_f4 =train_f4.drop('index',axis=1) \n",
        "\n",
        "train_f11 = original_train[11] \n",
        "train_f11= train_f11.reset_index() \n",
        "train_f11 =train_f11.sort_values(by=11, ascending= False) \n",
        "train_f11 =train_f11.reset_index() \n",
        "train_f11 =train_f11.drop('index',axis=1) \n",
        "\n",
        "train_f12 = original_train[12] \n",
        "train_f12= train_f12.reset_index() \n",
        "train_f12 =train_f12.sort_values(by=12, ascending= False) \n",
        "train_f12 =train_f12.reset_index() \n",
        "train_f12 =train_f12.drop('index',axis=1) \n",
        "\n",
        "train_f13 = original_train[13] \n",
        "train_f13= train_f13.reset_index() \n",
        "train_f13 =train_f13.sort_values(by=13, ascending= False) \n",
        "train_f13 =train_f13.reset_index() \n",
        "train_f13 =train_f13.drop('index',axis=1) \n",
        "\n",
        "train_f14 = original_train[14] \n",
        "train_f14= train_f14.reset_index() \n",
        "train_f14 =train_f14.sort_values(by=14, ascending= False) \n",
        "train_f14 =train_f14.reset_index() \n",
        "train_f14 =train_f14.drop('index',axis=1) \n",
        "\n",
        "train_f15 = original_train[15] \n",
        "train_f15= train_f15.reset_index() \n",
        "train_f15 =train_f15.sort_values(by=15, ascending= False) \n",
        "train_f15 =train_f15.reset_index() \n",
        "train_f15 =train_f15.drop('index',axis=1) \n",
        "\n",
        "train_f16 = original_train[16] \n",
        "train_f16= train_f16.reset_index() \n",
        "train_f16 =train_f16.sort_values(by=16, ascending= False) \n",
        "train_f16 =train_f16.reset_index() \n",
        "train_f16 =train_f16.drop('index',axis=1) \n",
        "\n",
        "\n",
        "train_f19 = original_train[19] \n",
        "train_f19= train_f19.reset_index() \n",
        "train_f19 =train_f19.sort_values(by=19, ascending= False) \n",
        "train_f19 =train_f19.reset_index() \n",
        "train_f19 =train_f19.drop('index',axis=1) \n",
        "\n",
        "train_f20 = original_train[20] \n",
        "train_f20= train_f20.reset_index() \n",
        "train_f20 =train_f20.sort_values(by=20, ascending= False) \n",
        "train_f20 =train_f20.reset_index() \n",
        "train_f20 =train_f20.drop('index',axis=1) \n",
        "\n",
        "train_f21 = original_train[21] \n",
        "train_f21= train_f21.reset_index() \n",
        "train_f21 =train_f21.sort_values(by=21, ascending= False) \n",
        "train_f21 =train_f21.reset_index() \n",
        "train_f21 =train_f21.drop('index',axis=1) \n",
        "\n",
        "train_f22 = original_train[22] \n",
        "train_f22= train_f22.reset_index() \n",
        "train_f22 =train_f22.sort_values(by=22, ascending= False) \n",
        "train_f22 =train_f22.reset_index() \n",
        "train_f22 =train_f22.drop('index',axis=1) \n",
        "\n",
        "train_f23 = original_train[23] \n",
        "train_f23= train_f23.reset_index() \n",
        "train_f23 =train_f23.sort_values(by=23, ascending= False) \n",
        "train_f23 =train_f23.reset_index() \n",
        "train_f23 =train_f23.drop('index',axis=1) \n",
        "\n",
        "\n",
        "train_f28 = original_train[28] \n",
        "train_f28= train_f28.reset_index() \n",
        "train_f28 =train_f28.sort_values(by=28, ascending= False) \n",
        "train_f28 =train_f28.reset_index() \n",
        "train_f28 =train_f28.drop('index',axis=1) \n",
        "\n",
        "train_f29 = original_train[29] \n",
        "train_f29= train_f29.reset_index() \n",
        "train_f29 =train_f29.sort_values(by=29, ascending= False) \n",
        "train_f29 =train_f29.reset_index() \n",
        "train_f29 =train_f29.drop('index',axis=1) \n",
        "\n",
        "train_f30 = original_train[30] \n",
        "train_f30= train_f30.reset_index() \n",
        "train_f30 =train_f30.sort_values(by=30, ascending= False) \n",
        "train_f30 =train_f30.reset_index() \n",
        "train_f30 =train_f30.drop('index',axis=1) \n",
        "\n",
        "train_f31 = original_train[31] \n",
        "train_f31= train_f31.reset_index() \n",
        "train_f31 =train_f31.sort_values(by=31, ascending= False) \n",
        "train_f31 =train_f31.reset_index() \n",
        "train_f31 =train_f31.drop('index',axis=1) \n",
        "\n",
        "train_f32 = original_train[32] \n",
        "train_f32= train_f32.reset_index() \n",
        "train_f32 =train_f32.sort_values(by=32, ascending= False) \n",
        "train_f32 =train_f32.reset_index() \n",
        "train_f32 =train_f32.drop('index',axis=1) \n",
        "\n",
        "\n",
        "train_f38 = original_train[38] \n",
        "train_f38= train_f38.reset_index() \n",
        "train_f38 =train_f38.sort_values(by=38, ascending= False) \n",
        "train_f38 =train_f38.reset_index() \n",
        "train_f38 =train_f38.drop('index',axis=1) \n",
        "\n",
        "train_f39 = original_train[39] \n",
        "train_f39= train_f39.reset_index() \n",
        "train_f39 =train_f39.sort_values(by=39, ascending= False) \n",
        "train_f39 =train_f39.reset_index() \n",
        "train_f39 =train_f39.drop('index',axis=1) \n",
        "\n",
        "train_f40 = original_train[40] \n",
        "train_f40= train_f40.reset_index() \n",
        "train_f40 =train_f40.sort_values(by=40, ascending= False) \n",
        "train_f40 =train_f40.reset_index() \n",
        "train_f40 =train_f40.drop('index',axis=1) \n",
        "\n",
        "train_f41 = original_train[41] \n",
        "train_f41= train_f41.reset_index() \n",
        "train_f41 =train_f41.sort_values(by=41, ascending= False) \n",
        "train_f41 =train_f41.reset_index() \n",
        "train_f41 =train_f41.drop('index',axis=1) \n",
        "\n",
        "train_f42 = original_train[42] \n",
        "train_f42= train_f42.reset_index() \n",
        "train_f42 =train_f42.sort_values(by=42, ascending= False) \n",
        "train_f42 =train_f42.reset_index() \n",
        "train_f42 =train_f42.drop('index',axis=1) \n",
        "\n",
        "train_f43 = original_train[43] \n",
        "train_f43= train_f43.reset_index() \n",
        "train_f43 =train_f43.sort_values(by=43, ascending= False) \n",
        "train_f43 =train_f43.reset_index() \n",
        "train_f43 =train_f43.drop('index',axis=1) \n",
        "\n",
        "\n",
        "train_f47 = original_train[47] \n",
        "train_f47= train_f47.reset_index() \n",
        "train_f47 =train_f47.sort_values(by=47, ascending= False) \n",
        "train_f47 =train_f47.reset_index() \n",
        "train_f47 =train_f47.drop('index',axis=1) \n",
        "\n",
        "train_f48 = original_train[48] \n",
        "train_f48= train_f48.reset_index() \n",
        "train_f48 =train_f48.sort_values(by=48, ascending= False) \n",
        "train_f48 =train_f48.reset_index() \n",
        "train_f48 =train_f48.drop('index',axis=1) \n",
        "\n",
        "train_f49 = original_train[49] \n",
        "train_f49= train_f49.reset_index() \n",
        "train_f49 =train_f49.sort_values(by=49, ascending= False) \n",
        "train_f49 =train_f49.reset_index() \n",
        "train_f49 =train_f49.drop('index',axis=1) \n",
        "\n",
        "train_f50 = original_train[50] \n",
        "train_f50= train_f50.reset_index() \n",
        "train_f50 =train_f50.sort_values(by=50, ascending= False) \n",
        "train_f50 =train_f50.reset_index() \n",
        "train_f50 =train_f50.drop('index',axis=1) \n",
        "train_f50.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(116, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 487
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dDRCM_7jWQV",
        "outputId": "92d92b7a-c104-4d97-f0ff-2ea5fdbebb03"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['INST_.1',         1,         2,         3,         4,        11,\n",
              "              12,        13,        14,        15,        16,        19,\n",
              "              20,        21,        22,        23,        28,        29,\n",
              "              30,        31,        32,        38,        39,        40,\n",
              "              41,        42,        43,        47,        48,        49,\n",
              "              50],\n",
              "      dtype='object', name='CATEGORY')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 470
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb7fKfF1kXCe",
        "outputId": "6292f22b-6890-4ce2-eb6f-6f6b8617f65a"
      },
      "source": [
        "f_df1 = pd.merge(train_f1,test_hsc1,how='inner',on='INST_.1')\n",
        "f_df2 = pd.merge(train_f2,test_hsc2,how='inner',on='INST_.1')\n",
        "f_df3 = pd.merge(train_f3,test_hsc3,how='inner',on='INST_.1')\n",
        "f_df4 = pd.merge(train_f4,test_hsc4,how='inner',on='INST_.1')\n",
        "\n",
        "f_df11 = pd.merge(train_f11,test_hsc11,how='inner',on='INST_.1')\n",
        "f_df12 = pd.merge(train_f12,test_hsc12,how='inner',on='INST_.1')\n",
        "f_df13 = pd.merge(train_f13,test_hsc13,how='inner',on='INST_.1')\n",
        "f_df14 = pd.merge(train_f14,test_hsc14,how='inner',on='INST_.1')\n",
        "f_df15 = pd.merge(train_f15,test_hsc15,how='inner',on='INST_.1')\n",
        "f_df16 = pd.merge(train_f16,test_hsc16,how='inner',on='INST_.1')\n",
        "\n",
        "f_df19 = pd.merge(train_f19,test_hsc19,how='inner',on='INST_.1')\n",
        "f_df20 = pd.merge(train_f20,test_hsc20,how='inner',on='INST_.1')\n",
        "f_df21 = pd.merge(train_f21,test_hsc21,how='inner',on='INST_.1')\n",
        "f_df22 = pd.merge(train_f22,test_hsc22,how='inner',on='INST_.1')\n",
        "f_df23 = pd.merge(train_f23,test_hsc23,how='inner',on='INST_.1')\n",
        "\n",
        "f_df28 = pd.merge(train_f28,test_hsc28,how='inner',on='INST_.1')\n",
        "f_df29 = pd.merge(train_f29,test_hsc29,how='inner',on='INST_.1')\n",
        "f_df30 = pd.merge(train_f30,test_hsc30,how='inner',on='INST_.1')\n",
        "f_df31 = pd.merge(train_f31,test_hsc31,how='inner',on='INST_.1')\n",
        "f_df32 = pd.merge(train_f32,test_hsc32,how='inner',on='INST_.1')\n",
        "\n",
        "f_df38 = pd.merge(train_f38,test_hsc38,how='inner',on='INST_.1')\n",
        "f_df39 = pd.merge(train_f39,test_hsc39,how='inner',on='INST_.1')\n",
        "f_df40 = pd.merge(train_f40,test_hsc40,how='inner',on='INST_.1')\n",
        "f_df41 = pd.merge(train_f41,test_hsc41,how='inner',on='INST_.1')\n",
        "f_df42 = pd.merge(train_f42,test_hsc42,how='inner',on='INST_.1')\n",
        "f_df43 = pd.merge(train_f43,test_hsc43,how='inner',on='INST_.1')\n",
        "\n",
        "f_df47 = pd.merge(train_f47,test_hsc47,how='inner',on='INST_.1')\n",
        "f_df48 = pd.merge(train_f48,test_hsc48,how='inner',on='INST_.1')\n",
        "f_df49 = pd.merge(train_f49,test_hsc49,how='inner',on='INST_.1')\n",
        "f_df50 = pd.merge(train_f50,test_hsc50,how='inner',on='INST_.1')\n",
        "f_df50.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 488
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "9xf6teN3t1Mi",
        "outputId": "be1afcb1-6a3a-423b-dc9a-3aab5b79d014"
      },
      "source": [
        "train_f1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>INST_.1</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2625</td>\n",
              "      <td>0.0235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1078</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1079</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1102</td>\n",
              "      <td>-0.0360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1101</td>\n",
              "      <td>-0.1785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>1028</td>\n",
              "      <td>-1.0340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>2527</td>\n",
              "      <td>-1.0500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>2528</td>\n",
              "      <td>-1.0500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>2526</td>\n",
              "      <td>-1.0500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>2525</td>\n",
              "      <td>-1.0500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>116 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     INST_.1       1\n",
              "0       2625  0.0235\n",
              "1       1078  0.0000\n",
              "2       1079  0.0000\n",
              "3       1102 -0.0360\n",
              "4       1101 -0.1785\n",
              "..       ...     ...\n",
              "111     1028 -1.0340\n",
              "112     2527 -1.0500\n",
              "113     2528 -1.0500\n",
              "114     2526 -1.0500\n",
              "115     2525 -1.0500\n",
              "\n",
              "[116 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 489
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "gzIKHCfQrkfM",
        "outputId": "27f6a79b-5fb1-40d2-ebb7-8ac4ff3d5af6"
      },
      "source": [
        "f_df1 = pd.merge(train_f3,test_hsc3,on='INST_.1')\n",
        "f_df1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>INST_.1</th>\n",
              "      <th>3</th>\n",
              "      <th>STUD_GROUP</th>\n",
              "      <th>SEX</th>\n",
              "      <th>CATEGORY</th>\n",
              "      <th>Deviation of testing year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1079</td>\n",
              "      <td>0.3070</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.083333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1300</td>\n",
              "      <td>-0.4830</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.636667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1031</td>\n",
              "      <td>-0.5910</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.667576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2325</td>\n",
              "      <td>-0.5990</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.594848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1801</td>\n",
              "      <td>-0.5990</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.378788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1026</td>\n",
              "      <td>-0.6430</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.871250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1076</td>\n",
              "      <td>-0.7385</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.031600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1325</td>\n",
              "      <td>-0.7700</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.695333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1125</td>\n",
              "      <td>-1.0035</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.569167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2500</td>\n",
              "      <td>-1.0070</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.469800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2250</td>\n",
              "      <td>-1.0150</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.842464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1000</td>\n",
              "      <td>-1.0700</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.866000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1075</td>\n",
              "      <td>-1.1700</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>-1.170842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1750</td>\n",
              "      <td>-1.2050</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.608571</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    INST_.1       3  STUD_GROUP  SEX  CATEGORY  Deviation of testing year\n",
              "0      1079  0.3070           0    0         3                   0.083333\n",
              "1      1300 -0.4830           0    0         3                  -0.636667\n",
              "2      1031 -0.5910           0    0         3                  -0.667576\n",
              "3      2325 -0.5990           0    0         3                  -0.594848\n",
              "4      1801 -0.5990           0    0         3                  -0.378788\n",
              "5      1026 -0.6430           0    0         3                  -0.871250\n",
              "6      1076 -0.7385           0    0         3                  -0.031600\n",
              "7      1325 -0.7700           0    0         3                  -0.695333\n",
              "8      1125 -1.0035           0    0         3                  -0.569167\n",
              "9      2500 -1.0070           0    0         3                  -0.469800\n",
              "10     2250 -1.0150           0    0         3                  -0.842464\n",
              "11     1000 -1.0700           0    0         3                  -0.866000\n",
              "12     1075 -1.1700           0    0         3                  -1.170842\n",
              "13     1750 -1.2050           0    0         3                  -0.608571"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 495
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3tVIrfqubdW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "a7ffdd21-12c1-4c2a-a69d-2654d7dbf5d8"
      },
      "source": [
        "train_f4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>INST_.1</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2625</td>\n",
              "      <td>0.0235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1079</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1078</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1101</td>\n",
              "      <td>-0.1785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1100</td>\n",
              "      <td>-0.1785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>1754</td>\n",
              "      <td>-1.1500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>1753</td>\n",
              "      <td>-1.1500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>1752</td>\n",
              "      <td>-1.1500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>1751</td>\n",
              "      <td>-1.1500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>1750</td>\n",
              "      <td>-1.1500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>116 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     INST_.1       4\n",
              "0       2625  0.0235\n",
              "1       1079  0.0000\n",
              "2       1078  0.0000\n",
              "3       1101 -0.1785\n",
              "4       1100 -0.1785\n",
              "..       ...     ...\n",
              "111     1754 -1.1500\n",
              "112     1753 -1.1500\n",
              "113     1752 -1.1500\n",
              "114     1751 -1.1500\n",
              "115     1750 -1.1500\n",
              "\n",
              "[116 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 494
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvvzC9nxr8qO"
      },
      "source": [
        " def lcs(s1, s2, s1Index, s2Index, arr):\n",
        "    \n",
        "    if s1Index ==-1 or s2Index == -1:\n",
        "        return 0\n",
        "    if(arr[s1Index][s2Index] != None):\n",
        "        return arr[s1Index][s2Index]\n",
        "\n",
        "    if s1[s1Index] == s2 [s2Index]:\n",
        "        result = 1+ lcs(s1, s2, s1Index -1, s2Index -1, arr)\n",
        "    else:\n",
        "        result= max(lcs(s1, s2, s1Index -1, s2Index, arr), lcs(s1, s2, s1Index, s2Index -1, arr))\n",
        "    arr[s1Index][s2Index] = result\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEUdeCFT8rAY",
        "outputId": "c8f89daf-d883-43f9-e290-8d5dcb882aa4"
      },
      "source": [
        "s1 = train_f1['INST_.1'].astype(str) \n",
        "s2= test_hsc1['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy1= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df1) \n",
        "print(1 ,',',len(f_df1),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy1,2)) \n",
        "\n",
        "s1 = train_f2['INST_.1'].astype(str) \n",
        "s2= test_hsc2['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy2= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df2) \n",
        "print(2 ,',',len(f_df2),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy2,2)) \n",
        "\n",
        "s1 = train_f3['INST_.1'].astype(str) \n",
        "s2= test_hsc3['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy3= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df3) \n",
        "print(3 ,',',len(f_df3),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy3,2)) \n",
        "\n",
        "s1 = train_f4['INST_.1'].astype(str) \n",
        "s2= test_hsc4['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy4= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df4) \n",
        "print(4 ,',',len(f_df4),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy4,2)) \n",
        "\n",
        "\n",
        "s1 = train_f11['INST_.1'].astype(str) \n",
        "s2= test_hsc11['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy11= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df11) \n",
        "print(11 ,',',len(f_df11),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy11,2)) \n",
        "\n",
        "s1 = train_f12['INST_.1'].astype(str) \n",
        "s2= test_hsc12['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy12= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df12) \n",
        "print(12 ,',',len(f_df12),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy12,2)) \n",
        "\n",
        "s1 = train_f13['INST_.1'].astype(str) \n",
        "s2= test_hsc13['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy13= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df13) \n",
        "print(13 ,',',len(f_df13),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy13,2)) \n",
        "\n",
        "s1 = train_f14['INST_.1'].astype(str) \n",
        "s2= test_hsc14['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy14= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df14) \n",
        "print(14 ,',',len(f_df14),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy14,2)) \n",
        "\n",
        "s1 = train_f15['INST_.1'].astype(str) \n",
        "s2= test_hsc15['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy15= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df15) \n",
        "print(15 ,',',len(f_df15),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy15,2)) \n",
        "\n",
        "s1 = train_f16['INST_.1'].astype(str) \n",
        "s2= test_hsc16['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy16= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df16) \n",
        "print(16 ,',',len(f_df16),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy16,2)) \n",
        "\n",
        "\n",
        "s1 = train_f19['INST_.1'].astype(str) \n",
        "s2= test_hsc19['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy19= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df19) \n",
        "print(19 ,',',len(f_df19),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy19,2)) \n",
        "\n",
        "s1 = train_f20['INST_.1'].astype(str) \n",
        "s2= test_hsc20['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy20= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df20) \n",
        "print(20 ,',',len(f_df20),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy20,2)) \n",
        "\n",
        "s1 = train_f21['INST_.1'].astype(str) \n",
        "s2= test_hsc21['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy21= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df21) \n",
        "print(21 ,',',len(f_df21),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy21,2)) \n",
        "\n",
        "s1 = train_f22['INST_.1'].astype(str) \n",
        "s2= test_hsc22['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy22= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df22) \n",
        "print(22 ,',',len(f_df22),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy22,2)) \n",
        "\n",
        "s1 = train_f23['INST_.1'].astype(str) \n",
        "s2= test_hsc23['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy23= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df23) \n",
        "print(23 ,',',len(f_df23),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy23,2)) \n",
        "\n",
        "\n",
        "s1 = train_f28['INST_.1'].astype(str) \n",
        "s2= test_hsc28['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy28= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df28) \n",
        "print(28 ,',',len(f_df28),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy28,2)) \n",
        "\n",
        "s1 = train_f29['INST_.1'].astype(str) \n",
        "s2= test_hsc29['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy29= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df29) \n",
        "print(29 ,',',len(f_df29),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy29,2)) \n",
        "\n",
        "s1 = train_f30['INST_.1'].astype(str) \n",
        "s2= test_hsc30['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy30= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df30) \n",
        "print(30 ,',',len(f_df30),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy30,2)) \n",
        "\n",
        "s1 = train_f31['INST_.1'].astype(str) \n",
        "s2= test_hsc31['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy31= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df31) \n",
        "print(31 ,',',len(f_df31),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy31,2)) \n",
        "\n",
        "s1 = train_f32['INST_.1'].astype(str) \n",
        "s2= test_hsc32['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy32= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df32) \n",
        "print(32 ,',',len(f_df32),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy32,2)) \n",
        "\n",
        "\n",
        "s1 = train_f38['INST_.1'].astype(str) \n",
        "s2= test_hsc38['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy38= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df38) \n",
        "print(38 ,',',len(f_df38),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy38,2)) \n",
        "\n",
        "s1 = train_f39['INST_.1'].astype(str) \n",
        "s2= test_hsc39['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy39= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df39) \n",
        "print(39 ,',',len(f_df39),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy39,2)) \n",
        "\n",
        "s1 = train_f40['INST_.1'].astype(str) \n",
        "s2= test_hsc40['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy40= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df40) \n",
        "print(40 ,',',len(f_df40),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy40,2)) \n",
        "\n",
        "s1 = train_f41['INST_.1'].astype(str) \n",
        "s2= test_hsc41['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy41= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df41) \n",
        "print(41 ,',',len(f_df41),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy41,2)) \n",
        "\n",
        "s1 = train_f42['INST_.1'].astype(str) \n",
        "s2= test_hsc42['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy42= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df42) \n",
        "print(42 ,',',len(f_df42),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy42,2)) \n",
        "\n",
        "s1 = train_f43['INST_.1'].astype(str) \n",
        "s2= test_hsc43['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy43= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df43) \n",
        "print(43 ,',',len(f_df43),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy43,2)) \n",
        "\n",
        "\n",
        "s1 = train_f47['INST_.1'].astype(str) \n",
        "s2= test_hsc47['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy47= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df47) \n",
        "print(47 ,',',len(f_df47),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy47,2)) \n",
        "\n",
        "s1 = train_f48['INST_.1'].astype(str) \n",
        "s2= test_hsc48['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy48= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df48) \n",
        "print(48 ,',',len(f_df48),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy48,2)) \n",
        "\n",
        "s1 = train_f49['INST_.1'].astype(str) \n",
        "s2= test_hsc49['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy49= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df49) \n",
        "print(49 ,',',len(f_df49),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy49,2)) \n",
        "\n",
        "s1 = train_f50['INST_.1'].astype(str) \n",
        "s2= test_hsc50['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy50= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df50) \n",
        "print(50 ,',',len(f_df50),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy50,2)) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 , 10 , 7 , 0.7\n",
            "2 , 14 , 7 , 0.5\n",
            "3 , 14 , 7 , 0.5\n",
            "4 , 5 , 4 , 0.8\n",
            "11 , 1 , 1 , 1.0\n",
            "12 , 23 , 8 , 0.35\n",
            "13 , 53 , 13 , 0.25\n",
            "14 , 66 , 15 , 0.23\n",
            "15 , 43 , 14 , 0.33\n",
            "16 , 7 , 4 , 0.57\n",
            "19 , 1 , 1 , 1.0\n",
            "20 , 7 , 5 , 0.71\n",
            "21 , 8 , 5 , 0.62\n",
            "22 , 12 , 5 , 0.42\n",
            "23 , 7 , 2 , 0.29\n",
            "28 , 6 , 4 , 0.67\n",
            "29 , 13 , 8 , 0.62\n",
            "30 , 14 , 8 , 0.57\n",
            "31 , 6 , 3 , 0.5\n",
            "32 , 1 , 1 , 1.0\n",
            "38 , 9 , 6 , 0.67\n",
            "39 , 39 , 11 , 0.28\n",
            "40 , 71 , 18 , 0.25\n",
            "41 , 88 , 20 , 0.23\n",
            "42 , 69 , 17 , 0.25\n",
            "43 , 21 , 9 , 0.43\n",
            "47 , 2 , 2 , 1.0\n",
            "48 , 4 , 2 , 0.5\n",
            "49 , 3 , 2 , 0.67\n",
            "50 , 2 , 2 , 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCYpYns2uk8B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKQTBjBMitND",
        "outputId": "6bb1c199-2212-4b23-d5fd-9b0037e6deb8"
      },
      "source": [
        "a  = (train_matrix.columns)&(test_matrix.columns)\n",
        "print(a)\n",
        "print(len(a))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['INST_.1',         1,         2,         3,         4,        11,\n",
            "              12,        13,        14,        15,        16,        19,\n",
            "              20,        21,        22,        23,        28,        29,\n",
            "              30,        31,        32,        38,        39,        40,\n",
            "              41,        42,        43,        47,        48,        49,\n",
            "              50],\n",
            "      dtype='object', name='CATEGORY')\n",
            "31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-H4PPkGu0WI",
        "outputId": "9b3b5e58-a923-4474-d112-33f97db7765b"
      },
      "source": [
        "for i in range(1,50):\n",
        "  print(\"accuracy\"+str(i),end=\" + \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy1 + accuracy2 + accuracy3 + accuracy4 + accuracy5 + accuracy6 + accuracy7 + accuracy8 + accuracy9 + accuracy10 + accuracy11 + accuracy12 + accuracy13 + accuracy14 + accuracy15 + accuracy16 + accuracy17 + accuracy18 + accuracy19 + accuracy20 + accuracy21 + accuracy22 + accuracy23 + accuracy24 + accuracy25 + accuracy26 + accuracy27 + accuracy28 + accuracy29 + accuracy30 + accuracy31 + accuracy32 + accuracy33 + accuracy34 + accuracy35 + accuracy36 + accuracy37 + accuracy38 + accuracy39 + accuracy40 + accuracy41 + accuracy42 + accuracy43 + accuracy44 + accuracy45 + accuracy46 + accuracy47 + accuracy48 + accuracy49 + "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQKBU0h4xJw6",
        "outputId": "7955359e-5147-4ac1-e42a-2a1e90937970"
      },
      "source": [
        "accuracy_knn=(accuracy1 + accuracy2 + accuracy3 + accuracy4 + accuracy11 + accuracy12 + accuracy13 + accuracy14 + accuracy15 + accuracy16  + accuracy19 + accuracy20 + accuracy21 + accuracy22 + accuracy23 +  accuracy28 + accuracy29 + accuracy30 + accuracy31 + accuracy32  + accuracy38 + accuracy39 + accuracy40 + accuracy41 + accuracy42 + accuracy43 + +accuracy47 + accuracy48 + accuracy49  + accuracy50)/30\n",
        "score_knn= accuracy_knn*100\n",
        "score_knn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56.27888343201547"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 476
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g4udJvpB1jF"
      },
      "source": [
        "**break** **knn**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "Rgy5hsBg51mi",
        "outputId": "519bd81e-816f-441b-8dff-c6efb3eb1eee"
      },
      "source": [
        "accuracy17"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-477-05f98c0ccad6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy17\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'accuracy17' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLiROg6e52Nr"
      },
      "source": [
        "**Random Forest** **Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqQ-Bloc559I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5FBvgw456Su"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "train_n= train_n.round({\"Deviation of training year\":3}) \n",
        "known_train =train_n.loc[(train_n['Deviation of training year']!=0)]\n",
        "\n",
        "ytn = known_train[\"Deviation of training year\"]\n",
        "Xtn = known_train.drop(columns=[\"Deviation of training year\"])\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xtn,ytn,test_size=0.2,random_state= 39)\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(Xtn,ytn,test_size=0.2,random_state= 39)\n",
        "#model=  LinearRegression()\n",
        "#model = DecisionTreeRegressor(max_depth=2)\n",
        "model =RandomForestRegressor(n_estimators= 100,random_state= 41)\n",
        "#model = KNeighborsRegressor(n_neighbors= 3)\n",
        "model.fit(X_train,y_train)\n",
        "model.score(X_test,y_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test,model.predict(X_test)))\n",
        "print(model.score(X_test,y_test))\n",
        "print(rmse)\n",
        "\n",
        "\n",
        "unknown_df = unknown_train.drop(columns=[\"Deviation of training year\"])\n",
        "y_pred = model.predict(unknown_df) \n",
        "y_pred  = pd.DataFrame(y_pred)\n",
        "y_pred = y_pred.rename({0: 'Deviation of training year'}, axis=1)\n",
        "y_pred\n",
        "unknown_df=unknown_df.reset_index()\n",
        "unknown_df=unknown_df.drop('index',axis=1)\n",
        "unknown_df\n",
        "df_out = pd.merge(unknown_df, y_pred, how = 'left', left_index = True, right_index = True)\n",
        "df_out\n",
        "known_train =known_train.reset_index()\n",
        "known_train=known_train.drop('index',axis=1)\n",
        "known_train\n",
        "train_frame =[known_train,df_out]\n",
        "reco_train =pd.concat(train_frame)\n",
        "original_train = reco_train.pivot(columns='CATEGORY',index='INST_.1',values='Deviation of training year')\n",
        "original_train\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SHhfy2A56Sw"
      },
      "source": [
        "train_f1 = original_train[1] \n",
        "train_f1= train_f1.reset_index() \n",
        "train_f1 =train_f1.sort_values(by=1, ascending= False) \n",
        "train_f1 =train_f1.reset_index() \n",
        "train_f1 =train_f1.drop('index',axis=1) \n",
        "\n",
        "train_f2 = original_train[2] \n",
        "train_f2= train_f2.reset_index() \n",
        "train_f2 =train_f2.sort_values(by=2, ascending= False) \n",
        "train_f2 =train_f2.reset_index() \n",
        "train_f2 =train_f2.drop('index',axis=1) \n",
        "\n",
        "train_f3 = original_train[3] \n",
        "train_f3= train_f3.reset_index() \n",
        "train_f3 =train_f3.sort_values(by=3, ascending= False) \n",
        "train_f3 =train_f3.reset_index() \n",
        "train_f3 =train_f3.drop('index',axis=1) \n",
        "\n",
        "train_f4 = original_train[4] \n",
        "train_f4= train_f4.reset_index() \n",
        "train_f4 =train_f4.sort_values(by=4, ascending= False) \n",
        "train_f4 =train_f4.reset_index() \n",
        "train_f4 =train_f4.drop('index',axis=1) \n",
        "\n",
        "train_f11 = original_train[11] \n",
        "train_f11= train_f11.reset_index() \n",
        "train_f11 =train_f11.sort_values(by=11, ascending= False) \n",
        "train_f11 =train_f11.reset_index() \n",
        "train_f11 =train_f11.drop('index',axis=1) \n",
        "\n",
        "train_f12 = original_train[12] \n",
        "train_f12= train_f12.reset_index() \n",
        "train_f12 =train_f12.sort_values(by=12, ascending= False) \n",
        "train_f12 =train_f12.reset_index() \n",
        "train_f12 =train_f12.drop('index',axis=1) \n",
        "\n",
        "train_f13 = original_train[13] \n",
        "train_f13= train_f13.reset_index() \n",
        "train_f13 =train_f13.sort_values(by=13, ascending= False) \n",
        "train_f13 =train_f13.reset_index() \n",
        "train_f13 =train_f13.drop('index',axis=1) \n",
        "\n",
        "train_f14 = original_train[14] \n",
        "train_f14= train_f14.reset_index() \n",
        "train_f14 =train_f14.sort_values(by=14, ascending= False) \n",
        "train_f14 =train_f14.reset_index() \n",
        "train_f14 =train_f14.drop('index',axis=1) \n",
        "\n",
        "train_f15 = original_train[15] \n",
        "train_f15= train_f15.reset_index() \n",
        "train_f15 =train_f15.sort_values(by=15, ascending= False) \n",
        "train_f15 =train_f15.reset_index() \n",
        "train_f15 =train_f15.drop('index',axis=1) \n",
        "\n",
        "train_f16 = original_train[16] \n",
        "train_f16= train_f16.reset_index() \n",
        "train_f16 =train_f16.sort_values(by=16, ascending= False) \n",
        "train_f16 =train_f16.reset_index() \n",
        "train_f16 =train_f16.drop('index',axis=1) \n",
        "\n",
        "\n",
        "train_f19 = original_train[19] \n",
        "train_f19= train_f19.reset_index() \n",
        "train_f19 =train_f19.sort_values(by=19, ascending= False) \n",
        "train_f19 =train_f19.reset_index() \n",
        "train_f19 =train_f19.drop('index',axis=1) \n",
        "\n",
        "train_f20 = original_train[20] \n",
        "train_f20= train_f20.reset_index() \n",
        "train_f20 =train_f20.sort_values(by=20, ascending= False) \n",
        "train_f20 =train_f20.reset_index() \n",
        "train_f20 =train_f20.drop('index',axis=1) \n",
        "\n",
        "train_f21 = original_train[21] \n",
        "train_f21= train_f21.reset_index() \n",
        "train_f21 =train_f21.sort_values(by=21, ascending= False) \n",
        "train_f21 =train_f21.reset_index() \n",
        "train_f21 =train_f21.drop('index',axis=1) \n",
        "\n",
        "train_f22 = original_train[22] \n",
        "train_f22= train_f22.reset_index() \n",
        "train_f22 =train_f22.sort_values(by=22, ascending= False) \n",
        "train_f22 =train_f22.reset_index() \n",
        "train_f22 =train_f22.drop('index',axis=1) \n",
        "\n",
        "train_f23 = original_train[23] \n",
        "train_f23= train_f23.reset_index() \n",
        "train_f23 =train_f23.sort_values(by=23, ascending= False) \n",
        "train_f23 =train_f23.reset_index() \n",
        "train_f23 =train_f23.drop('index',axis=1) \n",
        "\n",
        "\n",
        "train_f28 = original_train[28] \n",
        "train_f28= train_f28.reset_index() \n",
        "train_f28 =train_f28.sort_values(by=28, ascending= False) \n",
        "train_f28 =train_f28.reset_index() \n",
        "train_f28 =train_f28.drop('index',axis=1) \n",
        "\n",
        "train_f29 = original_train[29] \n",
        "train_f29= train_f29.reset_index() \n",
        "train_f29 =train_f29.sort_values(by=29, ascending= False) \n",
        "train_f29 =train_f29.reset_index() \n",
        "train_f29 =train_f29.drop('index',axis=1) \n",
        "\n",
        "train_f30 = original_train[30] \n",
        "train_f30= train_f30.reset_index() \n",
        "train_f30 =train_f30.sort_values(by=30, ascending= False) \n",
        "train_f30 =train_f30.reset_index() \n",
        "train_f30 =train_f30.drop('index',axis=1) \n",
        "\n",
        "train_f31 = original_train[31] \n",
        "train_f31= train_f31.reset_index() \n",
        "train_f31 =train_f31.sort_values(by=31, ascending= False) \n",
        "train_f31 =train_f31.reset_index() \n",
        "train_f31 =train_f31.drop('index',axis=1) \n",
        "\n",
        "train_f32 = original_train[32] \n",
        "train_f32= train_f32.reset_index() \n",
        "train_f32 =train_f32.sort_values(by=32, ascending= False) \n",
        "train_f32 =train_f32.reset_index() \n",
        "train_f32 =train_f32.drop('index',axis=1) \n",
        "\n",
        "\n",
        "train_f38 = original_train[38] \n",
        "train_f38= train_f38.reset_index() \n",
        "train_f38 =train_f38.sort_values(by=38, ascending= False) \n",
        "train_f38 =train_f38.reset_index() \n",
        "train_f38 =train_f38.drop('index',axis=1) \n",
        "\n",
        "train_f39 = original_train[39] \n",
        "train_f39= train_f39.reset_index() \n",
        "train_f39 =train_f39.sort_values(by=39, ascending= False) \n",
        "train_f39 =train_f39.reset_index() \n",
        "train_f39 =train_f39.drop('index',axis=1) \n",
        "\n",
        "train_f40 = original_train[40] \n",
        "train_f40= train_f40.reset_index() \n",
        "train_f40 =train_f40.sort_values(by=40, ascending= False) \n",
        "train_f40 =train_f40.reset_index() \n",
        "train_f40 =train_f40.drop('index',axis=1) \n",
        "\n",
        "train_f41 = original_train[41] \n",
        "train_f41= train_f41.reset_index() \n",
        "train_f41 =train_f41.sort_values(by=41, ascending= False) \n",
        "train_f41 =train_f41.reset_index() \n",
        "train_f41 =train_f41.drop('index',axis=1) \n",
        "\n",
        "train_f42 = original_train[42] \n",
        "train_f42= train_f42.reset_index() \n",
        "train_f42 =train_f42.sort_values(by=42, ascending= False) \n",
        "train_f42 =train_f42.reset_index() \n",
        "train_f42 =train_f42.drop('index',axis=1) \n",
        "\n",
        "train_f43 = original_train[43] \n",
        "train_f43= train_f43.reset_index() \n",
        "train_f43 =train_f43.sort_values(by=43, ascending= False) \n",
        "train_f43 =train_f43.reset_index() \n",
        "train_f43 =train_f43.drop('index',axis=1) \n",
        "\n",
        "\n",
        "train_f47 = original_train[47] \n",
        "train_f47= train_f47.reset_index() \n",
        "train_f47 =train_f47.sort_values(by=47, ascending= False) \n",
        "train_f47 =train_f47.reset_index() \n",
        "train_f47 =train_f47.drop('index',axis=1) \n",
        "\n",
        "train_f48 = original_train[48] \n",
        "train_f48= train_f48.reset_index() \n",
        "train_f48 =train_f48.sort_values(by=48, ascending= False) \n",
        "train_f48 =train_f48.reset_index() \n",
        "train_f48 =train_f48.drop('index',axis=1) \n",
        "\n",
        "train_f49 = original_train[49] \n",
        "train_f49= train_f49.reset_index() \n",
        "train_f49 =train_f49.sort_values(by=49, ascending= False) \n",
        "train_f49 =train_f49.reset_index() \n",
        "train_f49 =train_f49.drop('index',axis=1) \n",
        "\n",
        "train_f50 = original_train[50] \n",
        "train_f50= train_f50.reset_index() \n",
        "train_f50 =train_f50.sort_values(by=50, ascending= False) \n",
        "train_f50 =train_f50.reset_index() \n",
        "train_f50 =train_f50.drop('index',axis=1) \n",
        "train_f50.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVGs2D0G56S4"
      },
      "source": [
        "f_df1 = pd.merge(train_f1,test_hsc1,how='inner',on='INST_.1')\n",
        "f_df2 = pd.merge(train_f2,test_hsc2,how='inner',on='INST_.1')\n",
        "f_df3 = pd.merge(train_f3,test_hsc3,how='inner',on='INST_.1')\n",
        "f_df4 = pd.merge(train_f4,test_hsc4,how='inner',on='INST_.1')\n",
        "\n",
        "f_df11 = pd.merge(train_f11,test_hsc11,how='inner',on='INST_.1')\n",
        "f_df12 = pd.merge(train_f12,test_hsc12,how='inner',on='INST_.1')\n",
        "f_df13 = pd.merge(train_f13,test_hsc13,how='inner',on='INST_.1')\n",
        "f_df14 = pd.merge(train_f14,test_hsc14,how='inner',on='INST_.1')\n",
        "f_df15 = pd.merge(train_f15,test_hsc15,how='inner',on='INST_.1')\n",
        "f_df16 = pd.merge(train_f16,test_hsc16,how='inner',on='INST_.1')\n",
        "\n",
        "f_df19 = pd.merge(train_f19,test_hsc19,how='inner',on='INST_.1')\n",
        "f_df20 = pd.merge(train_f20,test_hsc20,how='inner',on='INST_.1')\n",
        "f_df21 = pd.merge(train_f21,test_hsc21,how='inner',on='INST_.1')\n",
        "f_df22 = pd.merge(train_f22,test_hsc22,how='inner',on='INST_.1')\n",
        "f_df23 = pd.merge(train_f23,test_hsc23,how='inner',on='INST_.1')\n",
        "\n",
        "f_df28 = pd.merge(train_f28,test_hsc28,how='inner',on='INST_.1')\n",
        "f_df29 = pd.merge(train_f29,test_hsc29,how='inner',on='INST_.1')\n",
        "f_df30 = pd.merge(train_f30,test_hsc30,how='inner',on='INST_.1')\n",
        "f_df31 = pd.merge(train_f31,test_hsc31,how='inner',on='INST_.1')\n",
        "f_df32 = pd.merge(train_f32,test_hsc32,how='inner',on='INST_.1')\n",
        "\n",
        "f_df38 = pd.merge(train_f38,test_hsc38,how='inner',on='INST_.1')\n",
        "f_df39 = pd.merge(train_f39,test_hsc39,how='inner',on='INST_.1')\n",
        "f_df40 = pd.merge(train_f40,test_hsc40,how='inner',on='INST_.1')\n",
        "f_df41 = pd.merge(train_f41,test_hsc41,how='inner',on='INST_.1')\n",
        "f_df42 = pd.merge(train_f42,test_hsc42,how='inner',on='INST_.1')\n",
        "f_df43 = pd.merge(train_f43,test_hsc43,how='inner',on='INST_.1')\n",
        "\n",
        "f_df47 = pd.merge(train_f47,test_hsc47,how='inner',on='INST_.1')\n",
        "f_df48 = pd.merge(train_f48,test_hsc48,how='inner',on='INST_.1')\n",
        "f_df49 = pd.merge(train_f49,test_hsc49,how='inner',on='INST_.1')\n",
        "f_df50 = pd.merge(train_f50,test_hsc50,how='inner',on='INST_.1')\n",
        "f_df50.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCQCHsv7hwUS"
      },
      "source": [
        " def lcs(s1, s2, s1Index, s2Index, arr):\n",
        "    \n",
        "    if s1Index ==-1 or s2Index == -1:\n",
        "        return 0\n",
        "    if(arr[s1Index][s2Index] != None):\n",
        "        return arr[s1Index][s2Index]\n",
        "\n",
        "    if s1[s1Index] == s2 [s2Index]:\n",
        "        result = 1+ lcs(s1, s2, s1Index -1, s2Index -1, arr)\n",
        "    else:\n",
        "        result= max(lcs(s1, s2, s1Index -1, s2Index, arr), lcs(s1, s2, s1Index, s2Index -1, arr))\n",
        "    arr[s1Index][s2Index] = result\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2Img7mq56S9"
      },
      "source": [
        "s1 = train_f1['INST_.1'].astype(str) \n",
        "s2= test_hsc1['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy1= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df1) \n",
        "print(1 ,',',len(f_df1),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy1,2)) \n",
        "\n",
        "s1 = train_f2['INST_.1'].astype(str) \n",
        "s2= test_hsc2['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy2= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df2) \n",
        "print(2 ,',',len(f_df2),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy2,2)) \n",
        "\n",
        "s1 = train_f3['INST_.1'].astype(str) \n",
        "s2= test_hsc3['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy3= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df3) \n",
        "print(3 ,',',len(f_df3),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy3,2)) \n",
        "\n",
        "s1 = train_f4['INST_.1'].astype(str) \n",
        "s2= test_hsc4['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy4= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df4) \n",
        "print(4 ,',',len(f_df4),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy4,2)) \n",
        "\n",
        "\n",
        "s1 = train_f11['INST_.1'].astype(str) \n",
        "s2= test_hsc11['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy11= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df11) \n",
        "print(11 ,',',len(f_df11),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy11,2)) \n",
        "\n",
        "s1 = train_f12['INST_.1'].astype(str) \n",
        "s2= test_hsc12['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy12= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df12) \n",
        "print(12 ,',',len(f_df12),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy12,2)) \n",
        "\n",
        "s1 = train_f13['INST_.1'].astype(str) \n",
        "s2= test_hsc13['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy13= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df13) \n",
        "print(13 ,',',len(f_df13),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy13,2)) \n",
        "\n",
        "s1 = train_f14['INST_.1'].astype(str) \n",
        "s2= test_hsc14['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy14= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df14) \n",
        "print(14 ,',',len(f_df14),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy14,2)) \n",
        "\n",
        "s1 = train_f15['INST_.1'].astype(str) \n",
        "s2= test_hsc15['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy15= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df15) \n",
        "print(15 ,',',len(f_df15),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy15,2)) \n",
        "\n",
        "s1 = train_f16['INST_.1'].astype(str) \n",
        "s2= test_hsc16['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy16= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df16) \n",
        "print(16 ,',',len(f_df16),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy16,2)) \n",
        "\n",
        "\n",
        "s1 = train_f19['INST_.1'].astype(str) \n",
        "s2= test_hsc19['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy19= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df19) \n",
        "print(19 ,',',len(f_df19),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy19,2)) \n",
        "\n",
        "s1 = train_f20['INST_.1'].astype(str) \n",
        "s2= test_hsc20['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy20= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df20) \n",
        "print(20 ,',',len(f_df20),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy20,2)) \n",
        "\n",
        "s1 = train_f21['INST_.1'].astype(str) \n",
        "s2= test_hsc21['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy21= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df21) \n",
        "print(21 ,',',len(f_df21),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy21,2)) \n",
        "\n",
        "s1 = train_f22['INST_.1'].astype(str) \n",
        "s2= test_hsc22['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy22= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df22) \n",
        "print(22 ,',',len(f_df22),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy22,2)) \n",
        "\n",
        "s1 = train_f23['INST_.1'].astype(str) \n",
        "s2= test_hsc23['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy23= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df23) \n",
        "print(23 ,',',len(f_df23),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy23,2)) \n",
        "\n",
        "\n",
        "s1 = train_f28['INST_.1'].astype(str) \n",
        "s2= test_hsc28['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy28= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df28) \n",
        "print(28 ,',',len(f_df28),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy28,2)) \n",
        "\n",
        "s1 = train_f29['INST_.1'].astype(str) \n",
        "s2= test_hsc29['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy29= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df29) \n",
        "print(29 ,',',len(f_df29),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy29,2)) \n",
        "\n",
        "s1 = train_f30['INST_.1'].astype(str) \n",
        "s2= test_hsc30['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy30= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df30) \n",
        "print(30 ,',',len(f_df30),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy30,2)) \n",
        "\n",
        "s1 = train_f31['INST_.1'].astype(str) \n",
        "s2= test_hsc31['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy31= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df31) \n",
        "print(31 ,',',len(f_df31),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy31,2)) \n",
        "\n",
        "s1 = train_f32['INST_.1'].astype(str) \n",
        "s2= test_hsc32['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy32= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df32) \n",
        "print(32 ,',',len(f_df32),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy32,2)) \n",
        "\n",
        "\n",
        "s1 = train_f38['INST_.1'].astype(str) \n",
        "s2= test_hsc38['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy38= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df38) \n",
        "print(38 ,',',len(f_df38),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy38,2)) \n",
        "\n",
        "s1 = train_f39['INST_.1'].astype(str) \n",
        "s2= test_hsc39['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy39= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df39) \n",
        "print(39 ,',',len(f_df39),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy39,2)) \n",
        "\n",
        "s1 = train_f40['INST_.1'].astype(str) \n",
        "s2= test_hsc40['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy40= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df40) \n",
        "print(40 ,',',len(f_df40),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy40,2)) \n",
        "\n",
        "s1 = train_f41['INST_.1'].astype(str) \n",
        "s2= test_hsc41['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy41= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df41) \n",
        "print(41 ,',',len(f_df41),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy41,2)) \n",
        "\n",
        "s1 = train_f42['INST_.1'].astype(str) \n",
        "s2= test_hsc42['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy42= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df42) \n",
        "print(42 ,',',len(f_df42),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy42,2)) \n",
        "\n",
        "s1 = train_f43['INST_.1'].astype(str) \n",
        "s2= test_hsc43['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy43= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df43) \n",
        "print(43 ,',',len(f_df43),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy43,2)) \n",
        "\n",
        "\n",
        "s1 = train_f47['INST_.1'].astype(str) \n",
        "s2= test_hsc47['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy47= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df47) \n",
        "print(47 ,',',len(f_df47),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy47,2)) \n",
        "\n",
        "s1 = train_f48['INST_.1'].astype(str) \n",
        "s2= test_hsc48['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy48= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df48) \n",
        "print(48 ,',',len(f_df48),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy48,2)) \n",
        "\n",
        "s1 = train_f49['INST_.1'].astype(str) \n",
        "s2= test_hsc49['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy49= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df49) \n",
        "print(49 ,',',len(f_df49),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy49,2)) \n",
        "\n",
        "s1 = train_f50['INST_.1'].astype(str) \n",
        "s2= test_hsc50['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy50= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df50) \n",
        "print(50 ,',',len(f_df50),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy50,2)) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYGpjuQp56S-"
      },
      "source": [
        "accuracy_rt=(accuracy1 + accuracy2 + accuracy3 + accuracy4 + accuracy11 + accuracy12 + accuracy13 + accuracy14 + accuracy15 + accuracy16  + accuracy19 + accuracy20 + accuracy21 + accuracy22 + accuracy23 +  accuracy28 + accuracy29 + accuracy30 + accuracy31 + accuracy32  + accuracy38 + accuracy39 + accuracy40 + accuracy41 + accuracy42 + accuracy43 +accuracy47+ accuracy48 +accuracy49 +accuracy50)\n",
        "score_rt = (accuracy_rt/30)*100\n",
        "score_rt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuZLoU_CA364"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksbjOHpOA4vf"
      },
      "source": [
        "**break** **rt**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEOnxyxgDvmx"
      },
      "source": [
        "score_knn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jAvxi_A9IrS"
      },
      "source": [
        "#accuracy17"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkVo5WNA9Hbq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae55jtDK9H62"
      },
      "source": [
        "**SVR** **model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG03BDwm9WkT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayoaKjoV90ir"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import linear_model\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "\n",
        "train_n= train_n.round({\"Deviation of training year\":3}) \n",
        "known_train =train_n.loc[(train_n['Deviation of training year']!=0)]\n",
        "\n",
        "ytn = known_train[\"Deviation of training year\"]\n",
        "Xtn = known_train.drop(columns=[\"Deviation of training year\"])\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xtn,ytn,test_size=0.2,random_state= 40)\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(Xtn,ytn,test_size=0.2,random_state= 39)\n",
        "#model=  LinearRegression()\n",
        "model = SVR()\n",
        "#model = DecisionTreeRegressor()\n",
        "model.fit(X_train,y_train)\n",
        "model.score(X_test,y_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test,model.predict(X_test)))\n",
        "print(model.score(X_test,y_test))\n",
        "print(rmse)\n",
        "\n",
        "\n",
        "unknown_df = unknown_train.drop(columns=[\"Deviation of training year\"])\n",
        "y_pred = model.predict(unknown_df) \n",
        "y_pred  = pd.DataFrame(y_pred)\n",
        "y_pred = y_pred.rename({0: 'Deviation of training year'}, axis=1)\n",
        "y_pred\n",
        "unknown_df=unknown_df.reset_index()\n",
        "unknown_df=unknown_df.drop('index',axis=1)\n",
        "unknown_df\n",
        "df_out = pd.merge(unknown_df, y_pred, how = 'left', left_index = True, right_index = True)\n",
        "df_out\n",
        "known_train =known_train.reset_index()\n",
        "known_train=known_train.drop('index',axis=1)\n",
        "known_train\n",
        "train_frame =[known_train,df_out]\n",
        "reco_train =pd.concat(train_frame)\n",
        "original_train = reco_train.pivot(columns='CATEGORY',index='INST_.1',values='Deviation of training year')\n",
        "original_train\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zvv2dH1T90i9"
      },
      "source": [
        "train_f1 = original_train[1] \n",
        "train_f1= train_f1.reset_index() \n",
        "train_f1 =train_f1.sort_values(by=1, ascending= False) \n",
        "train_f1 =train_f1.reset_index() \n",
        "train_f1 =train_f1.drop('index',axis=1) \n",
        "\n",
        "train_f2 = original_train[2] \n",
        "train_f2= train_f2.reset_index() \n",
        "train_f2 =train_f2.sort_values(by=2, ascending= False) \n",
        "train_f2 =train_f2.reset_index() \n",
        "train_f2 =train_f2.drop('index',axis=1) \n",
        "\n",
        "train_f3 = original_train[3] \n",
        "train_f3= train_f3.reset_index() \n",
        "train_f3 =train_f3.sort_values(by=3, ascending= False) \n",
        "train_f3 =train_f3.reset_index() \n",
        "train_f3 =train_f3.drop('index',axis=1) \n",
        "\n",
        "train_f4 = original_train[4] \n",
        "train_f4= train_f4.reset_index() \n",
        "train_f4 =train_f4.sort_values(by=4, ascending= False) \n",
        "train_f4 =train_f4.reset_index() \n",
        "train_f4 =train_f4.drop('index',axis=1) \n",
        "\n",
        "train_f11 = original_train[11] \n",
        "train_f11= train_f11.reset_index() \n",
        "train_f11 =train_f11.sort_values(by=11, ascending= False) \n",
        "train_f11 =train_f11.reset_index() \n",
        "train_f11 =train_f11.drop('index',axis=1) \n",
        "\n",
        "train_f12 = original_train[12] \n",
        "train_f12= train_f12.reset_index() \n",
        "train_f12 =train_f12.sort_values(by=12, ascending= False) \n",
        "train_f12 =train_f12.reset_index() \n",
        "train_f12 =train_f12.drop('index',axis=1) \n",
        "\n",
        "train_f13 = original_train[13] \n",
        "train_f13= train_f13.reset_index() \n",
        "train_f13 =train_f13.sort_values(by=13, ascending= False) \n",
        "train_f13 =train_f13.reset_index() \n",
        "train_f13 =train_f13.drop('index',axis=1) \n",
        "\n",
        "train_f14 = original_train[14] \n",
        "train_f14= train_f14.reset_index() \n",
        "train_f14 =train_f14.sort_values(by=14, ascending= False) \n",
        "train_f14 =train_f14.reset_index() \n",
        "train_f14 =train_f14.drop('index',axis=1) \n",
        "\n",
        "train_f15 = original_train[15] \n",
        "train_f15= train_f15.reset_index() \n",
        "train_f15 =train_f15.sort_values(by=15, ascending= False) \n",
        "train_f15 =train_f15.reset_index() \n",
        "train_f15 =train_f15.drop('index',axis=1) \n",
        "\n",
        "train_f16 = original_train[16] \n",
        "train_f16= train_f16.reset_index() \n",
        "train_f16 =train_f16.sort_values(by=16, ascending= False) \n",
        "train_f16 =train_f16.reset_index() \n",
        "train_f16 =train_f16.drop('index',axis=1) \n",
        "\n",
        "\n",
        "train_f19 = original_train[19] \n",
        "train_f19= train_f19.reset_index() \n",
        "train_f19 =train_f19.sort_values(by=19, ascending= False) \n",
        "train_f19 =train_f19.reset_index() \n",
        "train_f19 =train_f19.drop('index',axis=1) \n",
        "\n",
        "train_f20 = original_train[20] \n",
        "train_f20= train_f20.reset_index() \n",
        "train_f20 =train_f20.sort_values(by=20, ascending= False) \n",
        "train_f20 =train_f20.reset_index() \n",
        "train_f20 =train_f20.drop('index',axis=1) \n",
        "\n",
        "train_f21 = original_train[21] \n",
        "train_f21= train_f21.reset_index() \n",
        "train_f21 =train_f21.sort_values(by=21, ascending= False) \n",
        "train_f21 =train_f21.reset_index() \n",
        "train_f21 =train_f21.drop('index',axis=1) \n",
        "\n",
        "train_f22 = original_train[22] \n",
        "train_f22= train_f22.reset_index() \n",
        "train_f22 =train_f22.sort_values(by=22, ascending= False) \n",
        "train_f22 =train_f22.reset_index() \n",
        "train_f22 =train_f22.drop('index',axis=1) \n",
        "\n",
        "train_f23 = original_train[23] \n",
        "train_f23= train_f23.reset_index() \n",
        "train_f23 =train_f23.sort_values(by=23, ascending= False) \n",
        "train_f23 =train_f23.reset_index() \n",
        "train_f23 =train_f23.drop('index',axis=1) \n",
        "\n",
        "\n",
        "train_f28 = original_train[28] \n",
        "train_f28= train_f28.reset_index() \n",
        "train_f28 =train_f28.sort_values(by=28, ascending= False) \n",
        "train_f28 =train_f28.reset_index() \n",
        "train_f28 =train_f28.drop('index',axis=1) \n",
        "\n",
        "train_f29 = original_train[29] \n",
        "train_f29= train_f29.reset_index() \n",
        "train_f29 =train_f29.sort_values(by=29, ascending= False) \n",
        "train_f29 =train_f29.reset_index() \n",
        "train_f29 =train_f29.drop('index',axis=1) \n",
        "\n",
        "train_f30 = original_train[30] \n",
        "train_f30= train_f30.reset_index() \n",
        "train_f30 =train_f30.sort_values(by=30, ascending= False) \n",
        "train_f30 =train_f30.reset_index() \n",
        "train_f30 =train_f30.drop('index',axis=1) \n",
        "\n",
        "train_f31 = original_train[31] \n",
        "train_f31= train_f31.reset_index() \n",
        "train_f31 =train_f31.sort_values(by=31, ascending= False) \n",
        "train_f31 =train_f31.reset_index() \n",
        "train_f31 =train_f31.drop('index',axis=1) \n",
        "\n",
        "train_f32 = original_train[32] \n",
        "train_f32= train_f32.reset_index() \n",
        "train_f32 =train_f32.sort_values(by=32, ascending= False) \n",
        "train_f32 =train_f32.reset_index() \n",
        "train_f32 =train_f32.drop('index',axis=1) \n",
        "\n",
        "\n",
        "train_f38 = original_train[38] \n",
        "train_f38= train_f38.reset_index() \n",
        "train_f38 =train_f38.sort_values(by=38, ascending= False) \n",
        "train_f38 =train_f38.reset_index() \n",
        "train_f38 =train_f38.drop('index',axis=1) \n",
        "\n",
        "train_f39 = original_train[39] \n",
        "train_f39= train_f39.reset_index() \n",
        "train_f39 =train_f39.sort_values(by=39, ascending= False) \n",
        "train_f39 =train_f39.reset_index() \n",
        "train_f39 =train_f39.drop('index',axis=1) \n",
        "\n",
        "train_f40 = original_train[40] \n",
        "train_f40= train_f40.reset_index() \n",
        "train_f40 =train_f40.sort_values(by=40, ascending= False) \n",
        "train_f40 =train_f40.reset_index() \n",
        "train_f40 =train_f40.drop('index',axis=1) \n",
        "\n",
        "train_f41 = original_train[41] \n",
        "train_f41= train_f41.reset_index() \n",
        "train_f41 =train_f41.sort_values(by=41, ascending= False) \n",
        "train_f41 =train_f41.reset_index() \n",
        "train_f41 =train_f41.drop('index',axis=1) \n",
        "\n",
        "train_f42 = original_train[42] \n",
        "train_f42= train_f42.reset_index() \n",
        "train_f42 =train_f42.sort_values(by=42, ascending= False) \n",
        "train_f42 =train_f42.reset_index() \n",
        "train_f42 =train_f42.drop('index',axis=1) \n",
        "\n",
        "train_f43 = original_train[43] \n",
        "train_f43= train_f43.reset_index() \n",
        "train_f43 =train_f43.sort_values(by=43, ascending= False) \n",
        "train_f43 =train_f43.reset_index() \n",
        "train_f43 =train_f43.drop('index',axis=1) \n",
        "\n",
        "\n",
        "train_f47 = original_train[47] \n",
        "train_f47= train_f47.reset_index() \n",
        "train_f47 =train_f47.sort_values(by=47, ascending= False) \n",
        "train_f47 =train_f47.reset_index() \n",
        "train_f47 =train_f47.drop('index',axis=1) \n",
        "\n",
        "train_f48 = original_train[48] \n",
        "train_f48= train_f48.reset_index() \n",
        "train_f48 =train_f48.sort_values(by=48, ascending= False) \n",
        "train_f48 =train_f48.reset_index() \n",
        "train_f48 =train_f48.drop('index',axis=1) \n",
        "\n",
        "train_f49 = original_train[49] \n",
        "train_f49= train_f49.reset_index() \n",
        "train_f49 =train_f49.sort_values(by=49, ascending= False) \n",
        "train_f49 =train_f49.reset_index() \n",
        "train_f49 =train_f49.drop('index',axis=1) \n",
        "\n",
        "train_f50 = original_train[50] \n",
        "train_f50= train_f50.reset_index() \n",
        "train_f50 =train_f50.sort_values(by=50, ascending= False) \n",
        "train_f50 =train_f50.reset_index() \n",
        "train_f50 =train_f50.drop('index',axis=1) \n",
        "train_f50.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR1WJVzV90i-"
      },
      "source": [
        "f_df1 = pd.merge(train_f1,test_hsc1,how='inner',on='INST_.1')\n",
        "f_df2 = pd.merge(train_f2,test_hsc2,how='inner',on='INST_.1')\n",
        "f_df3 = pd.merge(train_f3,test_hsc3,how='inner',on='INST_.1')\n",
        "f_df4 = pd.merge(train_f4,test_hsc4,how='inner',on='INST_.1')\n",
        "\n",
        "f_df11 = pd.merge(train_f11,test_hsc11,how='inner',on='INST_.1')\n",
        "f_df12 = pd.merge(train_f12,test_hsc12,how='inner',on='INST_.1')\n",
        "f_df13 = pd.merge(train_f13,test_hsc13,how='inner',on='INST_.1')\n",
        "f_df14 = pd.merge(train_f14,test_hsc14,how='inner',on='INST_.1')\n",
        "f_df15 = pd.merge(train_f15,test_hsc15,how='inner',on='INST_.1')\n",
        "f_df16 = pd.merge(train_f16,test_hsc16,how='inner',on='INST_.1')\n",
        "\n",
        "f_df19 = pd.merge(train_f19,test_hsc19,how='inner',on='INST_.1')\n",
        "f_df20 = pd.merge(train_f20,test_hsc20,how='inner',on='INST_.1')\n",
        "f_df21 = pd.merge(train_f21,test_hsc21,how='inner',on='INST_.1')\n",
        "f_df22 = pd.merge(train_f22,test_hsc22,how='inner',on='INST_.1')\n",
        "f_df23 = pd.merge(train_f23,test_hsc23,how='inner',on='INST_.1')\n",
        "\n",
        "f_df28 = pd.merge(train_f28,test_hsc28,how='inner',on='INST_.1')\n",
        "f_df29 = pd.merge(train_f29,test_hsc29,how='inner',on='INST_.1')\n",
        "f_df30 = pd.merge(train_f30,test_hsc30,how='inner',on='INST_.1')\n",
        "f_df31 = pd.merge(train_f31,test_hsc31,how='inner',on='INST_.1')\n",
        "f_df32 = pd.merge(train_f32,test_hsc32,how='inner',on='INST_.1')\n",
        "\n",
        "f_df38 = pd.merge(train_f38,test_hsc38,how='inner',on='INST_.1')\n",
        "f_df39 = pd.merge(train_f39,test_hsc39,how='inner',on='INST_.1')\n",
        "f_df40 = pd.merge(train_f40,test_hsc40,how='inner',on='INST_.1')\n",
        "f_df41 = pd.merge(train_f41,test_hsc41,how='inner',on='INST_.1')\n",
        "f_df42 = pd.merge(train_f42,test_hsc42,how='inner',on='INST_.1')\n",
        "f_df43 = pd.merge(train_f43,test_hsc43,how='inner',on='INST_.1')\n",
        "\n",
        "f_df47 = pd.merge(train_f47,test_hsc47,how='inner',on='INST_.1')\n",
        "f_df48 = pd.merge(train_f48,test_hsc48,how='inner',on='INST_.1')\n",
        "f_df49 = pd.merge(train_f49,test_hsc49,how='inner',on='INST_.1')\n",
        "f_df50 = pd.merge(train_f50,test_hsc50,how='inner',on='INST_.1')\n",
        "f_df50.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDzIUa2qh1EU"
      },
      "source": [
        " def lcs(s1, s2, s1Index, s2Index, arr):\n",
        "    \n",
        "    if s1Index ==-1 or s2Index == -1:\n",
        "        return 0\n",
        "    if(arr[s1Index][s2Index] != None):\n",
        "        return arr[s1Index][s2Index]\n",
        "\n",
        "    if s1[s1Index] == s2 [s2Index]:\n",
        "        result = 1+ lcs(s1, s2, s1Index -1, s2Index -1, arr)\n",
        "    else:\n",
        "        result= max(lcs(s1, s2, s1Index -1, s2Index, arr), lcs(s1, s2, s1Index, s2Index -1, arr))\n",
        "    arr[s1Index][s2Index] = result\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QznAS8q90i-"
      },
      "source": [
        "s1 = train_f1['INST_.1'].astype(str) \n",
        "s2= test_hsc1['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy1= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df1) \n",
        "print(1 ,',',len(f_df1),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy1,2)) \n",
        "\n",
        "s1 = train_f2['INST_.1'].astype(str) \n",
        "s2= test_hsc2['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy2= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df2) \n",
        "print(2 ,',',len(f_df2),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy2,2)) \n",
        "\n",
        "s1 = train_f3['INST_.1'].astype(str) \n",
        "s2= test_hsc3['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy3= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df3) \n",
        "print(3 ,',',len(f_df3),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy3,2)) \n",
        "\n",
        "s1 = train_f4['INST_.1'].astype(str) \n",
        "s2= test_hsc4['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy4= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df4) \n",
        "print(4 ,',',len(f_df4),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy4,2)) \n",
        "\n",
        "\n",
        "s1 = train_f11['INST_.1'].astype(str) \n",
        "s2= test_hsc11['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy11= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df11) \n",
        "print(11 ,',',len(f_df11),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy11,2)) \n",
        "\n",
        "s1 = train_f12['INST_.1'].astype(str) \n",
        "s2= test_hsc12['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy12= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df12) \n",
        "print(12 ,',',len(f_df12),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy12,2)) \n",
        "\n",
        "s1 = train_f13['INST_.1'].astype(str) \n",
        "s2= test_hsc13['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy13= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df13) \n",
        "print(13 ,',',len(f_df13),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy13,2)) \n",
        "\n",
        "s1 = train_f14['INST_.1'].astype(str) \n",
        "s2= test_hsc14['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy14= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df14) \n",
        "print(14 ,',',len(f_df14),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy14,2)) \n",
        "\n",
        "s1 = train_f15['INST_.1'].astype(str) \n",
        "s2= test_hsc15['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy15= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df15) \n",
        "print(15 ,',',len(f_df15),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy15,2)) \n",
        "\n",
        "s1 = train_f16['INST_.1'].astype(str) \n",
        "s2= test_hsc16['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy16= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df16) \n",
        "print(16 ,',',len(f_df16),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy16,2)) \n",
        "\n",
        "\n",
        "s1 = train_f19['INST_.1'].astype(str) \n",
        "s2= test_hsc19['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy19= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df19) \n",
        "print(19 ,',',len(f_df19),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy19,2)) \n",
        "\n",
        "s1 = train_f20['INST_.1'].astype(str) \n",
        "s2= test_hsc20['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy20= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df20) \n",
        "print(20 ,',',len(f_df20),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy20,2)) \n",
        "\n",
        "s1 = train_f21['INST_.1'].astype(str) \n",
        "s2= test_hsc21['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy21= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df21) \n",
        "print(21 ,',',len(f_df21),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy21,2)) \n",
        "\n",
        "s1 = train_f22['INST_.1'].astype(str) \n",
        "s2= test_hsc22['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy22= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df22) \n",
        "print(22 ,',',len(f_df22),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy22,2)) \n",
        "\n",
        "s1 = train_f23['INST_.1'].astype(str) \n",
        "s2= test_hsc23['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy23= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df23) \n",
        "print(23 ,',',len(f_df23),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy23,2)) \n",
        "\n",
        "\n",
        "s1 = train_f28['INST_.1'].astype(str) \n",
        "s2= test_hsc28['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy28= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df28) \n",
        "print(28 ,',',len(f_df28),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy28,2)) \n",
        "\n",
        "s1 = train_f29['INST_.1'].astype(str) \n",
        "s2= test_hsc29['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy29= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df29) \n",
        "print(29 ,',',len(f_df29),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy29,2)) \n",
        "\n",
        "s1 = train_f30['INST_.1'].astype(str) \n",
        "s2= test_hsc30['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy30= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df30) \n",
        "print(30 ,',',len(f_df30),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy30,2)) \n",
        "\n",
        "s1 = train_f31['INST_.1'].astype(str) \n",
        "s2= test_hsc31['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy31= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df31) \n",
        "print(31 ,',',len(f_df31),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy31,2)) \n",
        "\n",
        "s1 = train_f32['INST_.1'].astype(str) \n",
        "s2= test_hsc32['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy32= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df32) \n",
        "print(32 ,',',len(f_df32),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy32,2)) \n",
        "\n",
        "\n",
        "s1 = train_f38['INST_.1'].astype(str) \n",
        "s2= test_hsc38['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy38= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df38) \n",
        "print(38 ,',',len(f_df38),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy38,2)) \n",
        "\n",
        "s1 = train_f39['INST_.1'].astype(str) \n",
        "s2= test_hsc39['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy39= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df39) \n",
        "print(39 ,',',len(f_df39),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy39,2)) \n",
        "\n",
        "s1 = train_f40['INST_.1'].astype(str) \n",
        "s2= test_hsc40['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy40= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df40) \n",
        "print(40 ,',',len(f_df40),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy40,2)) \n",
        "\n",
        "s1 = train_f41['INST_.1'].astype(str) \n",
        "s2= test_hsc41['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy41= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df41) \n",
        "print(41 ,',',len(f_df41),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy41,2)) \n",
        "\n",
        "s1 = train_f42['INST_.1'].astype(str) \n",
        "s2= test_hsc42['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy42= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df42) \n",
        "print(42 ,',',len(f_df42),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy42,2)) \n",
        "\n",
        "s1 = train_f43['INST_.1'].astype(str) \n",
        "s2= test_hsc43['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy43= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df43) \n",
        "print(43 ,',',len(f_df43),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy43,2)) \n",
        "\n",
        "\n",
        "s1 = train_f47['INST_.1'].astype(str) \n",
        "s2= test_hsc47['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy47= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df47) \n",
        "print(47 ,',',len(f_df47),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy47,2)) \n",
        "\n",
        "s1 = train_f48['INST_.1'].astype(str) \n",
        "s2= test_hsc48['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy48= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df48) \n",
        "print(48 ,',',len(f_df48),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy48,2)) \n",
        "\n",
        "s1 = train_f49['INST_.1'].astype(str) \n",
        "s2= test_hsc49['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy49= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df49) \n",
        "print(49 ,',',len(f_df49),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy49,2)) \n",
        "\n",
        "s1 = train_f50['INST_.1'].astype(str) \n",
        "s2= test_hsc50['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy50= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df50) \n",
        "print(50 ,',',len(f_df50),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy50,2)) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9T5uS_8690i_"
      },
      "source": [
        "accuracy_svr=(accuracy1 + accuracy2 + accuracy3 + accuracy4 + accuracy11 + accuracy12 + accuracy13 + accuracy14 + accuracy15 + accuracy16  + accuracy19 + accuracy20 + accuracy21 + accuracy22 + accuracy23 +  accuracy28 + accuracy29 + accuracy30 + accuracy31 + accuracy32  + accuracy38 + accuracy39 + accuracy40 + accuracy41 + accuracy42 + accuracy43 +accuracy47+ accuracy48 +accuracy49 +accuracy50)\n",
        "score_svr = (accuracy_svr/30)*100\n",
        "score_svr\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S069GXiAzh1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7F-se_tATBf"
      },
      "source": [
        "'''accuracy_dt=(accuracy1 + accuracy2 + accuracy3 + accuracy4 + accuracy11 + accuracy12 + accuracy13 + accuracy14 + accuracy15 + accuracy16  + accuracy19 + accuracy20 + accuracy21 + accuracy22 + accuracy23 +  accuracy28 + accuracy29 + accuracy30 + accuracy31 + accuracy32  + accuracy38 + accuracy39 + accuracy40 + accuracy41 + accuracy42 + accuracy43 +accuracy47+ accuracy48 +accuracy49 +accuracy50)\n",
        "score_dt = (accuracy_dt/30)*100\n",
        "score_dt'''\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv9ZwNjeFw38"
      },
      "source": [
        "**break** **svr**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWLRRZ_mwszz"
      },
      "source": [
        "#accuracy17"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPgOub1-Fvgb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n97ElkQBFwB1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_xL6d0a_D64"
      },
      "source": [
        "lcs13to15 =pd.read_csv('/content/drive/MyDrive/Colab Notebooks/lcs dataset/lcs13to15.csv')\n",
        "lcs13to15\n",
        "         "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCexHFfg_Y5Y"
      },
      "source": [
        "accuracy_of_13_14_15 = lcs13to15['Accuracy'].sum()\n",
        "accuracy_of_13_14_15\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_AnZOVBf4F2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmLz2aG2f4hD"
      },
      "source": [
        "**DT** **Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aObejEugf84W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-f0Bodhf9Rt"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import linear_model\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "\n",
        "train_n= train_n.round({\"Deviation of training year\":3}) \n",
        "known_train =train_n.loc[(train_n['Deviation of training year']!=0)]\n",
        "\n",
        "ytn = known_train[\"Deviation of training year\"]\n",
        "Xtn = known_train.drop(columns=[\"Deviation of training year\"])\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xtn,ytn,test_size=0.2,random_state= 41)\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(Xtn,ytn,test_size=0.2,random_state= 39)\n",
        "#model=  LinearRegression()\n",
        "#model = SVR()\n",
        "model = DecisionTreeRegressor(random_state= 41)\n",
        "model.fit(X_train,y_train)\n",
        "model.score(X_test,y_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test,model.predict(X_test)))\n",
        "print(model.score(X_test,y_test))\n",
        "print(rmse)\n",
        "\n",
        "\n",
        "unknown_df = unknown_train.drop(columns=[\"Deviation of training year\"])\n",
        "y_pred = model.predict(unknown_df) \n",
        "y_pred  = pd.DataFrame(y_pred)\n",
        "y_pred = y_pred.rename({0: 'Deviation of training year'}, axis=1)\n",
        "y_pred\n",
        "unknown_df=unknown_df.reset_index()\n",
        "unknown_df=unknown_df.drop('index',axis=1)\n",
        "unknown_df\n",
        "df_out = pd.merge(unknown_df, y_pred, how = 'left', left_index = True, right_index = True)\n",
        "df_out\n",
        "known_train =known_train.reset_index()\n",
        "known_train=known_train.drop('index',axis=1)\n",
        "known_train\n",
        "train_frame =[known_train,df_out]\n",
        "reco_train =pd.concat(train_frame)\n",
        "original_train = reco_train.pivot(columns='CATEGORY',index='INST_.1',values='Deviation of training year')\n",
        "original_train\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM4VCmZdf9Rw"
      },
      "source": [
        "train_f1 = original_train[1] \n",
        "train_f1= train_f1.reset_index() \n",
        "train_f1 =train_f1.sort_values(by=1, ascending= False) \n",
        "train_f1 =train_f1.reset_index() \n",
        "train_f1 =train_f1.drop('index',axis=1) \n",
        "\n",
        "train_f2 = original_train[2] \n",
        "train_f2= train_f2.reset_index() \n",
        "train_f2 =train_f2.sort_values(by=2, ascending= False) \n",
        "train_f2 =train_f2.reset_index() \n",
        "train_f2 =train_f2.drop('index',axis=1) \n",
        "\n",
        "train_f3 = original_train[3] \n",
        "train_f3= train_f3.reset_index() \n",
        "train_f3 =train_f3.sort_values(by=3, ascending= False) \n",
        "train_f3 =train_f3.reset_index() \n",
        "train_f3 =train_f3.drop('index',axis=1) \n",
        "\n",
        "train_f4 = original_train[4] \n",
        "train_f4= train_f4.reset_index() \n",
        "train_f4 =train_f4.sort_values(by=4, ascending= False) \n",
        "train_f4 =train_f4.reset_index() \n",
        "train_f4 =train_f4.drop('index',axis=1) \n",
        "\n",
        "train_f11 = original_train[11] \n",
        "train_f11= train_f11.reset_index() \n",
        "train_f11 =train_f11.sort_values(by=11, ascending= False) \n",
        "train_f11 =train_f11.reset_index() \n",
        "train_f11 =train_f11.drop('index',axis=1) \n",
        "\n",
        "train_f12 = original_train[12] \n",
        "train_f12= train_f12.reset_index() \n",
        "train_f12 =train_f12.sort_values(by=12, ascending= False) \n",
        "train_f12 =train_f12.reset_index() \n",
        "train_f12 =train_f12.drop('index',axis=1) \n",
        "\n",
        "train_f13 = original_train[13] \n",
        "train_f13= train_f13.reset_index() \n",
        "train_f13 =train_f13.sort_values(by=13, ascending= False) \n",
        "train_f13 =train_f13.reset_index() \n",
        "train_f13 =train_f13.drop('index',axis=1) \n",
        "\n",
        "train_f14 = original_train[14] \n",
        "train_f14= train_f14.reset_index() \n",
        "train_f14 =train_f14.sort_values(by=14, ascending= False) \n",
        "train_f14 =train_f14.reset_index() \n",
        "train_f14 =train_f14.drop('index',axis=1) \n",
        "\n",
        "train_f15 = original_train[15] \n",
        "train_f15= train_f15.reset_index() \n",
        "train_f15 =train_f15.sort_values(by=15, ascending= False) \n",
        "train_f15 =train_f15.reset_index() \n",
        "train_f15 =train_f15.drop('index',axis=1) \n",
        "\n",
        "train_f16 = original_train[16] \n",
        "train_f16= train_f16.reset_index() \n",
        "train_f16 =train_f16.sort_values(by=16, ascending= False) \n",
        "train_f16 =train_f16.reset_index() \n",
        "train_f16 =train_f16.drop('index',axis=1) \n",
        "\n",
        "\n",
        "train_f19 = original_train[19] \n",
        "train_f19= train_f19.reset_index() \n",
        "train_f19 =train_f19.sort_values(by=19, ascending= False) \n",
        "train_f19 =train_f19.reset_index() \n",
        "train_f19 =train_f19.drop('index',axis=1) \n",
        "\n",
        "train_f20 = original_train[20] \n",
        "train_f20= train_f20.reset_index() \n",
        "train_f20 =train_f20.sort_values(by=20, ascending= False) \n",
        "train_f20 =train_f20.reset_index() \n",
        "train_f20 =train_f20.drop('index',axis=1) \n",
        "\n",
        "train_f21 = original_train[21] \n",
        "train_f21= train_f21.reset_index() \n",
        "train_f21 =train_f21.sort_values(by=21, ascending= False) \n",
        "train_f21 =train_f21.reset_index() \n",
        "train_f21 =train_f21.drop('index',axis=1) \n",
        "\n",
        "train_f22 = original_train[22] \n",
        "train_f22= train_f22.reset_index() \n",
        "train_f22 =train_f22.sort_values(by=22, ascending= False) \n",
        "train_f22 =train_f22.reset_index() \n",
        "train_f22 =train_f22.drop('index',axis=1) \n",
        "\n",
        "train_f23 = original_train[23] \n",
        "train_f23= train_f23.reset_index() \n",
        "train_f23 =train_f23.sort_values(by=23, ascending= False) \n",
        "train_f23 =train_f23.reset_index() \n",
        "train_f23 =train_f23.drop('index',axis=1) \n",
        "\n",
        "\n",
        "train_f28 = original_train[28] \n",
        "train_f28= train_f28.reset_index() \n",
        "train_f28 =train_f28.sort_values(by=28, ascending= False) \n",
        "train_f28 =train_f28.reset_index() \n",
        "train_f28 =train_f28.drop('index',axis=1) \n",
        "\n",
        "train_f29 = original_train[29] \n",
        "train_f29= train_f29.reset_index() \n",
        "train_f29 =train_f29.sort_values(by=29, ascending= False) \n",
        "train_f29 =train_f29.reset_index() \n",
        "train_f29 =train_f29.drop('index',axis=1) \n",
        "\n",
        "train_f30 = original_train[30] \n",
        "train_f30= train_f30.reset_index() \n",
        "train_f30 =train_f30.sort_values(by=30, ascending= False) \n",
        "train_f30 =train_f30.reset_index() \n",
        "train_f30 =train_f30.drop('index',axis=1) \n",
        "\n",
        "train_f31 = original_train[31] \n",
        "train_f31= train_f31.reset_index() \n",
        "train_f31 =train_f31.sort_values(by=31, ascending= False) \n",
        "train_f31 =train_f31.reset_index() \n",
        "train_f31 =train_f31.drop('index',axis=1) \n",
        "\n",
        "train_f32 = original_train[32] \n",
        "train_f32= train_f32.reset_index() \n",
        "train_f32 =train_f32.sort_values(by=32, ascending= False) \n",
        "train_f32 =train_f32.reset_index() \n",
        "train_f32 =train_f32.drop('index',axis=1) \n",
        "\n",
        "\n",
        "train_f38 = original_train[38] \n",
        "train_f38= train_f38.reset_index() \n",
        "train_f38 =train_f38.sort_values(by=38, ascending= False) \n",
        "train_f38 =train_f38.reset_index() \n",
        "train_f38 =train_f38.drop('index',axis=1) \n",
        "\n",
        "train_f39 = original_train[39] \n",
        "train_f39= train_f39.reset_index() \n",
        "train_f39 =train_f39.sort_values(by=39, ascending= False) \n",
        "train_f39 =train_f39.reset_index() \n",
        "train_f39 =train_f39.drop('index',axis=1) \n",
        "\n",
        "train_f40 = original_train[40] \n",
        "train_f40= train_f40.reset_index() \n",
        "train_f40 =train_f40.sort_values(by=40, ascending= False) \n",
        "train_f40 =train_f40.reset_index() \n",
        "train_f40 =train_f40.drop('index',axis=1) \n",
        "\n",
        "train_f41 = original_train[41] \n",
        "train_f41= train_f41.reset_index() \n",
        "train_f41 =train_f41.sort_values(by=41, ascending= False) \n",
        "train_f41 =train_f41.reset_index() \n",
        "train_f41 =train_f41.drop('index',axis=1) \n",
        "\n",
        "train_f42 = original_train[42] \n",
        "train_f42= train_f42.reset_index() \n",
        "train_f42 =train_f42.sort_values(by=42, ascending= False) \n",
        "train_f42 =train_f42.reset_index() \n",
        "train_f42 =train_f42.drop('index',axis=1) \n",
        "\n",
        "train_f43 = original_train[43] \n",
        "train_f43= train_f43.reset_index() \n",
        "train_f43 =train_f43.sort_values(by=43, ascending= False) \n",
        "train_f43 =train_f43.reset_index() \n",
        "train_f43 =train_f43.drop('index',axis=1) \n",
        "\n",
        "\n",
        "train_f47 = original_train[47] \n",
        "train_f47= train_f47.reset_index() \n",
        "train_f47 =train_f47.sort_values(by=47, ascending= False) \n",
        "train_f47 =train_f47.reset_index() \n",
        "train_f47 =train_f47.drop('index',axis=1) \n",
        "\n",
        "train_f48 = original_train[48] \n",
        "train_f48= train_f48.reset_index() \n",
        "train_f48 =train_f48.sort_values(by=48, ascending= False) \n",
        "train_f48 =train_f48.reset_index() \n",
        "train_f48 =train_f48.drop('index',axis=1) \n",
        "\n",
        "train_f49 = original_train[49] \n",
        "train_f49= train_f49.reset_index() \n",
        "train_f49 =train_f49.sort_values(by=49, ascending= False) \n",
        "train_f49 =train_f49.reset_index() \n",
        "train_f49 =train_f49.drop('index',axis=1) \n",
        "\n",
        "train_f50 = original_train[50] \n",
        "train_f50= train_f50.reset_index() \n",
        "train_f50 =train_f50.sort_values(by=50, ascending= False) \n",
        "train_f50 =train_f50.reset_index() \n",
        "train_f50 =train_f50.drop('index',axis=1) \n",
        "train_f50.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9ehAbhAf9R4"
      },
      "source": [
        "f_df1 = pd.merge(train_f1,test_hsc1,how='inner',on='INST_.1')\n",
        "f_df2 = pd.merge(train_f2,test_hsc2,how='inner',on='INST_.1')\n",
        "f_df3 = pd.merge(train_f3,test_hsc3,how='inner',on='INST_.1')\n",
        "f_df4 = pd.merge(train_f4,test_hsc4,how='inner',on='INST_.1')\n",
        "\n",
        "f_df11 = pd.merge(train_f11,test_hsc11,how='inner',on='INST_.1')\n",
        "f_df12 = pd.merge(train_f12,test_hsc12,how='inner',on='INST_.1')\n",
        "f_df13 = pd.merge(train_f13,test_hsc13,how='inner',on='INST_.1')\n",
        "f_df14 = pd.merge(train_f14,test_hsc14,how='inner',on='INST_.1')\n",
        "f_df15 = pd.merge(train_f15,test_hsc15,how='inner',on='INST_.1')\n",
        "f_df16 = pd.merge(train_f16,test_hsc16,how='inner',on='INST_.1')\n",
        "\n",
        "f_df19 = pd.merge(train_f19,test_hsc19,how='inner',on='INST_.1')\n",
        "f_df20 = pd.merge(train_f20,test_hsc20,how='inner',on='INST_.1')\n",
        "f_df21 = pd.merge(train_f21,test_hsc21,how='inner',on='INST_.1')\n",
        "f_df22 = pd.merge(train_f22,test_hsc22,how='inner',on='INST_.1')\n",
        "f_df23 = pd.merge(train_f23,test_hsc23,how='inner',on='INST_.1')\n",
        "\n",
        "f_df28 = pd.merge(train_f28,test_hsc28,how='inner',on='INST_.1')\n",
        "f_df29 = pd.merge(train_f29,test_hsc29,how='inner',on='INST_.1')\n",
        "f_df30 = pd.merge(train_f30,test_hsc30,how='inner',on='INST_.1')\n",
        "f_df31 = pd.merge(train_f31,test_hsc31,how='inner',on='INST_.1')\n",
        "f_df32 = pd.merge(train_f32,test_hsc32,how='inner',on='INST_.1')\n",
        "\n",
        "f_df38 = pd.merge(train_f38,test_hsc38,how='inner',on='INST_.1')\n",
        "f_df39 = pd.merge(train_f39,test_hsc39,how='inner',on='INST_.1')\n",
        "f_df40 = pd.merge(train_f40,test_hsc40,how='inner',on='INST_.1')\n",
        "f_df41 = pd.merge(train_f41,test_hsc41,how='inner',on='INST_.1')\n",
        "f_df42 = pd.merge(train_f42,test_hsc42,how='inner',on='INST_.1')\n",
        "f_df43 = pd.merge(train_f43,test_hsc43,how='inner',on='INST_.1')\n",
        "\n",
        "f_df47 = pd.merge(train_f47,test_hsc47,how='inner',on='INST_.1')\n",
        "f_df48 = pd.merge(train_f48,test_hsc48,how='inner',on='INST_.1')\n",
        "f_df49 = pd.merge(train_f49,test_hsc49,how='inner',on='INST_.1')\n",
        "f_df50 = pd.merge(train_f50,test_hsc50,how='inner',on='INST_.1')\n",
        "f_df50.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMQNVv0bielj"
      },
      "source": [
        " def lcs(s1, s2, s1Index, s2Index, arr):\n",
        "    \n",
        "    if s1Index ==-1 or s2Index == -1:\n",
        "        return 0\n",
        "    if(arr[s1Index][s2Index] != None):\n",
        "        return arr[s1Index][s2Index]\n",
        "\n",
        "    if s1[s1Index] == s2 [s2Index]:\n",
        "        result = 1+ lcs(s1, s2, s1Index -1, s2Index -1, arr)\n",
        "    else:\n",
        "        result= max(lcs(s1, s2, s1Index -1, s2Index, arr), lcs(s1, s2, s1Index, s2Index -1, arr))\n",
        "    arr[s1Index][s2Index] = result\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yLxOTUHf9SC"
      },
      "source": [
        "s1 = train_f1['INST_.1'].astype(str) \n",
        "s2= test_hsc1['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy1= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df1) \n",
        "print(1 ,',',len(f_df1),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy1,2)) \n",
        "\n",
        "s1 = train_f2['INST_.1'].astype(str) \n",
        "s2= test_hsc2['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy2= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df2) \n",
        "print(2 ,',',len(f_df2),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy2,2)) \n",
        "\n",
        "s1 = train_f3['INST_.1'].astype(str) \n",
        "s2= test_hsc3['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy3= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df3) \n",
        "print(3 ,',',len(f_df3),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy3,2)) \n",
        "\n",
        "s1 = train_f4['INST_.1'].astype(str) \n",
        "s2= test_hsc4['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy4= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df4) \n",
        "print(4 ,',',len(f_df4),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy4,2)) \n",
        "\n",
        "\n",
        "s1 = train_f11['INST_.1'].astype(str) \n",
        "s2= test_hsc11['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy11= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df11) \n",
        "print(11 ,',',len(f_df11),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy11,2)) \n",
        "\n",
        "s1 = train_f12['INST_.1'].astype(str) \n",
        "s2= test_hsc12['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy12= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df12) \n",
        "print(12 ,',',len(f_df12),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy12,2)) \n",
        "\n",
        "s1 = train_f13['INST_.1'].astype(str) \n",
        "s2= test_hsc13['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy13= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df13) \n",
        "print(13 ,',',len(f_df13),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy13,2)) \n",
        "\n",
        "s1 = train_f14['INST_.1'].astype(str) \n",
        "s2= test_hsc14['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy14= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df14) \n",
        "print(14 ,',',len(f_df14),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy14,2)) \n",
        "\n",
        "s1 = train_f15['INST_.1'].astype(str) \n",
        "s2= test_hsc15['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy15= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df15) \n",
        "print(15 ,',',len(f_df15),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy15,2)) \n",
        "\n",
        "s1 = train_f16['INST_.1'].astype(str) \n",
        "s2= test_hsc16['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy16= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df16) \n",
        "print(16 ,',',len(f_df16),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy16,2)) \n",
        "\n",
        "\n",
        "s1 = train_f19['INST_.1'].astype(str) \n",
        "s2= test_hsc19['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy19= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df19) \n",
        "print(19 ,',',len(f_df19),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy19,2)) \n",
        "\n",
        "s1 = train_f20['INST_.1'].astype(str) \n",
        "s2= test_hsc20['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy20= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df20) \n",
        "print(20 ,',',len(f_df20),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy20,2)) \n",
        "\n",
        "s1 = train_f21['INST_.1'].astype(str) \n",
        "s2= test_hsc21['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy21= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df21) \n",
        "print(21 ,',',len(f_df21),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy21,2)) \n",
        "\n",
        "s1 = train_f22['INST_.1'].astype(str) \n",
        "s2= test_hsc22['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy22= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df22) \n",
        "print(22 ,',',len(f_df22),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy22,2)) \n",
        "\n",
        "s1 = train_f23['INST_.1'].astype(str) \n",
        "s2= test_hsc23['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy23= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df23) \n",
        "print(23 ,',',len(f_df23),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy23,2)) \n",
        "\n",
        "\n",
        "s1 = train_f28['INST_.1'].astype(str) \n",
        "s2= test_hsc28['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy28= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df28) \n",
        "print(28 ,',',len(f_df28),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy28,2)) \n",
        "\n",
        "s1 = train_f29['INST_.1'].astype(str) \n",
        "s2= test_hsc29['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy29= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df29) \n",
        "print(29 ,',',len(f_df29),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy29,2)) \n",
        "\n",
        "s1 = train_f30['INST_.1'].astype(str) \n",
        "s2= test_hsc30['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy30= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df30) \n",
        "print(30 ,',',len(f_df30),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy30,2)) \n",
        "\n",
        "s1 = train_f31['INST_.1'].astype(str) \n",
        "s2= test_hsc31['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy31= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df31) \n",
        "print(31 ,',',len(f_df31),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy31,2)) \n",
        "\n",
        "s1 = train_f32['INST_.1'].astype(str) \n",
        "s2= test_hsc32['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy32= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df32) \n",
        "print(32 ,',',len(f_df32),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy32,2)) \n",
        "\n",
        "\n",
        "s1 = train_f38['INST_.1'].astype(str) \n",
        "s2= test_hsc38['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy38= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df38) \n",
        "print(38 ,',',len(f_df38),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy38,2)) \n",
        "\n",
        "s1 = train_f39['INST_.1'].astype(str) \n",
        "s2= test_hsc39['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy39= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df39) \n",
        "print(39 ,',',len(f_df39),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy39,2)) \n",
        "\n",
        "s1 = train_f40['INST_.1'].astype(str) \n",
        "s2= test_hsc40['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy40= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df40) \n",
        "print(40 ,',',len(f_df40),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy40,2)) \n",
        "\n",
        "s1 = train_f41['INST_.1'].astype(str) \n",
        "s2= test_hsc41['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy41= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df41) \n",
        "print(41 ,',',len(f_df41),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy41,2)) \n",
        "\n",
        "s1 = train_f42['INST_.1'].astype(str) \n",
        "s2= test_hsc42['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy42= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df42) \n",
        "print(42 ,',',len(f_df42),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy42,2)) \n",
        "\n",
        "s1 = train_f43['INST_.1'].astype(str) \n",
        "s2= test_hsc43['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy43= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df43) \n",
        "print(43 ,',',len(f_df43),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy43,2)) \n",
        "\n",
        "\n",
        "s1 = train_f47['INST_.1'].astype(str) \n",
        "s2= test_hsc47['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy47= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df47) \n",
        "print(47 ,',',len(f_df47),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy47,2)) \n",
        "\n",
        "s1 = train_f48['INST_.1'].astype(str) \n",
        "s2= test_hsc48['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy48= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df48) \n",
        "print(48 ,',',len(f_df48),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy48,2)) \n",
        "\n",
        "s1 = train_f49['INST_.1'].astype(str) \n",
        "s2= test_hsc49['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy49= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df49) \n",
        "print(49 ,',',len(f_df49),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy49,2)) \n",
        "\n",
        "s1 = train_f50['INST_.1'].astype(str) \n",
        "s2= test_hsc50['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy50= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df50) \n",
        "print(50 ,',',len(f_df50),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy50,2)) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPkN7yyzf9SG"
      },
      "source": [
        "accuracy_dt=(accuracy1 + accuracy2 + accuracy3 + accuracy4 + accuracy11 + accuracy12 + accuracy13 + accuracy14 + accuracy15 + accuracy16  + accuracy19 + accuracy20 + accuracy21 + accuracy22 + accuracy23 +  accuracy28 + accuracy29 + accuracy30 + accuracy31 + accuracy32  + accuracy38 + accuracy39 + accuracy40 + accuracy41 + accuracy42 + accuracy43 +accuracy47+ accuracy48 +accuracy49 +accuracy50)\n",
        "score_dt = (accuracy_dt/30)*100\n",
        "score_dt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIgPSqMBgAPa"
      },
      "source": [
        "#accuracy17"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEs4ZTlXgA3w"
      },
      "source": [
        "**break** **dt**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pldL5egKM90h"
      },
      "source": [
        "**LCS** **code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPATeERIobyJ"
      },
      "source": [
        "**Predicted**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54LCrAPspbGk"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import linear_model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF8WIRdS4qQI"
      },
      "source": [
        "train_n= train_n.round({\"Deviation of training year\":3}) \n",
        "known_train =train_n.loc[(train_n['Deviation of training year']!=0)]\n",
        "\n",
        "ytn = known_train[\"Deviation of training year\"]\n",
        "Xtn = known_train.drop(columns=[\"Deviation of training year\"])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xtn,ytn,test_size=0.1,random_state= 51)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xtn,ytn,test_size=0.2,random_state= 39)\n",
        "#model=  LinearRegression()\n",
        "model =RandomForestRegressor(n_estimators= 100,random_state= 41)\n",
        "#model = KNeighborsRegressor(n_neighbors= 2)\n",
        "model.fit(X_train,y_train)\n",
        "model.score(X_test,y_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test,model.predict(X_test)))\n",
        "print(model.score(X_test,y_test))\n",
        "print(rmse)\n",
        "\n",
        "unknown_df1 = train_n.drop(columns=[\"Deviation of training year\"])\n",
        "unknown_df1\n",
        "y_pred = model.predict(unknown_df1) \n",
        "y_pred  = pd.DataFrame(y_pred)\n",
        "y_pred = y_pred.rename({0: 'Deviation of training year'}, axis=1)\n",
        "y_pred\n",
        "df_out = pd.merge(unknown_df1, y_pred, how = 'left', left_index = True, right_index = True)\n",
        "matrix_train = df_out.pivot(columns='CATEGORY',index='INST_.1',values='Deviation of training year')\n",
        "matrix_train\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1G2yq_TdbrD"
      },
      "source": [
        "train_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEwORixdq6_X"
      },
      "source": [
        "test_n=test_n.round({\"Deviation of testing year\":3}) \n",
        "known_test =test_n.loc[(test_n['Deviation of testing year']!=0)]\n",
        "\n",
        "yts = known_test[\"Deviation of testing year\"]\n",
        "Xts = known_test.drop(columns=[\"Deviation of testing year\"])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xts,yts,test_size=0.2,random_state= 51)\n",
        "#model=  LinearRegression()\n",
        "model =RandomForestRegressor(n_estimators= 33,random_state= 51)\n",
        "#model = KNeighborsRegressor(n_neighbors= 2)\n",
        "model.fit(X_train,y_train)\n",
        "model.score(X_test,y_test)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test,model.predict(X_test)))\n",
        "print(model.score(X_test,y_test))\n",
        "print(rmse)\n",
        "\n",
        "unknown_df1 = test_n.drop(columns=[\"Deviation of testing year\"])\n",
        "unknown_df1\n",
        "y_pred = model.predict(unknown_df1) \n",
        "y_pred  = pd.DataFrame(y_pred)\n",
        "y_pred = y_pred.rename({0: 'Deviation of testing year'}, axis=1)\n",
        "y_pred\n",
        "df_test = pd.merge(unknown_df1, y_pred, how = 'left', left_index = True, right_index = True)\n",
        "print(df_test.shape)\n",
        "print(test_n.shape)\n",
        "matrix_test = df_test.pivot(columns='CATEGORY',index='INST_.1',values='Deviation of testing year')\n",
        "matrix_test\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpYQshDxmkey"
      },
      "source": [
        "**LCS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs0MLQQqmn31"
      },
      "source": [
        " def lcs(s1, s2, s1Index, s2Index, arr):\n",
        "    \n",
        "    if s1Index ==-1 or s2Index == -1:\n",
        "        return 0\n",
        "    if(arr[s1Index][s2Index] != None):\n",
        "        return arr[s1Index][s2Index]\n",
        "\n",
        "    if s1[s1Index] == s2 [s2Index]:\n",
        "        result = 1+ lcs(s1, s2, s1Index -1, s2Index -1, arr)\n",
        "    else:\n",
        "        result= max(lcs(s1, s2, s1Index -1, s2Index, arr), lcs(s1, s2, s1Index, s2Index -1, arr))\n",
        "    arr[s1Index][s2Index] = result\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aS95jxNvZ0A"
      },
      "source": [
        "**GridsearchCV**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzWWwWQDvUhA"
      },
      "source": [
        "train_n=train_n.round({\"Deviation of training year\":3}) \n",
        "test_n=test_n.round({\"Deviation of testing year\":3}) \n",
        "known_train =train_n.loc[(train_n['Deviation of training year']!=0)]\n",
        "known_test =test_n.loc[(test_n['Deviation of testing year']!=0)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yntqog1fvUhD"
      },
      "source": [
        "TRAIN_SIZE = 0.80\n",
        "# Create boolean mask\n",
        "# np.random creates a vector of random values between 0 and 1\n",
        "# Those values are filtered to create a binary mask\n",
        "msk = np.random.rand(len(known_train)) < TRAIN_SIZE\n",
        "\n",
        "train80 = known_train[msk]  \n",
        "test20 = known_train[~msk] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvunVo4zvXub"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gFoIyo1Lw6e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igb9bNZzWKBa"
      },
      "source": [
        "***Cosine similarity***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_1XVPZu2GI0"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "import scipy.sparse as sp\n",
        "from scipy.sparse.linalg import svds\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzQVErDtUfnP"
      },
      "source": [
        "df = train_df.pivot(columns='INST_.1',index='CATEGORY',values='Deviation of training year')\n",
        "#df=df.reset_index()\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm3lnhy1WTmM"
      },
      "source": [
        "df1 = test_df.pivot(columns='INST_.1',index='CATEGORY',values='Deviation of testing year')\n",
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZvvGzEKOaB2"
      },
      "source": [
        "**Memory** **based** **CF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVdq7_-UOUcG"
      },
      "source": [
        "n_users = train_df[\"INST_.1\"].unique().shape[0]\n",
        "n_items = train_df.CATEGORY.unique().shape[0]\n",
        "print( str(n_users) + ' users')\n",
        "print( str(n_items) + ' items')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wca_zxV7Vtmt"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "import scipy.sparse as sp\n",
        "from scipy.sparse.linalg import svds\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiqFSj1-DVJg"
      },
      "source": [
        "def predict(l):\n",
        "    # finds the userIds corresponding to the top 5 similarities\n",
        "    # calculate the prediction according to the formula\n",
        "    return (df[l.index] * l).sum(axis=1) / l.sum()\n",
        "df = train_df.pivot(columns='CATEGORY',index='INST_.1',values='Deviation of training year')\n",
        "\n",
        "\n",
        "# use userID as columns for convinience when interpretering the forumla\n",
        "similarity = pd.DataFrame(cosine_similarity(\n",
        "    scale(df.T.fillna(-1000))),\n",
        "    index=df.columns,\n",
        "    columns=df.columns)\n",
        "# iterate each column (userID),\n",
        "# for each userID find the highest five similarities\n",
        "# and use to calculate the prediction for that user,\n",
        "# use fillna so that original ratings dont change\n",
        "\n",
        "res = df.apply(lambda col: ' '.join('{}'.format(mid) for mid in col.fillna(\n",
        "    predict(similarity[col.name].nlargest(7).iloc[1:])).nlargest(10).index))\n",
        "print(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hL2l2Oiq8fE"
      },
      "source": [
        "train_f1.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAJfyyaKdshf"
      },
      "source": [
        "res=res.reset_index()\n",
        "res = res.rename({0: 'Category'}, axis=1)\n",
        "res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK52R_Zcr22Z"
      },
      "source": [
        "def predict(l):\n",
        "    # finds the userIds corresponding to the top 5 similarities\n",
        "    # calculate the prediction according to the formula\n",
        "    return (df[l.index] * l).sum(axis=1) / l.sum()\n",
        "\n",
        "df = test_df.pivot(columns='CATEGORY',index='INST_.1',values='Deviation of testing year')\n",
        "# use userID as columns for convinience when interpretering the forumla\n",
        "similarity = pd.DataFrame(cosine_similarity(\n",
        "    scale(df.T.fillna(-1000))),\n",
        "    index=df.columns,\n",
        "    columns=df.columns)\n",
        "# iterate each column (userID),\n",
        "# for each userID find the highest five similarities\n",
        "# and use to calculate the prediction for that user,\n",
        "# use fillna so that original ratings dont change\n",
        "\n",
        "res1 = df.apply(lambda col: ' '.join('{}'.format(mid) for mid in col.fillna(\n",
        "    predict(similarity[col.name].nlargest(7).iloc[1:])).nlargest(10).index))\n",
        "print(res1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuFge6mydz8f"
      },
      "source": [
        "res1 =res1.reset_index()\n",
        "res1 = res1.rename({0: 'Category'}, axis=1)\n",
        "res1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzmsuVhKaBAv"
      },
      "source": [
        "def find_n_neighbours(df,n):\n",
        "    order = np.argsort(df.values, axis=1)[:, :n]\n",
        "    df = df.apply(lambda x: pd.Series(x.sort_values(ascending=False)\n",
        "           .iloc[:n].index, \n",
        "          index=['top{}'.format(i) for i in range(1, n+1)]), axis=1)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iWBlxKBbsBK"
      },
      "source": [
        "sim_user_30_u = find_n_neighbours(similarity,28)\n",
        "sim_user_30_u.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9j1h2J03kfX"
      },
      "source": [
        "**SVD** **model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-4kqizxOg67"
      },
      "source": [
        "train_svd = train_df.pivot(columns='CATEGORY',index=['INST_.1'],values='Deviation of training year').fillna(0)\n",
        "#train_svd=train_svd.reset_index()\n",
        "train_svd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCLKZnMNU42R"
      },
      "source": [
        "test_svd = test_df.pivot(columns='CATEGORY',index=['INST_.1'],values='Deviation of testing year').fillna(0)\n",
        "#test_svd=test_svd.reset_index()\n",
        "test_svd.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ML3y2ZdB7cQ"
      },
      "source": [
        "train_r = train_svd.values\n",
        "train_college_deviations_mean = np.mean(train_r, axis = 1)\n",
        "R_demeaned_train = train_r - train_college_deviations_mean.reshape(-1, 1)\n",
        "\n",
        "from scipy.sparse.linalg import svds\n",
        "U, sigma, Vt = svds(R_demeaned_train, k = 21)\n",
        "sigma = np.diag(sigma)\n",
        "train_colleges_predicted_deviations = np.dot(np.dot(U, sigma), Vt)+train_college_deviations_mean.reshape(-1, 1)\n",
        "train_colleges_predicted_deviations\n",
        "original_train = pd.DataFrame(train_colleges_predicted_deviations, columns = train_svd.columns)\n",
        "original_train.index= train_svd.index\n",
        "original_train\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRRUHV3UVObf"
      },
      "source": [
        "test_r = test_svd.values\n",
        "test_college_deviations_mean = np.mean(test_r, axis = 1)\n",
        "R_demeaned_test = test_r - test_college_deviations_mean.reshape(-1, 1)\n",
        "R_demeaned_test\n",
        "from scipy.sparse.linalg import svds\n",
        "U, sigma, Vt = svds(R_demeaned_test, k = 23)\n",
        "sigma = np.diag(sigma)\n",
        "test_colleges_predicted_deviations = np.dot(np.dot(U, sigma), Vt)+test_college_deviations_mean.reshape(-1, 1)\n",
        "test_colleges_predicted_deviations\n",
        "test_pred = pd.DataFrame(test_colleges_predicted_deviations, columns = test_svd.columns)\n",
        "test_pred\n",
        "test_pred.index= test_svd.index\n",
        "test_pred.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgGXasUHoc2h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EU4zthVlodMT"
      },
      "source": [
        "train_f1 = original_train[1] \n",
        "train_f1= train_f1.reset_index() \n",
        "train_f1 =train_f1.sort_values(by=1, ascending= False) \n",
        "train_f1 =train_f1.reset_index() \n",
        "train_f1 =train_f1.drop('index',axis=1) \n",
        "\n",
        "train_f2 = original_train[2] \n",
        "train_f2= train_f2.reset_index() \n",
        "train_f2 =train_f2.sort_values(by=2, ascending= False) \n",
        "train_f2 =train_f2.reset_index() \n",
        "train_f2 =train_f2.drop('index',axis=1) \n",
        "\n",
        "train_f3 = original_train[3] \n",
        "train_f3= train_f3.reset_index() \n",
        "train_f3 =train_f3.sort_values(by=3, ascending= False) \n",
        "train_f3 =train_f3.reset_index() \n",
        "train_f3 =train_f3.drop('index',axis=1) \n",
        "\n",
        "train_f4 = original_train[4] \n",
        "train_f4= train_f4.reset_index() \n",
        "train_f4 =train_f4.sort_values(by=4, ascending= False) \n",
        "train_f4 =train_f4.reset_index() \n",
        "train_f4 =train_f4.drop('index',axis=1) \n",
        "\n",
        "train_f11 = original_train[11] \n",
        "train_f11= train_f11.reset_index() \n",
        "train_f11 =train_f11.sort_values(by=11, ascending= False) \n",
        "train_f11 =train_f11.reset_index() \n",
        "train_f11 =train_f11.drop('index',axis=1) \n",
        "\n",
        "train_f12 = original_train[12] \n",
        "train_f12= train_f12.reset_index() \n",
        "train_f12 =train_f12.sort_values(by=12, ascending= False) \n",
        "train_f12 =train_f12.reset_index() \n",
        "train_f12 =train_f12.drop('index',axis=1) \n",
        "\n",
        "train_f13 = original_train[13] \n",
        "train_f13= train_f13.reset_index() \n",
        "train_f13 =train_f13.sort_values(by=13, ascending= False) \n",
        "train_f13 =train_f13.reset_index() \n",
        "train_f13 =train_f13.drop('index',axis=1) \n",
        "\n",
        "train_f14 = original_train[14] \n",
        "train_f14= train_f14.reset_index() \n",
        "train_f14 =train_f14.sort_values(by=14, ascending= False) \n",
        "train_f14 =train_f14.reset_index() \n",
        "train_f14 =train_f14.drop('index',axis=1) \n",
        "\n",
        "train_f15 = original_train[15] \n",
        "train_f15= train_f15.reset_index() \n",
        "train_f15 =train_f15.sort_values(by=15, ascending= False) \n",
        "train_f15 =train_f15.reset_index() \n",
        "train_f15 =train_f15.drop('index',axis=1) \n",
        "\n",
        "train_f16 = original_train[16] \n",
        "train_f16= train_f16.reset_index() \n",
        "train_f16 =train_f16.sort_values(by=16, ascending= False) \n",
        "train_f16 =train_f16.reset_index() \n",
        "train_f16 =train_f16.drop('index',axis=1) \n",
        "\n",
        "\n",
        "train_f19 = original_train[19] \n",
        "train_f19= train_f19.reset_index() \n",
        "train_f19 =train_f19.sort_values(by=19, ascending= False) \n",
        "train_f19 =train_f19.reset_index() \n",
        "train_f19 =train_f19.drop('index',axis=1) \n",
        "\n",
        "train_f20 = original_train[20] \n",
        "train_f20= train_f20.reset_index() \n",
        "train_f20 =train_f20.sort_values(by=20, ascending= False) \n",
        "train_f20 =train_f20.reset_index() \n",
        "train_f20 =train_f20.drop('index',axis=1) \n",
        "\n",
        "train_f21 = original_train[21] \n",
        "train_f21= train_f21.reset_index() \n",
        "train_f21 =train_f21.sort_values(by=21, ascending= False) \n",
        "train_f21 =train_f21.reset_index() \n",
        "train_f21 =train_f21.drop('index',axis=1) \n",
        "\n",
        "train_f22 = original_train[22] \n",
        "train_f22= train_f22.reset_index() \n",
        "train_f22 =train_f22.sort_values(by=22, ascending= False) \n",
        "train_f22 =train_f22.reset_index() \n",
        "train_f22 =train_f22.drop('index',axis=1) \n",
        "\n",
        "train_f23 = original_train[23] \n",
        "train_f23= train_f23.reset_index() \n",
        "train_f23 =train_f23.sort_values(by=23, ascending= False) \n",
        "train_f23 =train_f23.reset_index() \n",
        "train_f23 =train_f23.drop('index',axis=1) \n",
        "\n",
        "\n",
        "train_f28 = original_train[28] \n",
        "train_f28= train_f28.reset_index() \n",
        "train_f28 =train_f28.sort_values(by=28, ascending= False) \n",
        "train_f28 =train_f28.reset_index() \n",
        "train_f28 =train_f28.drop('index',axis=1) \n",
        "\n",
        "train_f29 = original_train[29] \n",
        "train_f29= train_f29.reset_index() \n",
        "train_f29 =train_f29.sort_values(by=29, ascending= False) \n",
        "train_f29 =train_f29.reset_index() \n",
        "train_f29 =train_f29.drop('index',axis=1) \n",
        "\n",
        "train_f30 = original_train[30] \n",
        "train_f30= train_f30.reset_index() \n",
        "train_f30 =train_f30.sort_values(by=30, ascending= False) \n",
        "train_f30 =train_f30.reset_index() \n",
        "train_f30 =train_f30.drop('index',axis=1) \n",
        "\n",
        "train_f31 = original_train[31] \n",
        "train_f31= train_f31.reset_index() \n",
        "train_f31 =train_f31.sort_values(by=31, ascending= False) \n",
        "train_f31 =train_f31.reset_index() \n",
        "train_f31 =train_f31.drop('index',axis=1) \n",
        "\n",
        "train_f32 = original_train[32] \n",
        "train_f32= train_f32.reset_index() \n",
        "train_f32 =train_f32.sort_values(by=32, ascending= False) \n",
        "train_f32 =train_f32.reset_index() \n",
        "train_f32 =train_f32.drop('index',axis=1) \n",
        "\n",
        "\n",
        "train_f38 = original_train[38] \n",
        "train_f38= train_f38.reset_index() \n",
        "train_f38 =train_f38.sort_values(by=38, ascending= False) \n",
        "train_f38 =train_f38.reset_index() \n",
        "train_f38 =train_f38.drop('index',axis=1) \n",
        "\n",
        "train_f39 = original_train[39] \n",
        "train_f39= train_f39.reset_index() \n",
        "train_f39 =train_f39.sort_values(by=39, ascending= False) \n",
        "train_f39 =train_f39.reset_index() \n",
        "train_f39 =train_f39.drop('index',axis=1) \n",
        "\n",
        "train_f40 = original_train[40] \n",
        "train_f40= train_f40.reset_index() \n",
        "train_f40 =train_f40.sort_values(by=40, ascending= False) \n",
        "train_f40 =train_f40.reset_index() \n",
        "train_f40 =train_f40.drop('index',axis=1) \n",
        "\n",
        "train_f41 = original_train[41] \n",
        "train_f41= train_f41.reset_index() \n",
        "train_f41 =train_f41.sort_values(by=41, ascending= False) \n",
        "train_f41 =train_f41.reset_index() \n",
        "train_f41 =train_f41.drop('index',axis=1) \n",
        "\n",
        "train_f42 = original_train[42] \n",
        "train_f42= train_f42.reset_index() \n",
        "train_f42 =train_f42.sort_values(by=42, ascending= False) \n",
        "train_f42 =train_f42.reset_index() \n",
        "train_f42 =train_f42.drop('index',axis=1) \n",
        "\n",
        "train_f43 = original_train[43] \n",
        "train_f43= train_f43.reset_index() \n",
        "train_f43 =train_f43.sort_values(by=43, ascending= False) \n",
        "train_f43 =train_f43.reset_index() \n",
        "train_f43 =train_f43.drop('index',axis=1) \n",
        "\n",
        "\n",
        "train_f47 = original_train[47] \n",
        "train_f47= train_f47.reset_index() \n",
        "train_f47 =train_f47.sort_values(by=47, ascending= False) \n",
        "train_f47 =train_f47.reset_index() \n",
        "train_f47 =train_f47.drop('index',axis=1) \n",
        "\n",
        "train_f48 = original_train[48] \n",
        "train_f48= train_f48.reset_index() \n",
        "train_f48 =train_f48.sort_values(by=48, ascending= False) \n",
        "train_f48 =train_f48.reset_index() \n",
        "train_f48 =train_f48.drop('index',axis=1) \n",
        "\n",
        "train_f49 = original_train[49] \n",
        "train_f49= train_f49.reset_index() \n",
        "train_f49 =train_f49.sort_values(by=49, ascending= False) \n",
        "train_f49 =train_f49.reset_index() \n",
        "train_f49 =train_f49.drop('index',axis=1) \n",
        "\n",
        "train_f50 = original_train[50] \n",
        "train_f50= train_f50.reset_index() \n",
        "train_f50 =train_f50.sort_values(by=50, ascending= False) \n",
        "train_f50 =train_f50.reset_index() \n",
        "train_f50 =train_f50.drop('index',axis=1) \n",
        "train_f50.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HATP3BbodMW"
      },
      "source": [
        "f_df1 = pd.merge(train_f1,test_hsc1,how='inner',on='INST_.1')\n",
        "f_df2 = pd.merge(train_f2,test_hsc2,how='inner',on='INST_.1')\n",
        "f_df3 = pd.merge(train_f3,test_hsc3,how='inner',on='INST_.1')\n",
        "f_df4 = pd.merge(train_f4,test_hsc4,how='inner',on='INST_.1')\n",
        "\n",
        "f_df11 = pd.merge(train_f11,test_hsc11,how='inner',on='INST_.1')\n",
        "f_df12 = pd.merge(train_f12,test_hsc12,how='inner',on='INST_.1')\n",
        "f_df13 = pd.merge(train_f13,test_hsc13,how='inner',on='INST_.1')\n",
        "f_df14 = pd.merge(train_f14,test_hsc14,how='inner',on='INST_.1')\n",
        "f_df15 = pd.merge(train_f15,test_hsc15,how='inner',on='INST_.1')\n",
        "f_df16 = pd.merge(train_f16,test_hsc16,how='inner',on='INST_.1')\n",
        "\n",
        "f_df19 = pd.merge(train_f19,test_hsc19,how='inner',on='INST_.1')\n",
        "f_df20 = pd.merge(train_f20,test_hsc20,how='inner',on='INST_.1')\n",
        "f_df21 = pd.merge(train_f21,test_hsc21,how='inner',on='INST_.1')\n",
        "f_df22 = pd.merge(train_f22,test_hsc22,how='inner',on='INST_.1')\n",
        "f_df23 = pd.merge(train_f23,test_hsc23,how='inner',on='INST_.1')\n",
        "\n",
        "f_df28 = pd.merge(train_f28,test_hsc28,how='inner',on='INST_.1')\n",
        "f_df29 = pd.merge(train_f29,test_hsc29,how='inner',on='INST_.1')\n",
        "f_df30 = pd.merge(train_f30,test_hsc30,how='inner',on='INST_.1')\n",
        "f_df31 = pd.merge(train_f31,test_hsc31,how='inner',on='INST_.1')\n",
        "f_df32 = pd.merge(train_f32,test_hsc32,how='inner',on='INST_.1')\n",
        "\n",
        "f_df38 = pd.merge(train_f38,test_hsc38,how='inner',on='INST_.1')\n",
        "f_df39 = pd.merge(train_f39,test_hsc39,how='inner',on='INST_.1')\n",
        "f_df40 = pd.merge(train_f40,test_hsc40,how='inner',on='INST_.1')\n",
        "f_df41 = pd.merge(train_f41,test_hsc41,how='inner',on='INST_.1')\n",
        "f_df42 = pd.merge(train_f42,test_hsc42,how='inner',on='INST_.1')\n",
        "f_df43 = pd.merge(train_f43,test_hsc43,how='inner',on='INST_.1')\n",
        "\n",
        "f_df47 = pd.merge(train_f47,test_hsc47,how='inner',on='INST_.1')\n",
        "f_df48 = pd.merge(train_f48,test_hsc48,how='inner',on='INST_.1')\n",
        "f_df49 = pd.merge(train_f49,test_hsc49,how='inner',on='INST_.1')\n",
        "f_df50 = pd.merge(train_f50,test_hsc50,how='inner',on='INST_.1')\n",
        "f_df50.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "050Rt5BhodMY"
      },
      "source": [
        " def lcs(s1, s2, s1Index, s2Index, arr):\n",
        "    \n",
        "    if s1Index ==-1 or s2Index == -1:\n",
        "        return 0\n",
        "    if(arr[s1Index][s2Index] != None):\n",
        "        return arr[s1Index][s2Index]\n",
        "\n",
        "    if s1[s1Index] == s2 [s2Index]:\n",
        "        result = 1+ lcs(s1, s2, s1Index -1, s2Index -1, arr)\n",
        "    else:\n",
        "        result= max(lcs(s1, s2, s1Index -1, s2Index, arr), lcs(s1, s2, s1Index, s2Index -1, arr))\n",
        "    arr[s1Index][s2Index] = result\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zga7ymLjodMZ"
      },
      "source": [
        "s1 = train_f1['INST_.1'].astype(str) \n",
        "s2= test_hsc1['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy1= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df1) \n",
        "print(1 ,',',len(f_df1),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy1,2)) \n",
        "\n",
        "s1 = train_f2['INST_.1'].astype(str) \n",
        "s2= test_hsc2['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy2= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df2) \n",
        "print(2 ,',',len(f_df2),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy2,2)) \n",
        "\n",
        "s1 = train_f3['INST_.1'].astype(str) \n",
        "s2= test_hsc3['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy3= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df3) \n",
        "print(3 ,',',len(f_df3),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy3,2)) \n",
        "\n",
        "s1 = train_f4['INST_.1'].astype(str) \n",
        "s2= test_hsc4['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy4= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df4) \n",
        "print(4 ,',',len(f_df4),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy4,2)) \n",
        "\n",
        "\n",
        "s1 = train_f11['INST_.1'].astype(str) \n",
        "s2= test_hsc11['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy11= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df11) \n",
        "print(11 ,',',len(f_df11),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy11,2)) \n",
        "\n",
        "s1 = train_f12['INST_.1'].astype(str) \n",
        "s2= test_hsc12['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy12= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df12) \n",
        "print(12 ,',',len(f_df12),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy12,2)) \n",
        "\n",
        "s1 = train_f13['INST_.1'].astype(str) \n",
        "s2= test_hsc13['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy13= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df13) \n",
        "print(13 ,',',len(f_df13),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy13,2)) \n",
        "\n",
        "s1 = train_f14['INST_.1'].astype(str) \n",
        "s2= test_hsc14['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy14= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df14) \n",
        "print(14 ,',',len(f_df14),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy14,2)) \n",
        "\n",
        "s1 = train_f15['INST_.1'].astype(str) \n",
        "s2= test_hsc15['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy15= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df15) \n",
        "print(15 ,',',len(f_df15),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy15,2)) \n",
        "\n",
        "s1 = train_f16['INST_.1'].astype(str) \n",
        "s2= test_hsc16['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy16= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df16) \n",
        "print(16 ,',',len(f_df16),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy16,2)) \n",
        "\n",
        "\n",
        "s1 = train_f19['INST_.1'].astype(str) \n",
        "s2= test_hsc19['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy19= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df19) \n",
        "print(19 ,',',len(f_df19),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy19,2)) \n",
        "\n",
        "s1 = train_f20['INST_.1'].astype(str) \n",
        "s2= test_hsc20['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy20= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df20) \n",
        "print(20 ,',',len(f_df20),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy20,2)) \n",
        "\n",
        "s1 = train_f21['INST_.1'].astype(str) \n",
        "s2= test_hsc21['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy21= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df21) \n",
        "print(21 ,',',len(f_df21),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy21,2)) \n",
        "\n",
        "s1 = train_f22['INST_.1'].astype(str) \n",
        "s2= test_hsc22['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy22= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df22) \n",
        "print(22 ,',',len(f_df22),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy22,2)) \n",
        "\n",
        "s1 = train_f23['INST_.1'].astype(str) \n",
        "s2= test_hsc23['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy23= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df23) \n",
        "print(23 ,',',len(f_df23),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy23,2)) \n",
        "\n",
        "\n",
        "s1 = train_f28['INST_.1'].astype(str) \n",
        "s2= test_hsc28['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy28= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df28) \n",
        "print(28 ,',',len(f_df28),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy28,2)) \n",
        "\n",
        "s1 = train_f29['INST_.1'].astype(str) \n",
        "s2= test_hsc29['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy29= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df29) \n",
        "print(29 ,',',len(f_df29),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy29,2)) \n",
        "\n",
        "s1 = train_f30['INST_.1'].astype(str) \n",
        "s2= test_hsc30['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy30= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df30) \n",
        "print(30 ,',',len(f_df30),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy30,2)) \n",
        "\n",
        "s1 = train_f31['INST_.1'].astype(str) \n",
        "s2= test_hsc31['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy31= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df31) \n",
        "print(31 ,',',len(f_df31),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy31,2)) \n",
        "\n",
        "s1 = train_f32['INST_.1'].astype(str) \n",
        "s2= test_hsc32['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy32= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df32) \n",
        "print(32 ,',',len(f_df32),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy32,2)) \n",
        "\n",
        "\n",
        "s1 = train_f38['INST_.1'].astype(str) \n",
        "s2= test_hsc38['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy38= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df38) \n",
        "print(38 ,',',len(f_df38),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy38,2)) \n",
        "\n",
        "s1 = train_f39['INST_.1'].astype(str) \n",
        "s2= test_hsc39['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy39= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df39) \n",
        "print(39 ,',',len(f_df39),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy39,2)) \n",
        "\n",
        "s1 = train_f40['INST_.1'].astype(str) \n",
        "s2= test_hsc40['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy40= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df40) \n",
        "print(40 ,',',len(f_df40),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy40,2)) \n",
        "\n",
        "s1 = train_f41['INST_.1'].astype(str) \n",
        "s2= test_hsc41['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy41= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df41) \n",
        "print(41 ,',',len(f_df41),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy41,2)) \n",
        "\n",
        "s1 = train_f42['INST_.1'].astype(str) \n",
        "s2= test_hsc42['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy42= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df42) \n",
        "print(42 ,',',len(f_df42),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy42,2)) \n",
        "\n",
        "s1 = train_f43['INST_.1'].astype(str) \n",
        "s2= test_hsc43['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy43= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df43) \n",
        "print(43 ,',',len(f_df43),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy43,2)) \n",
        "\n",
        "\n",
        "s1 = train_f47['INST_.1'].astype(str) \n",
        "s2= test_hsc47['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy47= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df47) \n",
        "print(47 ,',',len(f_df47),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy47,2)) \n",
        "\n",
        "s1 = train_f48['INST_.1'].astype(str) \n",
        "s2= test_hsc48['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy48= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df48) \n",
        "print(48 ,',',len(f_df48),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy48,2)) \n",
        "\n",
        "s1 = train_f49['INST_.1'].astype(str) \n",
        "s2= test_hsc49['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy49= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df49) \n",
        "print(49 ,',',len(f_df49),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy49,2)) \n",
        "\n",
        "s1 = train_f50['INST_.1'].astype(str) \n",
        "s2= test_hsc50['INST_.1'].astype(str) \n",
        "a = [[None for i in range(len(s2))] for j in range(len(s1))] \n",
        "accuracy50= lcs(s1, s2, len(s1)-1, len(s2)-1, a)/len(f_df50) \n",
        "print(50 ,',',len(f_df50),',',lcs(s1, s2, len(s1)-1, len(s2)-1, a),',',round(accuracy50,2)) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6FAJVK61op8"
      },
      "source": [
        "accuracy_svd =(accuracy1 + accuracy2 + accuracy3 + accuracy4 + accuracy11 + accuracy12 + accuracy13 + accuracy14 + accuracy15 + accuracy16  + accuracy19 + accuracy20 + accuracy21 + accuracy22 + accuracy23 +  accuracy28 + accuracy29 + accuracy30 + accuracy31 + accuracy32  + accuracy38 + accuracy39 + accuracy40 + accuracy41 + accuracy42 + accuracy43 + +accuracy47 + accuracy48 + accuracy49  + accuracy50)/30\n",
        "score_svd= accuracy_svd*100\n",
        "score_svd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ebj5PSRXD_RG"
      },
      "source": [
        "print(\"knn:\",round(score_knn,2))\n",
        "print(\"rt: \",round(score_rt,2))\n",
        "print(\"dt: \",round(score_dt,2))\n",
        "print(\"svr: \",round(score_svr,2))\n",
        "print(\"svd \",round(score_svd,2))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}